# Bloom filter changes for Grafana Loki (Loki Community Call Sep 2024)

In this Community Call, Senior Software Engineer Christian Haudum talks to us about bloom filter changes for Grafana Loki, ...

Published on 2024-09-13T15:00:47Z

URL: https://www.youtube.com/watch?v=keXrUf8jw1A

Transcript: and restart okay so welcome everyone we are recording this so if you don't want to be recorded turn off your camera and the agenda is kind of short today uh but we have an interesting topic to discuss regarding Bloom filters and possibly pivoting to structure metadata so H who wants to get started with that we have like a bunch of questions that I think yay and Nicole pull together so maybe between Christian and I we can answer those yeah definitely Nicole do you want to answer all the questions with the white dots and I'll ask all the questions with the black dots sure but maybe maybe Kristen you can tell us first what um what what the bloom filter changes are yeah uh so in the since the Lo release 3.0 uh we have been working excessively on the bloom filter feature uh which is was one of the major features of 3.0 in general and uh we've been iterating a lot trying out different ideas that's also why uh the feature is marked as experimental in the be at all uh because we need to kind of make make this uh work for large scale so we can also use it internally at graan labs and and that's why there have been quite a lot of changes and uh I want to mention the the major changes that we did in the past couple of of months so the biggest change actually that happened recently is that uh happened on the right path for blooms uh in the very beginning with Loi througho we had a component called the bloom compactor which was responsible for building the bloom blocks from from the chunk data from the loog lines uh and uploading the blocks to object storage so they can be dat quered and this uh Bloom compactor component worked in a very similar way to the to the regular uh compactor it's a stateful set when cators uh and um basically every the the component was using ring uh to determine which instance of the bloom compactor uh does what part or what chunk of the work for a specific tenant and a specific time range basically uh this made the the operational uh burden quite High uh stateful sets in combinat are very hard to operate uh anytime you have a topology change in the ring it means that ownership against three assigned you're doing rework it's not very efficient uh you have hardly any control of splitting the the work more granular between compactors or you can of distribute since some compactors do more work than others uh you can't if you're just playing a playing uh state for St you can't kind of distinguish what uh what the um what the individual instances are doing and some of them are idling some of them are doing way more work so this this the bloom Camp therefore has been replaced by two new components uh seems more complex at first but uh the two more components are one is a planner component which is still a state for set but it R as a Singleton and uh this component is really just responsible for planning the work out for for building the blooms and uh the the second component the bloom Builder is a stateless service which pulls the work from from the from the task cue from the from the planner and uh basically you can scale the the amount of Bloom Builders uh very easily horizontally depending depending on your your demand so you can scale up and down and there's no reassignment of tasks but every stateless Builder kind of pulls the task that it it should work on so it's much more even distributed and by by running these this these uh Builders also uh stateless on you can run them on spot instances for example if you use a managed uh kuet service and spot instances are way more cheaper up to 75% cheap ER than the regular ones so with the same amount of uh of workers you can achieve like way uh lower TCO so that has been the the big change in the past uh what you see so far already is uh removing the all the code from the bloom compactor from from the GitHub repository uh and repl replaced in the deployment uh for for the h deployment replaced the the compactor also with the uh Ploom planner and Builder components uh and um yeah and with with going forward we only use the the planner Builder setup uh for for new uh new feature development okay so would you say that the planner and Builder together are doing the same work of the compactor or and and it's just that that it's more scalable or is it a totally different thing uh they're doing exactly the same work like the the implementation of the work that is done uh is basically identical to what the compactor did in a single component but it's now splitting up into planning into building phase that's why it's much more easy to scale and to operate um but the work is essentially the same and to produce the same output can I sort of ask question so does the bloom gateways still exist is that still a way of interacting with the the blooms and it's just this this component gone and is there any other interactions with other components within Loki that's changed compared to the old architecture or do you know the the queriers or the indexes still talk to blooms Etc um to get their information the r path States the same uh since the the output of the bloom planner and Builders is is identical to what we what the compacted did uh the the bloom gate we can can uh use the same blocks the same format uh everything's the same so the read path didn't change at all with regards to the change the the bloom gateways are still responsible for filtering out the the chunks that don't contain the the searched um the the filter criteria so to reduce the amount of of chunks that need to be searched for for the spe specified search term yes so there's no change in the r path at all with regards to that okay so I mean on one hand there's this surface level change of the the bloom compactor not being there anymore and instead being replaced by the planner and the Builder but also how does that tie in it it it seems like there's also been a change in direction to word structured metadata so that is the that is the upcoming change that we are started working uh right now more or less uh and this is a bit of a pivot in the not in the way how we how we index uh data but the way what we index and and the shift there is that we essentially uh decided to move away from indexing engrams of of the log line content towards indexing the plane uh structured metadata values and uh the reason for that is uh that what we have seen so far is when you index engrams of of the log lines this is a very Universal concept uh to index a large large blops of text which is which log lengths can be uh but you index basically uh every single every single detail for every single log line and log lines contain a lot of of course a lot of redundant information a lot of information that probably is never queried for example beat time stamps or specific uh specific names keywords that that you probably never want to uh filter out uh in in NE in H queries so there's a lot of uh a lot of data that is have been indexed when uh which is never been queried and this results in very large uh Bloom uh data FES Bloom block sizes uh which had turned out to be a very very problematic uh in in in operational terms so it's very hard to operate them it's it's uh when we started out with this uh with indexing uh log lines it kind of the size is felt manageable uh with with low to medium sized uh environments like in our development environment everything still seem fine seems seem still fine uh but once we we made the leap to uh more production environments we saw that the amount of data that is indexed and never qu is kind of too big to make it easy to operate uh and so what we also saw is the the from the um aering point of view that people know what the quering for uh rather than just arbitrary data and this is usually some some uh identifiers for example Trace IDs uh or other unique IDs transaction IDs from from their structured logs uh and very often people al already use that uh use use these IDs and index them into into structure metad data along the along the log line anyway um so we are going to to build it in a Direction Where We instead of indexing the log line we index the the structured metadata into the blooms which significantly reduces the amount of data is index in the first time is much more uh much nearer to what people are quering for and what they're looking for people are not looking for sub strings for example of a trac D but they always know the Tracer D up front that they looking for the full one and we can we don't need to tokenize and create multiple engrams from from a single structured metadata value but we can just index the full uh the full key uh and retrieve that from the Blom field as well when you when you create so we save a lot of uh resources when because we index way less and at query time uh we have the advantage that we also don't need to uh we can basically look up the the keys that I search for more easily in the bloom which will overall bring down the the size of the of the bloom blocks of the generated data uh to make it manageable and operatable at a at at a large scale as well um so yeah so so we kind of built structured metadata what you're saying for like to sort of solve the open Telemetry problem of all of that metadata that comes with with the payload so do you see the role of structure metadata changing to be a much more active um sort of an active tool that we use or we tell our customers to use um and sort of with that should they be like you know shoving everything into structured metadata or is there best practices around what they should be doing you know and keeping in structured metadata uh so first yes uh uh indexing or the this pivoting to indexing structure M data fits very well into the concept of of oel where attributes from uh from otel requests are kind of automatically transferred into struction metad data and if you uh if you send the the attributes in a in in a a thought through way uh you can benefit uh first of all a lot from from from these fields being instructure made without for example needing to pass a log line that is Chason uh even without the the bloom filter attachment but now uh by adding the bloom filters on top of structure metad data uh it's kind of structured met data become even more important than than it is than it is now with otel and it think it makes the the otel uh um the uh yeah transition the transition to otel uh even more uh compelling in a way uh when you say we're going to to uh to use that for with Bloom filters to accelerate your query um with regards to the second question then uh when when people are using this in open source or with with our customers to should they shovel everything into into structured metadata um no uh it doesn't mean that that this is uh useful uh it's only useful if you really want to uh if you want to or if you have fields that you are actively looking for uh uh at at query time so if you have a use case where you we need to search like for PR IDs or transaction IDs or um some for some iot use case for some some uh device IDs uh where you want to get all the logs from from from the full log volume uh then then it makes sense to use that as as structure metadata so except for the initial search term that you're looking for additional attributes in or additional Fields instruction metad data don't benefit uh from that like it even makes it more complicated because at the end you're still getting a a a log line back that you want to my you want to possibly filter on even further down like that you want where you want to do also a string match later on or transform it the log line into something different uh different result and of course if you if you move uh if you want to do that if you still want to do that uh you don't benefit from that being instruct metadata you have to do that on the login itself anyway um and uh yeah so it really just makes sense for these specific fields that you're that you're looking for that want to filter down your your Neel and htic searches so does that mean that there are no current plans to improve the performance of querying like the the real needle and hastac ones uh queries where they're running on solely on the log lines it sounds like the shift is that we're doing that only for structured metadata now is there any are we completely dropping that line of work or is it more like we'll do that later um yes so by by indexing only structure meta that we remove the the capability of of doing kind of accelerated search on on strings on the log line itself so it's really uh it Narrows down I say it Narrows down the use case of of NE HC searches where up to now they were very general where you could it's kind of almost like a a um no not not full text search but into the direction of a full text search where you have a large blow of text and you want to like um search for occurrences of a specific term uh but that shifted towards a really dedicated um single field lookup more or less where you have one specific term that you want to that you know up front and might or might not be part of the log line itself uh can be some additional attribute or it can be something that has been extracted at the the client side already uh yeah but the so because once you filter down by by a structure m start a field and you can reduce the amount of chunks that you need to root Force look at afterwards you can speed say this is almost linear right The Brute Force search you can scale almost linearly to a certain degree and if you if you can kind of remove or yeah remove 80% of all the the log lens that you need to Brute Force search it's Loki is is that's what Loki is best at it core uh doing Pro CL search on moderate amount of of unstructured log lines so this is kind of a combination you it's like a two almost like a two step the first thing is filtering down the amount of work that needs to be done or reduce the amount of work needs to be done by by looking at the specific field and then apply the Pro Force search uh as a second step which is Loki is really good at just to kind of like add question on to that one with um unstructured metadata the way that it will now work would it will you select what which Keys you want from the instruction metadata to be added to the blooms or would you just basically say we expect all of the UN the keys in the unru metadata fields to be important so we're just going to take all of them into the that index um is as the first iteration we are going to uh index all the fields of or stru of the structure metad data uh we would like to keep it kind of minimal the amount of configuration that you need so ideally it would be a single single configuration a zero configuration feature uh but yes there might be cases where where you want to run lowkey and you have a lot of structured metad data and you want you know that you're only going to use one two three maybe a hand a handful of fields really for for searching and uh this is very likely be a a second step that we say uh we have a include list of fields that you actually want to to index uh it helps to reduce the the the amount of of of work at UH at creation at creation time right uh so if you if you know up front you only need a certain Fe certain amount of feeds and you should be able to do that uh it's not yet properly planned out how this is going to work uh because the first iteration will be all metad dat okay and and maybe this is also like I I'm not I'm not so clued up on how blooms work so maybe this is a very beginner question but what is the difference between like a highly indexed you know the a traditional database that has a very large index and then um having balloom filters that run on structured metadata is there a performance difference between those um so the the the main difference is that blooms can be very space efficient it can be a very space eff space efficient index for large large quantities of data because it's probabilistic uh data structure it means uh when when you when you look up a key in in the bloom and you you get you get a kind of a a a match a um uh yeah when when when the Bloomfield returns that it's it's contained then it's probably contained it doesn't mean that it's actually is contained whereas it's it's like the opposite around from uh from other indexes where you so for example a a uh an index of every field and you know it's going to be there and if you if you if you look it up and it's not there it's not there uh but it's it's kind of the other way around it it just means that if it if you get a uh you get a probably true probably true response and by that this this can be done by by kind of overlapping Keys internally in the bloom filter and that's that's the reason why it can be rather small compared to uh similarly uh working other indexes that say it's probabilistic you have a a certain um false positive rate which is rather small it also doesn't really uh doesn't really matter if you need to for example uh additionally search then if if you don't filter out one or yeah if you filter out if say uh if you have you have you have thousand chunks overall and your Bloom filter returns it says uh you have you can fil out 900 chunks but do really matter if the if the actual thing you're looking for is only in uh in 95 chunks because five chunks had a false positive out of this thousand so uh they the main difference between other indexes uh is that it's just probis and therefore it's still small but the uh the uh the gain you get from even a small index is is really high and what we have seen is when this displ into the road was what you have seen large indexes like if it's if you index too much data into a bloom filter then it also uh grows to a to a degree where it's really hard to manage and that's with traditional indexes as well if if they become bigger and bigger I mean it of course they can make everything faster but it's it's way more expensive to operate and it's way harder to operate and that's what we try to minimize with with Bloom filters so this kind of like brings it like because I had like a obvious question like Nicole there as well so this is the whole reason for using like Bloom filters rather than index like cardinality in the fact that we can we're almost like we're taking chunks and we're guessing within a much like we're almost Pro probabbly can't even say that word um prob like probabilistically um looking for say a trace ID rather than saying okay we're gonna we're gonna every specific Trace ID which could just blow out your your cardinality um ex yeah and so space space it's the space uh uh space efficiency that make them really attractive and and there's kind of no do does do blooms have like a a shelf life will they eventually rotate out for you know for more or or do we can because they're so small we can keep them sort of indefinitely uh there is uh already a retention feature for for blooms so the the bloom the bloom blocks like the data of the actual files are stored in object storage and you can configure this the retention for these files the thing thing is the nice thing about this additional uh Bloom filter is that you don't rely on the bloom filter so if the bloom filter for a specific time or a specific data set is not there uh it just means that we can't additionally filter anything but it's not like that we are breaking or relying on that file being present so it's very it's very easy to just remove them and it's just if you remove them at the same time where remove the rest of your data let's say you have a a 30 or 60 or 90 day retention of your of your index and if your chunks it afterwards of course you can you can delete them as well or if you're saying you you're quering only the the the last week anyway or last two weeks then you theoretically you could even delete the the bloom filters after this time after two weeks even though you're you still have the index for another month additionally but you don't benefit from the acceler search then after beyond that time of the retention of the bloom blocks uh the feature is already there uh so you can configure that uh very similar to to how we configure the retention for um the uh the chunks and index on the on the regular compactor so is the idea that if if blooms are turned on then then there's going to be a bloom that's created for every log line that's ingested or or stream that's ingested uh yes for for every tenant and and every stream you have kind of a separate Bloom filter where but multiple to kind of keep the uh to kind of keep the the blooms organized you can have multiple um streams in a single in a single file you just live together uh multiple Blooms of of multiple series can be live together in a single block just for for managing that's like you have a a a certain amount of of uh of streams they kind of they have an identifier which is the fingerprint and the and these identify kind of a a uh a range of where yeah it's uh what is it the 6 60 64bit range uh it's a very high range like you can distribute your streams really nicely across this this range and then you can split them about into parts so every part has an equally amount of of your streams and you can then block them together into a single into single file um that said this is how it's currently done so you have multiple Blooms of multiple streams in a single file um this is something which might change as well or even likely to change as well uh for the reason that uh at query time if you want if you need to download blocks to to create the bloom data for if you like if let's say you have 100 streams with 100 blooms in a in a bloom block grouped together but you're only interested in looking at at a single as a single stream to filter out a single stream um you still need to download all 100 uh Bloom filters which is not efficient on the uh on the read path so by splitting up the the bloom blocks or making blocks for a single series uh we've been discussing that to do that it allows us to more efficiently download the the blocks for querying and this will also make them smaller overall because you don't group them don't group 100 streams anymore into a single block and and the block becomes I don't know uh eight 12 32 megabytes big um you can you have just a you have just if you have 10 you have 10 or 100 uh streams and then you can the the individual file size gets much lower and it helps also to for example uh to Cache uh to cach these files in memory and which makes them even more easy to to operate and operationalize so you can you can even uh run or to query the the blooms uh at some point is like in a stateless manner where similar to chunks you just uh fetch them from from a m cach or intermediate cache uh rather than from object storage uh if they are below 2 megabytes for example the individual files uh then you can then you can kind of stateless query them and distribute all the query work uh to the queriers um rather than a specific type like a specific uh servage which is now the bloom Gateway the bloom Gateway is a is a stateful service which also intermediately caches the the bloom blocks because of their size which is which is problematic um and if you if if we can get the bloom uh block size down to very like below 2 megabytes for example for a single series then uh it makes makes operations even simpler so what happens if there's a recording rule that is set up are blooms automatically built off of those um recording rules do not uh do not use blooms if if you're running the recording rule in the in the ruler so there are two ways how you how you can evaluate recording rules ly one is uh on the ruler itself uh which kind of uh is a is a uses the the the query engine uh from lowy but it's it's single threaded and it doesn't do any uh splitting and Charing that is usually happening in the in the query front end um but if and the second uh so then you can't benefit from from blooms but the where you would automatically benefit from from blooms is when you use use the remote rule evalation which is the ruler just dispatches the query to the to the query front end uh to evaluate the rule and then the regular read path is taking uh is is is is used which depending on the tenant the configuration either uses the blooms or not us not using the blooms but it would use the regular repath and so it could benefit from the blooms but I would say uh since rules are usually only evaluated in the very in the very recent data like last 1 minute 5 minutes maybe 10 minutes uh hardly anything beyond 30 minutes I would say uh they would not really benefit from blooms anyway because uh it takes some time from inchest until you de blooms a build um we've seen kind of like a delay of of 6 hours even even more in in our production environments where we just in order to process the amount of data and index the amount of data after ingestion it's just you have this delay until the bloom blocks are ready and be used uh that said this will be reduced if we index less with structure meta data so this will speed up by by the amount of how much structure meta data is smaller than the log line data uh but still you very likely not really benefiting from maybe the last hour or two hours maybe where you don't have blooms yet and so it's not really I would say it's not really a feature for uh for rule evaluation so sort of like bubbling back up a bit then if we have a look at our what's what should our users sort of future proof or prepare for just to get ready because obviously there's a lot of work that you guys still need to do to get this ready for unstructured metadata you know what what what should they be looking at should they be looking at configuring you know their agents such as alloy to start use structured metadata and start working out what they want to put in structured metadata what's kind of like your advice to get them ready so the advice to get ready I would say is yes start using structure metadata um if you have a very specific use case on how you want to create your logs so certain as I said before certain companies are uh have the their log use case built around very specific searches uh Trace IDs where they want to trace a a transaction or something throughout their their whole system and see how it's how this like to follow it similar to what what you could achieve with with with tracing uh but maybe a bit more detailed and with all the extra information that you have from logs uh uh but yeah like if you have that use case and you know you you filter on on specific Fields a lot then uh it's I would advise to put it into structur meters data also instead of instead of the labels I mean regular labels have this uh have the problem of you can't use very high cardinality Fields or Val values on on the regular labels because that would affect how how we store or how Loki stores uh stores your logs and that's kind of a it's a restriction uh the the log but the the label values should be not too too big not like not too many but also not too little uh so you have a kind of a balanced distribution of how to store store logs but with if you have very high cality fields that you query put them into structure M start using alloy or even better using start using oel as you discussed earlier uh where this should be even easier if you have uh if you have traced these attributes or put anything into into uh into uh yeah attributes with with otel I think this is the the the future proof uh solution I would say uh Loki is definitely also using in more more interest Direction uh just as a as a unified um way to to inest any any uh observability signals really and I guess so like my final question so if anyone had like started experimenting with like the compactor and you know Bloom filters um is there anything you advise them to do before you know say they upgrade to the next version of the helm like should they be prepared obviously that that component's no longer going to be there so should they basically just maybe disable any of the bloom features for now in the in the next iteration of the helm just to save any problems um so uh for the for changing from Bloom compactors to bloom Builders there is not really um much to consider if you're using Helm for example um you should be the the helm the helm configuration the helm default values should be sufficient uh their head beans some um configuration changes however like some of the per tenant settings in in Loki if you if you have changed them that have been prefixed with Bloom compact Bloom like Bloom Dash compact something uh because the to was removed uh the always got renamed to bloom bloom Dash build instead of Bloom compactor uh this is stated also in the in the upgrade guides uh upgrade notes of Loki so you can look at that uh the few have been renamed that that still exist now but just moved to the Ploom Ploom Ploom uh PLO build uh section of the configuration and like settings that have been Bloom compact specific are not there anymore they've been removed and therefore so need to remove from your configuration otherwise Loki won't start so that's for the helm uh and the the regular low key for with regards to the upcoming change with the structured metad data this is going to be a bit more difficult though um not in terms of uh what you need to deploy the components are still the same uh the the the problem however is that the bloom blocks won't be comp compatible anymore so you can't run both index log lines and index structure metad data at the same time uh this is not backward computable we're going to break this uh we think it's it's easier to make the clear cut and say if you want to continue with your indexing your log lines and you are kind of happy with that you can you probably yeah you need to continue with your uh um with your current version and you can't upgrade unfortunately uh if you upgrade you would need to stop building the blooms first and to make the clean cut you you need to delete the blooms uh directory on object storage to uh to kind of wipe the existing blocks not because they are not uh you're not uh the D won't be used anywhere way you theoretically probably could use could not delete them but if you want but if they would be they could be downloaded and we would detect that they are not compatible anymore and we would discard it again so it's it's unneeded work to need to be done if you just remove the uh after stopping the the the the bloom building removing the the blooms directory on object storage for the on the bucket that that your L is pointing to uh then you upgrade the components uh the new component or like the new version which will be ly uh 3.2 uh then uh the new version will build only Blooms from from structure metadata and also the the r path will only accept those new new blocks um you can you can specify anyway how much uh how much back in the in the you want to to build the blooms for so there's the Min table offset and Max table offset in the bloom planner options to specify kind of how many days backwards do we want to build rebuild the blooms for and if you say you need the the the blooms uh but now for structure made that you can you can say 30 days even uh to rebuild your Bloom it will take some time but eventually will catch up and uh uh will will rebuild all the blooms anyway um so yeah this manual step of of deleting the the not compatible files from object storage but I think that's uh a a feasible thing to do uh because uh it enables defin end process to deliver this feature faster uh for everyone and uh like there's no real need for being backwards compatible because you can't query blooms and uh and log lines at the same time anyway with the same uh with the same feature so uh yeah I think it's a good uh compromise with this regard okay that was it for me have about EJ yeah you've absolutely crushed it and thank you for letting us just dig into blooms in general as well I we were just like we have the masters of blooms on the call so let's just go for it yeah it was great definitely uh I hope this is this is helpful for other people as well who when we have seen that the community is actively uh using blooms already with open source uh they're posting issues and uh we see them uh it's not always easy to to answer and uh and uh uh support them as as much we much as we would like to but uh yeah I think people people will benefit from from this as much as as we do as a as a company uh having a feature that is just easier to operate and has less data to to deal with is just uh and has basically the same um um benefits uh is is uh definitely good a good direction and we are excited about that what if folks yeah thank you very much Christian for answering all those questions that was a master class on blooms with luy so yeah uh it's just us I don't think anyone else is on on the call right so I think we can call it a day and thanks everyone for joining and Nicole will you take care of uploading this to YouTube yes I will stop recording right now thanks everyone thank you very much

