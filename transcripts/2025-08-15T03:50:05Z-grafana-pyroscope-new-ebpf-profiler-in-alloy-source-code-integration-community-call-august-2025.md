# Grafana Pyroscope: New eBPF profiler in Alloy &amp; Source Code Integration (Community Call August 2025)

Published on 2025-08-15T03:50:05Z

## Description

Christian is going to talk about the new eBPF profiler in Grafana Alloy as well as new Grafana Pyroscope Source Code Integration ...

URL: https://www.youtube.com/watch?v=E1PjgOfFoDQ

## Summary

In the August Pyroscope community call, hosted by Christian and Tiffany, participants discussed significant updates related to source code integration and the new eBPF profiler in Alloy. Christian provided detailed insights into the benefits and functionalities of the source code integration, which allows users to connect their profiling data with the corresponding lines of code, enhancing the analysis of resource consumption in applications, particularly for Go language. The integration enables users to override Git repository labels in the UI, making it easier to access the relevant source code during incidents. Additionally, the new eBPF profiler, which replaces the previous one, offers improved support for multiple programming languages and enhanced profiling capabilities. The call also covered future enhancements, including better navigation features in the UI and potential integration with other source code hosting services like Azure DevOps. Attendees were encouraged to ask questions in the community Slack and to participate in future discussions.

# Pyroscope Community Call - August

## Introduction

Hi folks, welcome to the August version of the Pyroscope community call. If you've been here before, you know the drill. Please feel free to leave comments in the chat. If you're new and can't access the chat, you may need to create a channel first. 

Today, we will discuss the source code integration UI improvements, the new eBPF profiler, and Alloy. If you have questions after our discussion, you can join us on [slack.garafono.com](https://slack.garafono.com) to ask anything.

I will now pass it over to Christian, who will also share a link to the previous version of the source code integration call, which goes deeper into some aspects.

---

## Updates from Christian

Hey everyone! I have a few updates. In previous calls, we announced several things, and now you can actually start using them. 

### Agenda
- Source Code Integration
- Demo
- Limitations
- New eBPF Profiler Backend

First, let's discuss the source code integration: why it's useful and how it works to fetch your source code.

The **source code integration** allows you to analyze the resource consumption of your running software. In production, continuous profiling helps you look at aggregations like flame graphs, which break down resource usage by function name. We collect additional information, such as the specific instruction address the program is running at. This process allows us to recover the file name and the source code line, even though the binary itself does not contain the source code.

Typically, we work with compiled languages, where you have source code, a compiler, and then a binary. This binary no longer contains the source code, and additional tools are required to make sense of it. We translate the addresses back to their original file names and line numbers.

The source code integration is primarily targeted towards Go, but we have plans to expand support for other languages.

### Source Code Mapping
To map a git reference and its URL to your source code, we previously introduced a notation with labels. However, we’ve improved the UI to allow users to override these labels, especially useful in case of incidents or if you suspect you're using the wrong version. 

The **source code integration** is available in Grafana Cloud and OSS. You can find direct documentation shared by Tiffany.

In Grafana Cloud, setup is easier as we handle GitHub credentials for you. However, OSS users will need to follow some steps to configure their accounts.

### Access to Source Code
Accessing source code mapping requires you to have rights in GitHub. For private code, you need to have the necessary permissions; otherwise, you won't be able to recover it.

### Improvements in the UI
We have made the UI more flexible, allowing you to adapt the version of the source code when needed. This adaptability is particularly helpful in incidents.

### Profiling and Source Code
The next step involves knowing the source code version and its location. We need to clean up the source file paths, as they might differ based on where the code is checked out. Currently, we support Go modules and vendor builds, but we are looking to improve support for other custom build tools.

We aim to avoid storing the entire source code; we only process the requested file in memory to ensure user privacy and ease of auditing.

---

## Demo

Let's look at a demo using Grafana Cloud. 

1. We start by exploring the services discovered in our setup.
2. We can see a flame graph of the services running and how they interact.
3. If we haven't set up labels, we can now override them in the UI, allowing us to connect to the correct version of the source code.
4. By selecting the appropriate GitHub repository and version, we can load the corresponding source code.

This feature allows us to investigate incidents more efficiently without needing to set everything up beforehand.

### Navigating Source Code
As we navigate through the source code, we can easily view function details, which helps us understand resource usage better. We can look into functions, find where CPU time is spent, and analyze performance issues.

### Limitations
There are still gaps in navigation and edge cases that we need to address. We want to improve how we handle custom-built Go binaries and possibly allow self-hosting of source code servers in the future.

---

## eBPF Profiler Integration

Now, let's shift gears to the new eBPF profiler. 

The next release of Alloy (version 1.11) will contain the eBPF profiler, which offers wider language support and improved capabilities. This profiler will provide better visibility into various languages, including JVM, Node.js, PHP, and more.

The eBPF profiler allows us to profile CPU usage and off-CPU profiling, which indicates when something is not using the CPU. This is critical for understanding performance bottlenecks.

### Integrating with Other Tools
We are also exploring how to integrate the eBPF profiler with other observability tools, including distributed tracing through BA (Baylor). While these tools currently operate independently, we aim to find ways to share information between them.

---

## Conclusion

Thank you all for joining today’s call. If you have any questions, feel free to ask now or reach out later through Slack. Remember to check out the links shared in the chat for more information about source code integration and the upcoming community call next month.

If you’re interested in distributed tracing and other topics, be sure to join the Tempo community call happening shortly.

Thank you, everyone! Have a great day!

## Raw YouTube Transcript

Hi folks. Um, welcome to the August version of the Pyroscope community call. Um, if you've been here before, you know the drill. Uh, go into the chat and leave comments there. If you're new to this, um, you may it doesn't let you do anything with the chat. You may need to go actually and create a channel in order to be able to chat. So, please go and do that. Um, so yeah, basically today we're going to be talking about the source code integration UI improvements and also the new ebpf profile profiler and alloy. And then also if you have questions after we do everything today, um, you can go over to slack.garfono.com and you can join us over there and ask questions that you may have there. And so yeah, I'm going to pass it over to Christian and also I'm going to comment in the uh share a link for the previous version that we did that was for the source coast integration that maybe went a little deeper into some other parts of it. >> Yeah. Um hey everyone. Um yeah, like I I basically have a couple of updates. I think the last couple of calls we announced a lot of things and and now I guess uh you can actually start using them. Um so um roughly the agenda for today um I I'd like to start with the source code integration I guess why is it useful how does it work to to kind of fetch your source code and um um then uh yeah actually I will going to go straight into the demo um and we might see a couple of limitations so during the demo and and that's maybe why I want to look at what's next for the source code integration where are the current limits? Um we we also will look in into the new um hotel EVPF profiler back end which which has been merged now and also go slightly back to the demo and and uh see this in action. Um cool. So um yeah any any questions like basically like feel free to to comment or um actually uh wait till the Q&A section. Um I'm I'm happy with it either. Um so why would you want this source code integration? So um a profile obviously allows you to analyze the resource consumption of of your running software um um and especially if it's continuous profiling you're running software in production and you tend to kind of look at aggregations like a flame graph where everything is broken down by um the call stack and you can see basically like it broken down by function name there. But um the way we kind of collect profiles actually we have even more information than just the function name. We actually know which which part of the instruction I guess the the program is running at. And um to get to the function name we actually need to figure out this uh particular address what kind of it means um uh when when it comes to the call stack of the program and part of that we can basically also like um recover the file name and the source code line. Um so typically like um mostly speaking about compiled languages now but like you have source code you have a compiler like in the end you have a binary and then basically like um that binary the the the the kind of the there's binary code there's no no longer source code so you won't be able to make much sense of it without any additional tools. And so basically part of that we we kind of translate the addresses again back to where they kind of once came from. Um and uh this this basically like um will then yield us the file name um where where the kind of compiled file um was that translated in that binary code and the line number. Um so while uh kind of the the pro model that we use kind of allows to to to do that um kind of for pretty much any languages right now I think the the ecosystem is is mostly targeted towards go and and that's where I guess we have all the data available. So, so most of the things I'm going to show you today um like like are very we go specific but we have a couple of ideas how we can bring this to other languages and and um and and what is next there. So um in in order to then come kind of uh so you have the profile, you have the information about the file path, you also need to know kind of what version of the source code it is and where you would find the source code because um obviously like in a binary it doesn't contain the source code anymore. So it needs to kind of come from somewhere. Um so previously we kind of introduced that was an accident um this kind of notation with the labels here. So we we basically like uh want you to map a git reference and its git URL um to to kind of show you where where the source code lives. Um while this is kind of nice if if you have everything automated um and you might kind of uh have the problem that like there's another service that you didn't do those labels and and that's basically where we kind of improved the way the the UI can select the source code. So those labels can now be overwritten in the UI and that's kind of quite useful especially when it come when it comes to incidents or like when you kind of slightly think you're using the wrong version um you can basically adapt that version and and and like help you to kind of to show the the the right source code. Um so generally the source code integration um is available in uh graphana cloud and in OSS. So the um uh like a kind of those two are links. So if you open the the slide links, you can kind of go directly there, but it was also recently shared um uh the the the kind of direct docs on on this. I think Tiffany, you shared them. Um >> for graphana cloud, you you have less to do. I guess in that case, we we already set up the the kind of GitHub credentials, GitHub account. Um but the OSS talks will kind of guide you through those steps and kind of it works works in in both and the the kind of functionality is the same there. >> And I was looking at the docs and it's mentioning that it was only source like source code mapping is only available to people have access to the source code in GitHub. Does that mean it has to be inside of one of your repositories or just the code needs to be public? >> Um like it needs to be you need to have access in GitHub. So you're kind of using your rights as um Christian Simon if it's in my case and and so for example I also have access to the closed source pro Graphana source code. So if I open that I can see all that source code as well. Um uh so so basically like it follows like your your GitHub user. >> Okay. So like say basically like but does it need to be something that I where I have like edit rights on the code or just where I can actually >> so like uh most code I guess of your dependencies is most likely going to public and and you can use that and like obviously for for private code you need to have access otherwise there's there's no way for us to recover that and yeah we we're basically like logging you in using like or off style um and and you will be logged in as as the Tiffany GitHub user and and using kind of your permissions and and rate limits. So if you are able to see more source code then you will see it I won't. Um so I don't know internally we we we kind of uh like have that or off or we basically need to or authenticate another time to access graphana uh source code. This is also necessary to do that before I can see it in in the source code integration so that it's no loophole I guess. Um >> yeah, Brian is saying simplified you can't view source code that is private and you don't have access to it. Makes sense. >> Yeah. >> And then so like say whether it's on graphana cloud you have to go and configure it. Are there any plans to make it so it's just a thing that's already there that you don't have to actually do any sort of like specific stuff to set up? >> Yeah. So like basically like uh in graphana cloud you don't have to do anything specific. In OSS that's kind of where you have to do a bit more kind of GitHub uh u account creation. So like I guess the the thing that we made slightly sl simpler is uh we no longer require those labels to be there. So the labels is something that need to be there when you collect the profile and you can not easily add them later. And obviously with uh being able to override labels in the UI or that kind of settings in the UI you you kind of like don't have to think about it before. So you can collect the profile and then later start using the source code integration. So I do think this this kind of made uh it a bit simpler. Um so in general like I I think it will become a lot clearer as well when we go to the demo. Um in in uh um so I guess where we are right now we basically have the profile we have the file name and we have the file path we know the source code repo and and uh uh yeah it's it's kind of reference. Um so as the as the next step we we kind of need to clean up the the source file. Like often when you compile something you might have artifacts like for example in in in my laptop I have all my source code in home Christian git and like that might be the the kind of full file path and so obviously like this kind of structure is different for if Tiffany checks out the code and builds it. So we basically need to kind of some do some cleaning up to find the right source file. And also um in the go case there are a couple of ways of how you maybe handle dependencies and we currently support um the the the basically go mod build and we uh support basically go mode vendor when it's part of the the source code repository. Um uh there's also like another special thing where we have to handle the standard library slightly different and and so this is kind of very specific to the language and there are actually ways that we kind of don't support in go right now. So that you might for example use a different build tool like basil to to build your go code and in that uh case the git repository won't contain the source code and there's not a kind of direct link. Um I will talk a bit later in what's next um about how we can actually fix that and and uh allow more custom ways of building source code which then also will help to adopt more languages. Um in general like like one of the core principles for us was we don't want the user to upload us the whole of the source code. So we actually want to be not in a position where we kind of have to store source code and all of the source code for for a long time. So we really only want to process maybe this one file because the user has requested it and then it's also a lot easier for for for our customers to audit like what we access because in the case when I go to one file it will be very clear that I guess I requested that and then basically like um our our back end then maybe requests the go file and another source file but it will be very clear like at no point we will have the whole source code or we could leak it and we will also not store it persistently. it will basically be processed and will be in memory um uh only. So let's maybe actually look at this a bit more in action. Um so uh what I've done here and I need to share the right tab. So this is basically like a graphana cloud that I uh that I'm uh using and I kind of deployed it to my toy cluster let's say. So I'm running a few applications for um yeah managing a few things and and like you can see like kind of the services that that have been like discovered here like I've not cared much about any of those services. So I've not set up those labels and so previously like you kind of would have uh gotten so probably I just start with the alloy that actually um component that collects uh the observability for us. So you can kind of see um how the um the flame graph is here. I can maybe get an idea what what uh this alloy is um um I'm doing by figuring out. So we we can see um we run some file match components. So and then we actually process some low key stages. So most likely this is the alloy that processes my logs and and it's it's usage in the cluster. So if I want to go a bit further um then I obviously want to see the function details and now as I haven't set up those labels um I I I'm not able but actually with this new UI you can see here I can actually override this and so I guess in my case I I want the source code to come from Aloy this is publicly available so everyone who runs Aloy can can use that and then I also know um need to know the the version I want. So I can basically like just set something like head which is is the main um branch. But if I actually know which version it is, I can also type this here. And so now it it offers me to connect to GitHub, which I'm now doing because I've done that before. It it doesn't require any additional um um steps. And now what we can see is we we kind of see the source code loading and and um uh yeah overlaying the information in the profile with um where where that's basically like um uh coming from in in the source code line. I can also go directly to the to the file and and and basically like as as you can see this the source code name uh this file name here contains like slightly more information and that needs to be cleaned up that that was uh kind of the the thing I was talking about. And so if I think now like oh I um I I I have selected actually the wrong commit I can also change that and change it to a newer version of AOY and um yeah and that that's basically like allows you in incidents kind of to the lock quicker and it basically like don't require you to to set up everything. Um there might be even components that like you don't know yet you have a problem about. So in this case um we looked at a lawyer. I'm fairly familiar with a lawyer. I have a couple of PRs there and and uh we obviously maintain the profiling code there. Um but it might be something like um I don't know like DNS. So like usually most problems are somewhat related to DNS. So there might be a use case where I want to look more into the the kind of cluster DNS um which is this this core DNS deployment here. And while I can kind of um already make a lot of sense what this is doing by by just the function names, I obviously like I'm able to to to go a lot deeper if I'm now opening um the the source code here. And I guess in the same way um so we can say like like pretty large contributors to to the resource usage are the DNS serving the metrics pipeline and this is kind of some health check by the looks of it. Um, but if I actually want to figure out a bit more what what this is doing, I I obviously want want to look at the the source code and for this um it is a an open source uh uh project. So I I maybe just figure out Oh no. Um that's thing I wanted to do. Um just figure out where the repo is and I think you should be able to see. Yeah. Um, so core DNS GitHub. So this is basically like where where the source code lives and now I'm going back and we can see like how the code is loading now. So, while I'm not exactly sure which version it is, um um I I definitely can see this kind of being uh like accurate. So you can see how we are in the check function here that is also the check function that we clicked and um so for example the check function calls send and then here send if I want to know what kind of the send function does and where it spends the time which basically like I can see that it spends the time all exclusively exchange which also matches I guess with um the exchange here. So um those those all other contributions are significantly smaller and and so you can basically go down the the whole way and until I I guess you you figure figure out where where the the the code where the CPU usage is spent. >> So by default um it wasn't you had to go and like put in the uh repo that you were specifically going for. >> You will always need a repo. Um that's the kind of required. Um >> so does it is it basic like so putting the repo in there it's not the because like you're running your application right and obviously it makes the calls and it hits what whether it's cordns or alloy or whatever the heck it is that's happening. Um what is it that makes it so that you have to specifically put in the repo versus it knowing because it's called different libraries. Um yes like I guess in in theory we can probably infer like I guess we know the application is called core DNS and that if we maybe use AI to ask where the source code for codNs lives the answer might be core DNS but obviously like we don't know that for sure or like like that's not a mapping I guess that we we can can safely say so that's why I basically need to give it where the source code lives. So we we don't have that information currently um at collection time I guess where is your source code. So I definitely think this is possible to relay that in binary. So I don't I don't think all go binaries contain the the source code uh ref or source code hash but like there's definitely a way to include them into the build out. >> Yeah. It's like so like obviously you have your you're running your binary so it may not know all that kind of stuff but like if there's an option of like hey here is the overall code base that this is calling and then that should be able to see hey what libraries are being used if it has access to the original code because then otherwise you wouldn't have to put in like this is the one for cordns and then you have to figure out and like how does it work if like say hey right now yeah you're running head for your binary if you were to switch it to some specific git rep like version um is or get reference does that that like how does that change things because you're still running the code specifically using >> so basically like if I'm using the the wrong checkout then I will I will find that maybe a command is using CPU or some oddities like this um so um I obviously like like need to quickly look up what codNS version I'm actually running um let me just do that quickly ly for DNS. >> Yeah, because I figured like if it maybe if it had if you were able to give it access to like hey this is like if it's something that you have all of the code originally like maybe it's a binary you made being like hey here's my repo and that it based on that get know can see where everything's coming from since go knows when you're building it where these different things originally came from and then what versions are being used. So that way you don't have to be like oh here let me go to core DNS and put in the repository here let me go to alloy and put in the repository if you >> yeah no like this is definitely like I think maybe also like a problem that we are very early in that process. So like um like right now obviously if you if you look at um if you look at some of the the kind of code here. So here you could see the studs in codns um like the uh the kind of uh call stack we look here. So like likely this is the the right source repo. Um but I think this is kind of a benefit of go that the package name contains the the source repo. So um I do think this is something that we need to detect when we collect the profile. We don't do this right now and theoretically we could also look at two versions of code DNS and while we handle that if you put your labels in because when when you put the label um as described earlier so the service git ref you could look at two labels uh so you could look at two versions and you can actually select which one you want to look at because they they might be contributing differently to the flame graph. Um, right now the that's kind of not possible if we don't detect that early early in the in the process, I guess. >> And then like right now there's a bunch of like gray parts which are on the flame graph which are things that aren't taking nearly as much time or CPU and memory and we don't care as much but is there a way to like look into that stuff easily? Like is there any way to zoom in onto things? >> So like zooming in like uh is is basically like the focus block feature. So you can see how how much more appears here. Um so remember um I I kind of went into the the health check before um and like like we can see our health check send and so on. And now I guess we can also see like other parts. So like in we were in send earlier. So um I guess where we can see the the kind of uh like a call to exchange and to set question which I can't see right now. Um, so like like I also like just found out the version. So in in this case I'm I'm running like the 11.3. So I don't think this will change anything. But now I guess like we basically see the same thing, but if that version wouldn't be right, we might see some really odd behavior. We might not even be in the send function. Um here um and and and so like uh yeah, I guess you can kind of see how how this this health check I guess uses then UDP connection which then eventually becomes a kernel call um slightly further down the the line and while I guess So we we and so like here we can kind of see where this kind of starts to break down. Like in this case we um we we have a path that we can't resolve. So um like the there's a lot of those kind of edge cases where basically like in this case this is the the tool the go tool chain um go mod and for some reason we we don't pass this correctly and and are not able to resolve the source code and like the the while we're working very hard to to kind of get all those identified there can be still a lot of those cases where we basically like don't clean up the pulse correctly and you see no match. So I um I definitely encourage people to report those and and uh we we basically need to add um um uh we need to kind of add those uh into our test suite. But basically like the takeaway for you should be um no longer um setting the labels does not prevent you from using the the source code integration. So you can basically start using like like the profile as as soon as it's there. I'm probably going to move on now to the um uh to the bit um about the EVPF um integration. Oh, sorry. First um let's think about like what what kind of are are the gaps right now. Um, so you kind of saw me when I was um moving around the source code. It's kind of hard to keep track when you um when you're kind of moving up and down functions. Um, so so you want to kind of improve the navigation that you see which function currently at it should be highlighted and you you should be able to kind of connect the next um the next steps. Um we also kind of um found a lot of those edge cases and a lot of customuilt versions of go binaries and so um we want to investigate how we can support those better. Um so currently we're thinking we want to kind of um allow people to self-host uh source code. So um when I said earlier that one of our design choices was to avoid owning the whole source code um uh we we kind of um don't want to move away from that but for some um um some some kind of languages or for some build tools it is kind of very important to own the whole of source code. So we we kind of hit that when when a when a customer who uses Basil to build Go uh came to us that they they can't resolve the dependencies there. So basil kind of needs the full tree needs to have the full source code in order to kind of fetch the dependencies and and and uh like have them available and and so basically like our thinking is now that we will host a source code server that is so or we will not host the source code server. We will host that at the customer side and the customer will have to kind of basically like give that access to the source code and then can control source code access through that. So, we will still not own the source code. All the calls will still go to the self-hosted source code server. Um, I also linked kind of the proof of concept I've done for for the Basil Go. But, um, I I do think this could be a good gateway of like venturing into multiple languages because for for other languages, you need kind of slightly other um ways of fetching the the kind of dependency source code. And I I do think um it it will allow us to kind of iterate quicker on this when we when we have different source code servers doing this kind of work for us. >> And I'm going to throw on a question. Um >> yeah, >> the question is whether it's possible to integrate with with Azure DevOps. >> Okay. Azure DevOps. I I don't know what it's like. >> I assume that's what a stands for. Um so like I'm I'm not fully sure what the like what Azure DevOps does. Um so I imagine it is some CI/CD or or maybe Alexandra can you maybe provide a bit more um on on which way to integrate. It could also be like that it's kind of a source code host. Um I will back to you when uh when we when we >> when you when you give me a few more pointers. Um so I guess in general like um uh like if like whatever service you you kind of use to uh to store your source code um with this ability to self-host your server you can kind of integrate with those systems. So like basically the answer is uh like give me this file as kind of the request that the the source code server gets or resolve that commit for me and as long as you can kind of answer those um like the PC um that I wrote for Basil works with any git. So um so DevOps is basically a git hosting service um as far as the command says and um the the kind of Basil PC uses git clone and then the URL. So as long as that is possible um that will work. Um in the traditional implementation um that that we used we um we didn't fully like like or we we couldn't really use git in the sense that we then wouldn't like own too much of the um of the source code or we felt that is too invasive and so so that's why we kind of went for the GitHub API. Um, I I do think the the quickest way to support like any any use case will be this this this kind of like API that that we allow customers I guess to integrate with. >> Yeah. So the I I think the answer kind of got figured out but basically the source code is an repo on Azure DevOps but the question and statement was about whether it's just um only GitHub or any platform that's get like in right now it's just GitHub. Correct. >> Yeah. So like the the thing that we host um on our end, I do think this will stay probably like uh cloud services for a while. So while it's GitHub right now like GitLab definitely has the same ways of or gitlab.com has the same ways of integrating. But if you have more something like like I don't know less less common um we might ask you maybe to to to self-host the service. And right now I I have a PC but I do want this to be kind of a supported thing that that is part of the main Priscope project this source code server and this should only rely on git. Um and and and then I guess uh like like everything that source code server has access on git then will be kind of uh shown to the users. I hope that makes sense uh Alexandria. Um if you have any more questions definitely ask them and and uh I guess we get back to you. Um yeah so like um the um the other kind of thing that that like we we need to improve is this kind of end to end passing of information. I guess we discovered that um the Go version used right now is not known and we we kind of either have to guess it or we use the latest which which is not correct in all cases. And so um we basically want to detect the Go version. We want to be able to detect the source repo URL, the commit hash and then basically like pass that through all the way into Pyroscope and then use it in the UI. Right now there's a couple of things preventing us from doing this and I hope uh with the adoption of um um uh the the OTLP format and the SAM con um around OTLP attributes it will help us to kind of propagate that information properly and also built it into most if not all profilers. Um um something we also want to kind of make slightly better. Um if if you kind of uh remember we we we are in the in the kind of uh source code view here for example but like while we offer you a view on GitHub um we we I I think one of the natural steps would be to open it in your IDE and right now that there's basically no good way and obviously there's a lot of idees and and people have a lot of different preferences but we basically want to have a a better way of of kind of getting you to the next step and and maybe even showing you um information. So um we we we obviously have the MCP server I think was also part of one of the last uh community calls um like the like like there there might be some way of of kind of bringing those two a bit closer together um that it feels a bit more natural and um yeah that that was was really it. Um I definitely think the um there's a lot of uh insights to get from looking at the profiles using um using something like the source code integrations. So seeing directly I guess um what happens there like reading the context for comments and uh I do think this is very powerful. So um we will kind of continue to invest in in that. Um so I guess now slightly like topic change. Um so we we also kind of spoke about this before but um now actually the PR is merged and um the next release of alloy version 1.11 will contain the um the hotel ebpf profiler. Um so we kind of replaced our own profiler from parascope. Ebpf with a new one and there's no option to get the old one back. We we basically like want to go all in on on the OTL. um the hotel EDPF profiler and that uh has a couple of reasons but basically like that profiler like has um a lot wider language support. Um it it um like like provides obviously hotel provides us with a a good way of working together with other companies and and multiple um vendors can can bring the expertise to it. So I definitely imagine it to move a lot quicker than than our eBPF profiler. And um and so I guess you can already see that like um currently like the the the kind of language support in in the version 10 110 of Aloe was basically only Python as a high level language is why we by adopting the the um Alt EVPF profiler um can support like the JVM, Node.js, JS, PHP, P and Ruby and NET. Um remember all of that is only CPU profile types. Um so this will um this this will uh like like only be able to look at the um the the timing when CPU is used. And there's also a feature for off CPU profiling which kind of highlights when something stops using the CPU. it it will not exactly tell you what what is what it is doing because it's not using the CPU in in that time but most of the time from the context of the the stack trace you you will be able to to kind of get that answers um there's like also like a lot more wider features in the the PRs like so um the like like one of the things I'm looking forward is the ability to to kind of profile actual urrobes so probes um like like like can uh basically like count how often a certain function has been called and you then can see where they were calling from. That could be very interesting for like me alloc kind of functions or wherever you kind of gain access to something that that is scarce scar resource. Um so so that's uh pretty exciting. Um >> I have two questions for you. Um, one, uh, could in case some people who are watching are newer to all this, could you give like a really quick synopsis as to what alloy is and how it's beneficial here in general? >> Yeah, so like alloy is basically like um our um hotel collector distribution from Grafana Labs. Um so like the the the idea is that basically like all your observability collection should go through alloy and then go to the the kind of destination which can be graphana cloud could also be another vendor and I guess you can kind of modify things on the way. you can select what what do you want to collect and um I guess in the case for um profiling like a lawyer would be kind of controlling how often should what process be profiled and then also kind of collect more metadata around um like I don't know what part is this running in what what container maybe one day as we mentioned before we also want to collect the information about which go version what is the binaries source code um get and what is the git ref um information like this is basically alloyy's job to collect them and um yeah ship them off to graphana cloud or to Prosiscope or to to any kind of product that supports the the the kind the protocols >> and then I have a question from Alexandra from earlier um that's relevant to this um whether the profiler is also included with BA or just an alloy >> so right now um like file Baylor and the EBPF profiler do similar things right now they don't work together in in a sense so they are slightly different things so what basically BAR does it's doing distributed tracing for that it interferes with the way um HTP messages or like all the network communication is happening to kind of associate information about the trace with it and so um like it will give you basically uh like distributed tracing gives you a view kind of of one request how it passes through your system and profiling is more like on a node you know what uh a process is using CPU uh what this process is using CPU on and there's obviously the intersection of them two if one request uses quite a lot of CPU we would be able to associate that right now that's not possible yet but with um uh I don't know how how how much you follow that but like Baylor has um also kind of been donated to hotel and there is the plan that this is kind of shared the information about what trace is running on together with the the function that has been called could be uh information in the profile and so um uh yeah this this will basically like like help you to understand when a particular request uses quite a lot of CPU and where this request is coming from, like what other services were involved. And I I definitely think this gives you a pretty good view of um like like what the cost is, what request cost is like you you you can kind of basically like work backwards. Um what what led to that state of I don't know high CPU usage. Let's say you have a bug. you would figure out from the trace which customer sent it, what what is the um what is the request ID and and browser and so on and could hopefully like reproduce it a lot quicker if not um quickly spot where the problem lays com combined by the two. So, I don't really have a a great update or a timeline for this, but this is definitely something that that will um will be possible um to kind of share that context with um with the EVPF profile especially because I guess they work on the same level. they they do kind of roughly the same work being able to trace processes, understand um what what what kind of language ecosystem they are and um this this could be a great integration point for them too. Um right now there's not the right mechanisms in place in in hotel but I I do think I I we will see this in the next six months >> and then like so at least with the uh profiler before this one um there were in the docs it was talking about how you needed to uh enable frame pointers. Is that something that you still that I think that's something you don't need to care as much about with this or is that something you still have to worry about now? >> Yes. But um I'm not super familiar with the details, but I do think this this is um no longer necessary in all cases. So the um like like there are a couple of techniques to to walk the stack without frame pointers and I do think the the hotel profiler is able to to do them. Um I >> that was my understanding but I wanted to verify. >> All right, carry on. >> Yes. like I I basically wanted to quickly jump back to the demo. So, um what I kind of didn't mention before is like all of those profiles that we have here, they actually collected using this this new EVPF profiler while the uh old profiler would not be able to to kind of show you the file path and the source code information. The the new EPF profiler is also to able um to to extract that information. And basically that's kind of why we kind of see um also kernel level functions here. So we can see kind of a this is all I guess go up till a point and then I guess you hit um through through the Cisco I guess you interface with with the Linux kernel and and this is I guess visibility you didn't have before um when you were only using um like kind of the the the go prof uh profiles or with ebpf you wouldn't um have with the pyroscope ebpf you wouldn't have this kind of resolution of line numbers. Um, so no, that that is a pretty exciting feature and and like I'm I'm running on on my hobby machine, I'm running a few things that are not go. So for example, gitlab is is one of them. So you can see a lot of uh deep stack traces there of of of Ruby. Um or I also have some Java I think. Um, I think it's this controller here that runs Java. Obviously, I I don't really know much about, but um, this looks pretty much like like Java code and Java function names. So, so this is kind of something that yeah, we we got by by kind of adopting the the hotel profiler and and uh yeah, like um we we are able to kind of resolve those now. Um so basically like uh like I also have a small uh call for action. Um so so the next uh release of alloy will contain the new profiler and I I also provided some instructions here how I can test this today and um especially if you're running a lot of services that are have not been supported before. I I would like to to to kind of make use of the the new profiler and and hopefully like find no bugs at all and just um have better profiling data. But uh in the off chance you find uh some regressions, we we definitely want to know about them. um yeah like as soon as possible and uh and address them before we we have to release and this was kind of all the content I prepared. >> Awesome. >> But I'm happy to chat about anything else. >> Yeah. So folks, if you have any questions um definitely uh please ask them whether it's in here if you have something at the moment or if you think about something later. As you can see on the slide, um if you go to slack deck orfunno.com, um that is for the community Slack and you can go to the Periscope channel. There's uh tempo, a bunch of other stuff too. Um I can share again the uh link if you're interested in watching more about source code integration from um before. Let me double check that I'm copying the right link. Okay. So, I'm sharing that again for folks who missed it from earlier. And then also, if you want to look at the slides and be able to click onto the links, I'm adding that in the chat again as well. And then we'll be having another community call in about a month as well. So, please obviously come and join us again for that one. And um since it's going to be the uh first time of going and running the community call on right back toback where I'm dealing with both in some capacity. If you're interested in distributed tracing and tempo and want to come and see things about that and performance and MCP servers, um please go and check out the Tempo community call that is in a little less than an hour as well. So yeah, um I'm not seeing any questions currently. So yeah, please again ask questions, join us in Slack. Um and then there's we also have um forums that you can go to as well. Um and then there's community.graphana.com. So yeah, um I guess thank you everyone and talk to you all some other time. >> Yeah. No, thanks for joining. Um like definitely like reach out uh with with any problem you have. >> Bye-bye. >> Thanks for doing this as well. It's nice having you again. >> Yeah. No, always happy to to do that. Like uh have a have a nice rest of your day and enjoy the the distributed tracing in a bit. >> Thanks very much.

