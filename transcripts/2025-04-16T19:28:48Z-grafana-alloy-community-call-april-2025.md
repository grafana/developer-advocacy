# Grafana Alloy Community Call  April 2025

Grafana Cloud is the easiest way to get started with Grafana dashboards, metrics, logs, and traces. Our forever-free tier includes ...

Published on 2025-04-16T19:28:48Z

URL: https://www.youtube.com/watch?v=fuERbqFzjyw

Transcript: All right, welcome to the April 2025 alloy community call. I've forgotten all your spiel, Matt, uh that you normally start these things with. It was in my head a moment ago and it's gone now. But um yeah, we uh don't have an agenda today other than community Q&A. Um and then this will be posted to Graphana's YouTube channel um a day or two after the meeting. Uh yeah. So to start off, we'll just open it up to any questions. My questions would be on u the debug the graph view of alloy and what the future plans are for it. I really like it. it could be a wider screen. Even on the examples, it shows just a little bit of it. Um, one of the other things I thought about was the the lines only have color, so you can tell what they are whenever there's data flowing, but could they show color all the time and then go back to gray and flash the color whenever it's moving? And I didn't know if there was any way to have the boxes have color. But then once I realized that part of the open telemetry is there's different types of data going through there. It's important to know which the lines were. Um and that's part of it under the debugging view. Um, I added another component because I wanted to only look at metrics at one point to see the debugging lines going through and I didn't know if there was a different way to do that. But if there was a way to say I only want to see the metrics or I only want to see the logs or the traces that would keep me from having to put in just a component for breaking those out. So that's some some great feedback. Yeah, that feature uh was released updated by William who's on PTO uh this for for a big chunk of this month. So he would be the the primary developer of that feature within alloy. So I don't know um that anyone on the call has a great idea of kind of what features are next. There's a couple similar issues to what you mentioned that are open um either by him or by by other folks of you know better use of screen real estate. Um but um I know it's an exciting component that we all think is a ton of great value. So we'll be sure to continue investing in it and those are some good ideas. Uh for sure it definitely is good and useful and I appreciate it. Yeah, we'll make sure we pass that feedback along to William as he's as he gets back. Um, and if you are interested in opening GitHub issues for that specific feedback on the repository, that'd be great. Um, so that it gets tracked. Uh, alternatively, we can we can do that internally as well. I can do that. I did one for the more screen real estate, although that would have been better better wording than what I did. Yeah, it's uh I think it's a pretty clear clear concern that there's there's better ways to use up more of the screen. So, we're looking into ways to improve it. Oh, sorry. I've been using multiple alloy files in ours. I haven't moved to the uh deployed from uh graphfana mostly because our environment we have lots of different environments lots of different things that we have to deal with um which alloy makes it great and having the separate files makes it really good but some of the components I have like in some environments in lower environments or different environments I have different databases I want to uh monitor and so I'm using the um Postgress exporter but in some environments I have one set of databases in another environment I have a different set and it's not I can set up a separate completely separate component but I thought maybe it would be better to be able to com combine those into the scrape and just say these others but I don't see a okay to variably say in this environment use this um I can't merge those together. I mean I can join them in the alloy file if I have if I know what it's supposed to be but I can't just add those. I didn't know if there was a maybe there's a better way. I'm sure there's a better way of me explaining that. Matt, you look like you're about to respond. Um, yes, there is sort of a way here. It's not a great way. So, you can do um a module that like loads a file from a disk and some method. So essentially what you would need to do is load a file from content and then likely do a coales on that. Um actually you may not need the coales now that I think about it but load file on a disk and then load that module because an empty module is acceptable. So for the environments that um you you kind of don't have that on um you can essentially have it be a noop and then for the environments where you do turn it on you can have it be a um a valid. So one thing you could do is have a uh like your local the um I think it is it module.file file import whatever the name of the component is that imports a file for a module have that path point to a blank file if the environment variable is not set and have it point to say say you know if you have like postgress file has an environment variable on the environments where you don't want it you don't have postgress you have that point to something empty a dummy file if you have it on an environment where you want it to be you would have it pointed at like you know postgress.alloy alloy and then that is a way that not ideal in any way um should work. Okay. I have not done it as much as I've gotten. I've not done anything with modules. So I'll have to look at that. Yeah, that's that's one way to kind of mimic that behavior. Um I briefly thought about could you abuse for each for this, but I think the import file is probably a little cleaner with just some environment variables that point to files on the disk. Now, the only problem is I think you will have to have a dummy file on disk. Um, or wherever you're pulling it from. Um, it does have to be on disk. You'd import from a lot of locations. Um, but you'll need at least a dummy one because if if local file if the import uh somebody posted up the name of it, import.file. If import.file doesn't point at a valid disc, it will f or sorry, a valid file, it will fail to load. Um, so you don't need, you know, you could have the Postgress file point at empty.alloy where on the ones that you want to track it points at, um, you know, Postgress.alloy and you can do that for any kind of environment or, you know, anything you want. Um, that's one way to do it. Okay, thank you. Um, you could also if you if you ever moved to fleet management, um, that's probably the cleaner way to do it. [Music] Um, if you're if you're not using Graphfana Cloud or don't have access to it because of whatever reasons, um, then obviously not. The only reason I'm not using it is because we are on Grafana Cloud. The only reason I'm not using it is it came out after I had gotten all kinds of things done with alloy. Yeah, it's it's definitely a a slick feature that they are continuing to improve. I know they're working on kind of a attribute and variable injection soon in those managed pipelines which might also be uh really useful for this particular use case but I don't think that's actually um available um quite yet. I think it's like in an active poll request state so it should be [Music] soon. But uh yeah, fleet management's pretty slick, pretty cool. Um, and it it actually under the hood works similar to what Matt was describing where all of the different pipelines that you bring in are imported as separate modules. So they can't conflict with each other. You don't have to worry about naming conflicts and things like that in between them. All right. Thank you. That's all I had. All right. And the only other thing I wanted to to mention that got tossed in the agenda was that we released alloy 18 and a small patch fix in 181. Um, a lot of interesting new features including the like you mentioned the improvements to the graph. Um, go ahead Pete. Yeah. Um, uh, I had one quick thing that I wanted to bring up. It's a real it's a minor one. Um, I opened up a GitHub issue gosh about a month ago now. Um, I just pasted into the chat and it's just it's a minor nitpick in the documentation for the new file log uh hotel collector collector receiver option. Um, the default set in the docs says the start at field is beginning, but when you look at the code start at field and defaults to end. Uh, that tripped me up once when I was using that. So, um, yeah, just highlighting it. I can uh I can make a PR for that. I just didn't know which is the proper default to to use. So, thanks for that. We we want to mimic the upstream defaults unless we have a a specific reason not to. It should be in the documentation. So, it must be an accidental um typo or mistake on the implementation there. Um that brings up since you you bring up a a poll request that didn't get any attention for a month. Um, we're looking to uh improve our kind of issue triaging process. Um, working on drafting something that'll get probably posted in a poll request by the end of this week to just have a more defined system. Uh, have things get u hopefully more attention by making it easier for uh members of the team to be able to easily look at a queue of what things haven't been triaged and need attention. So, um, if anybody has particular pain points or particular systems from other repositories that they contribute to or raise issues in that they like, we we'd love some feedback. So, hopefully that'll be uh raised soon. We'll probably post about it in the community Slack once it's had a little bit of a little bit of internal review um as well just to make sure our community members know that things will hopefully be getting uh more attention and the ways to uh expect that system to work. Cool. No, I appreciate that. Unless anyone has any other topics they'd like to bring up, we can wrap this one up in a minute here. Uh, thanks everyone for attending. As mentioned earlier, the Oh, go ahead Paul. Hey, uh, sorry. Uh I just had one thing because I I see that P is on the call. Um so I happen to be working on a Kubernetes related component which is going to be similar to the Mir.ru.cubernetes component but it will be I think called mimiral alerts. Kubernetes and it would be looking for alert manager CRDs combining them um not alert manager CDs alert manager config CDs combining them into one and sending them to the mirror alert manager to configure the mirror alert manager end point and so when I saw uh Pet on the call I thought I'll check if the Kubernetes uh H charts have uh anything related at the moment uh just checked the docs and it seems like they currently don't have the mimia rules Kubernetes component. Yeah. So you're talking about the the Kubernetes monitoring Helm chart which myself and some other small small team writes uh which uses alloy just I'm setting context for the sake of the recording. Um the Kubernetes monitoring Helmchart uh right now does not use the Mamir rules components or anything like that. The perspective that we have is that the destinations that we set are all about where we send kind of active telemetry data. Um I haven't added anything in there related to rules or graphana dashboards for that matter. You know, we've had requests for you know alert rules and reporting rules and dashboards and all those sorts of things. My biggest concern is those are more like one-time configuration settings and I get concerned about if you have multiple Kubernetes clusters connected to the same backend you know mamir or graphanas and if you have different sets of rules on each of those you know trying to detangle race conditions or you know priorities and things like that. So at the moment we don't do anything with that. So uh the good news is if you make changes you're not stepping on any of my work. Um but uh but maybe there's a future in which you know we can look into doing something like that. Okay. Thank you. Yeah, that's good news for me too. I don't need to change the ham chat when I add the component. There you go. No, thanks for asking. I appreciate it. All right, maybe one more last call then. Any other takers? All right, thanks all for joining. We'll stop the recording here and again it'll be uploaded to YouTube in the next day or two.

