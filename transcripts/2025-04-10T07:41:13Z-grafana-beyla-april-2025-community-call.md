# Grafana Beyla April 2025 community call

Beyla community call of April 2025.

Published on 2025-04-10T07:41:13Z

URL: https://www.youtube.com/watch?v=ztG32l5qWhw

Transcript: nice recording Welcome to this April 2025 Graphana community call So is there any topic you you would like to discuss i've seen you active lately uh PR and Thomas Uh so we I I guess you both would like to or have any topic to discuss Whoever wants to go first I will go first Okay I mean since I completely started last week uh new with Baylor I did have some uh issues with the documentation Uh specifically um the structure so like all the options are documented and they're quite well documented actually Uh but I was having issues pointing um each section into a specific location in the Yammer configuration and I had to go back to the source code to actually look how the configuration structure is looking and I thought maybe adding a full configuration with all the options would be a good help for new users So they like the full configuration there and can just go look ah where is it placed how should it be and maybe add a few comments in there uh that that would be for everyone who does not know how it actually looks like a great help I think Mhm Yeah Actually it will be very far uh useful I guess like in other projects that you mean getting the whole uh the whole configuration sample with comments right uh like with helm charts like in in helm charts you usually have everything commented out but you have the full configuration available and to have that also on on the graphana website I mean yeah to totally makes total sense Yeah Mhm Mhm Mhm Yeah I think it's a very good idea That's just something I noticed and like past week and maybe had it six seven times where I thought "Oh where is it not supposed to go?" And and I had to really go dig in the source code and figure it out Yeah Yeah You're right You're right uh documentation we are we are improving it steadily but there are still many many parts to improve so yeah your your input is very welcome Mhm Mhm And the second thing I guess was the one I sent you before which I just created uh about the service name and I put a small example there specifically thinking now uh actually about the helm charts provided by graphana like you have the tempo distributed locally distributed mimia distributed and when you're using those helm charts with bail uh every component has the same service name so you're losing all of the service graph and and linking up between the because the service name is the same for everything Yeah Yeah Uh I will need to look in detail in into the into the chart uh because I guess the chart is not h is not setting h the same uh okay in bail now we are uh in bail now we are using if you don't set [Music] the if you don't set the the labels the open telemetry or kubernetes labels for the service name ba will take the owner name uh service name so probably if a deployment If if Loki is deploy for example distributed Loki is deployed as a single deployment all the pots will be named as you mentioned with the same uh will be named with the with the same service name So yeah that's right So my advice will be and I guess it does this is possible uh to set different uh my advice will be to send different different uh labels or specific labels for each of the helm components I guess I get that that this is something that should be improved at the tempo site or or loy site On the other side it's true that having more flexibility to to set or to add extra to add extra fields to the service name will be will be helpful I wouldn't say the pot name because at the end the pot name is just deployment name with some gish but being able to attach container name or some prefix Yeah that I'm specifically thinking about the component uh because you have in the like the helm charts are using the the field already component So you have to distribute the inest uh whatever I wrote there else uh as a component label So it's probably already enough to take the name and attach the component to it and then you already get the get the service graph correctly I believe Yeah Yeah Yeah Yeah Mhm Mhm Yeah Something we we we we can I think you you already submitted a a feature request right yeah Yeah Yeah I think it's something we can we can evaluate Yeah The Yes Like taking a a given label Yeah In also also we should see if if there is something that could be improved not not only for baila but for other for other instrumentation is only that could be improved in the in the tempo distributed or loy distributed helm charts Yeah we will we will see if there's something can be improved there to to be able to to not get this uh unique name for all the for all the components whatever you are using not only but other instrumentation Mhm Yeah So any comment from any other comment from Grafana about that or you want more context about the the issue the discussion i'm good Yeah me too I know that you have one actually outstanding issue that I was looking for for Thomas about the the nesting for PHP FPM events There seems to be still seems to be some bug Uh but Thomas sent me the logs so I should be able to look at it right in the the min Cool So yeah any other topic to discuss thomas um I do not have any like feature suggestion as of now but I just wanted to bring this to team's attention that I have picked a feature to implement I'm comparatively very new to the project itself but uh like I'm running through the codebase and uh I'll just drop the link and uh I had a few questions but they were answered in Slack so I'm not like blocked I'm currently working on the PR but yeah I just wanted to talk about this like yeah I'm talking about Yeah Right Mhm It is about uh like being able to see HTTP request headers in the like traces that are being collected by the EBPF collectors So like initially we were only working with trace parent headers but now we uh like there's a feature request that uh it would be nice if we could see content type or user like user agent headers in the spans So I'm currently working on implementing it somehow So um In Slack I asked a question about the size of these headers because uh unlike trace parent headers size of these headers is like variable It's not fixed by the specification So uh and Nicola replied that u I should start with like 128 characters to begin with and see how like how it pans out So yeah I actually have a comment to that um because we are using PHP debug bar and that is getting crazy at some point where it's adding headers like with 8K 16K and more in the in the response specifically So it doesn't but do you want those no I would not want those anyway It's just it's just an issue which we had uh that engineix can't process them in the backwards way and the request fails So I know it's happening not that uh like BA will fail with correlation of towards extent Yeah Should we um make the list of headers configurable like a filter so it just picks up the headers you specified instead would that be a middle ground no compromise Yeah it's going to be hard to implement Oh actually no Since we're doing it in user space maybe doesn't then it's going to be filter I guess we are storing all of them in EVP and then filter them in in user space right uh is this is this how we're going to go about it i mean I I haven't seen the issue before Uh yeah I I I have some [Music] some questions about how how does affect memory of our internal VPF maps because currently we are only storing transparent But if we store all the headers of all the requests or responses uh how that could be affect the internal memory and also whether we should ask or add new cleanup mechanisms just to avoid that keeps growing and growing Yeah Uh that's super valid point in my opinion and um if you think if you think about we need to have I don't know like I I don't know partic have you thought of how how you're implementing this So the initial plan was to like collect the headers in the the EVPS space like kernel space and filter it out in the user space but like the concern is actually like real because it will affect the memory because all the headers will be written on the rain buffer and it'll be too much Yeah So maybe I mean my first this is a good feeling only Um the way I would approach this would be to try to get the headers in in the BPF uh first like scan the the the headers and see extract what we want But that has the downside or the flip side that this is expensive because we're just like we place the transparent header we're going to have to do some kind of magic there It gets a little bit more complicated So person from my from where I'm standing only Um I don't know the answer to that I I if I were to approach this I would probably try to do both and compare them and and have to measure an actual data instead of uh just uh you know guessing Obviously we have a good feeling and Mario has and you guys have particular point I mean if you're shipping all of these you're going to fill in the rig buffer Uh there's also all the latency of copying from kernel space into user space that's gonna also cause CPU issues So if I were to take a wild guess I would still think that doing it in the BPF might be slightly faster just because you don't have this context switch from kernel space to user space the coping to ring buff But but uh I I can't I can't say that without measuring No but it can't be it won't be easy because first of all like for for go we're fine but for non-go we have to have BP of loop and then you have to do this pattern matching and then copying and storing into some additional buffers like extracting things like and at the end of the day you still have to ship them to user space and majority of stuff is just going to be pairs of these buffers and then if you ever create a list then it's even more complicated Now for every list you create you have to go check this map of is this header allowed then you go and keep on doing um but if people don't put a list of required and they say everything you're still going to copy all the memory to user space You're just going to do the walk in EVPF I I was thinking more of of having like a hashmap where is header allow As I said once you I'm thinking of HTTP requests right uh let's say outgoing the same way that we write phase parent on some sort of sock message program or egress when the same way we scan for the for the boundary for where to write and extend the packet I would scan for the column and then have a view You're not copying memory right you just have a view on that actual packet memory and and use that as a map key Maybe you do need to cop the key I don't know Uh and then okay this is allowed Then you find this the the end of line and cop copy the data and then you do that for each line of the the headers until you find the the end of HTTP headers But there's problems with that As you're saying there's also problems if you have a header with a big uh string and then you're trading everything So it's it's a it's a difficult problem I don't know the answer like that's what I said I think maybe maybe the easiest is to just store them in a map and then query the map straight up from user space like uh we have a unique key maybe by the connection and then uh once the event comes on the ring buffer we hit a map say do we have headers for it then we pull it in or something like that maybe Yeah Yeah So then we don't pollute the ring buffer we just uh store the map the memory and then we pull it out If there's headers there's headers If there's not Okay So like just to be clear it's like suggesting that we create a new map Yeah Just for the headers and then we can like query it on the user space depending on what the headers user selected Yeah Yeah And that Yeah And that way it would be easy to disable if people don't want it They don't want to pay the extra overhead of parsing the errors Um yeah I mean just say don't do this part I'm not too convinced on that But yeah I think ultimately yeah we got to try it Try and see how it goes right uh Yeah I think pricing eBPF would be faster if people wanted one header out of the 20 But if they wanted all headers oh yeah which is what some of the other products you know closed source do out there uh which they they capture as many headers Then you copy the memory no matter what So then in that case it's much better to do it in user space user space We can write tests Uh we can provide that the logic for parsing the headers is all there And um mind you we used to have this feature in the past where we would say copy the request buffer So we would grab the whole request buffer We would go and we will push it on a ring buffer Um we disabled it because it was too expensive but we used to grab a much bigger chunk of memory than the uh than what we do today It was like if you ran that on anything that was uh like I don't know even a little bit more serious it would just ALS CPU would grow up pretty significantly How much did you copy did you copy the whole HTTP request or just the first eight K i think we did the first K actually Um okay And even that was I mean you can clearly see the overhead and I just I don't know I think there's still some remnants maybe in the code of that existing there or some comments being left around for that unless we clean them up But uh there used to be so that was pretty much just copying the I'm not talking about the go side which is what you're doing but um I was talking about the other the the the other applications in that case we were just uh um sending all the data to user space and then parsing it there Mhm There is another thing to bear in mind as well That's why it's going to be important to really measure this uh for doing this into like regardless regardless uh of the approach We still need to find the headers and copy if everything right into a map right that's what you suggesting right you find the head No I'm just saying we don't even bother with that We just copy the start of the request It doesn't have to be the headers We we grab the URL and it go up to 1K and just let it be if some where where is that like TC like K probes like that's I guess that's what I'm asking because okay K probes might be better because if you do this in like suck message you have RTC you have to pull you need to do this you need to pull the whole thing and once I measured it the the BPF pull data that is it's very slow it's very very very very slow like so the SKB read and store load bikes and store bikes is is much faster in that regard So anyhow bottom line is we got to measure like try it prototype and measure and see what comes out of it So firstly I should try the ring approach and then map like map approach as well What are we trying to compare i think I mean either way is fine if you write the initial approach with ring buffer that's okay and then we can we can optimize from there whatever is easiest for you Mhm Yeah Okay Okay Nice Any other topic to discuss hotel donation repo I can I can do a status report uh on on the donation uh even if many of you already know it Uh we we got a due diligence We accept all the terms of that due diligence and last week in in CubeCon talking with some hotel community members they asked us to start moving the code to a new repository under the open telemetry umbrella and start doing there all the refactors that are are required Uh probably we need to remove some we will need to remove some features Uh so probably we will need to keep those features those remove features in the graphana avail repository and link the code in the other repository maybe as a as a library We have uh asked already for a for a for a new repository Uh we will need to get uh we will let me share the petition here We will need to get uh the repository done the approval So I guess this is in in process I created an issue sharing here and also pasting in the in the minutes There are some some aspects uh that we will need to be careful I guess that is it is unavoidable that during some period both repositories will will diverge and run in parallel For example doing some refactories on on one reposi in the old repository while the bail repository is still adding new features and back fixes that at some point will need to to be ported We should manage to make this period as short as possible But there is still some some risk there of duplicating efforts diverging to to code bases Any other topic so if not maybe we can close this community call Yeah Thanks you guys for joining Yeah Thank you a lot for joining and also for contributing It's much appreciated Yeah Good morning Mar Yeah Cool Uh have a nice evening or day Yeah Okay See you everyone Bye Bye Bye See you

