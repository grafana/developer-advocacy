# Logging Best Practices (Grafana â¤ï¸â€ðŸ”¥ OpenTelemetry Community Call)

Published on 2025-12-18T07:17:55Z

## Description

We're back with a new Grafana â¤ï¸â€  OpenTelemetry Community Call episode, and this time we're diving into logging with ...

URL: https://www.youtube.com/watch?v=D-bWeY-gBWU

## Summary

In the third episode of the "Grafana Loves Fireheart" community call, hosted by Ludmilla, the discussion centered around logging in the context of OpenTelemetry and its evolving landscape. Key participants included Jack Berg, an OpenTelemetry Technical Committee member, Ed, who has been instrumental in building Loki at Grafana, and Nicole Vanderhoeven, a performance engineer and developer advocate at Grafana. The conversation explored the importance of logs as a fundamental observability signal, the challenges of logging practices, and the integration of structured logs within the OpenTelemetry framework. The panelists emphasized the need for intentionality in logging, the significance of maintaining a balance between human-readable outputs and structured data, and the potential pitfalls of treating logs and metrics interchangeably. The session concluded with a call to action for community feedback on future topics and a reminder of the importance of thoughtful logging practices.

## Chapters

Here are the key moments from the livestream along with their timestamps:

00:00:00 Introductions and Overview of the Call
00:02:10 Guest Introductions: Jack, Ed, and Nicole
00:05:00 Announcements: OpenTelemetry Unplugged Conference and Observability Survey
00:08:30 Discussion on the Future of Logging in 2025
00:20:00 The Importance of Logs as an Observability Signal
00:28:15 Debate on Zero Duration Spans vs. Logs
00:35:00 Discussion on Logging APIs and OpenTelemetry's Approach
00:45:00 Tips for Effective Logging Practices
00:55:30 Audience Questions: Logs vs. Metrics vs. Traces
01:05:00 Closing Remarks and Final Thoughts

# Grafana Loves Fireheart: Episode 3 - Logging

Okay, hi everyone! We are back with our Grafana loves Fireheart community call. Today marks our third episode, and weâ€™re going to talk about all things logging. If you have questions about logging, feel free to post them in the chat on YouTubeâ€”we're happy to hear them!

There are so many aspects surrounding logging. Logging is something everyone is familiar with; it has been around for about 30 years, and everyone does it in their own different way. Today, weâ€™re exploring how people handle logging in 2025 and how they integrate it with OpenTelemetry.

### Introductions

We have some great folks here who are deeply involved with logging.

- **Jack Berg**: Jack is an OpenTelemetry Technical Committee member and has been involved with the OpenTelemetry project for over five years, particularly in the logging space. He is also a maintainer for the OpenTelemetry Java project.
- **Ed**: Ed works on Loki at Grafana and has been building it for nearly seven years. He has gained considerable expertise in logging during this time and looks forward to sharing best practices.
- **Nicole Vanderhovven**: Nicole is a performance engineer and a developer advocate at Grafana. She has also been working on Loki and is here to learn about all things OpenTelemetry.

### Announcements

Before we dive into our discussion, here are a few quick announcements:

- If you're interested in talking with OpenTelemetry folks, join the OpenTelemetry Unplugged conference happening alongside FOSDEM. We would love to see you there!
- We are launching an observability survey and would greatly appreciate your feedback on the current state of observability.

Additionally, the Call for Papers (CFP) is open for speaking at Grafana 2026, along with submissions for the Golden Grail Awards. This is a competition for cool dashboards, including non-business-related ones, so if you've worked on something for your home lab, consider sharing it!

### Logging in 2025

Now, letâ€™s discuss logging in 2025. With the evolution of observabilityâ€”moving from observability 1.0 to 2.0 and now approaching 3.0â€”what role does logging play?

**Ed's Perspective**: Logs are the only true observability signal. They provide the most accessible way for anyone writing software to gain insights into application behavior. Although metrics and traces are also important, logging remains fundamental.

**Nicole's Input**: Many people already have established ways of handling logs, so with OpenTelemetry entering the market, the question is why they should change their existing practices. The challenge is integrating logging into a broader observability strategy while ensuring logs remain useful and accessible.

### The Role of Logs vs. Metrics and Traces

**Jack**: Logs, metrics, and traces serve different purposes. For instance, logs can capture high cardinality data that metrics may struggle with. Metrics are often optimized for performance and usage patterns, while logs provide detailed context for debugging.

**Ed**: Traces can provide insights into the lifecycle of requests and how they traverse through services, while logs can capture detailed error messages and contextual information that may not be feasible to represent as metrics.

### Best Practices for Logging

1. **Be Intentional**: When writing logs, consider who the audience isâ€”humans or machinesâ€”and what information is necessary.
2. **Structure Your Logs**: Use structured logging with key-value pairs to enhance accessibility and querying.
3. **Log Errors Intentionally**: Ensure that error messages are actionable and provide clues for resolution.

### Q&A Session

During our discussion, we received several questions:

- **Using OpenTelemetry with Existing Systems**: How does OpenTelemetry interact with existing logging frameworks?
- **Centralized Logging vs. Local Storage**: Should you log directly to a centralized system or to local files? Both approaches have pros and cons.

### Conclusion

As we wrap up, we encourage everyone to think critically about their logging practices. Logging is an essential part of observability, and being deliberate about how logs are structured and used can greatly enhance their effectiveness.

Thank you all for joining us today! If you have suggestions for future topics or specific questions you'd like us to cover, please let us know in the comments. Happy holidays and see you at Grafana 2026!

## Raw YouTube Transcript

Okay. Hi everyone. We are back with our Graphana loves Fireheart up on telemetry uh community call. Today it's our third episode. We're going to talk about all things logging. And if you have questions about logging, come join us on YouTube. Uh you well, you're already here. You can post your questions in the chat. We'll be happy to hear them. Um there are so many things around login. login is the thing everybody's familiar with. It's been there for like 30 years and everybody does it in their own different way. So here we are trying to figure out how people do this in 2025 and uh what they do with login, how they work with login and open telemetry out of open telemetry world. And here we have uh some great folks who are very deeply involved with logging. Um I'm going to start with Jack uh who is open telemetry TC member. Jack, do you want to introduce yourself? >> Yeah, thanks Ludm Miller. Uh I'm Jack Berg. Uh I joined Graphana somewhat recently. So I'm new to Graphfana, but I'm not new to logging or to open telemetry. I've been involved with the open telemetry project for um over five years and specifically in the log signal. I've done a lot of things with that. uh discussed it, argued about it, all the things. Uh I'm a member of the or a maintainer for the open telemetry Java project and I'm a member of the technical committee. So back to you Ludma. [snorts] >> Yeah. And another awesome guest we have is Ed. Ed works on luck at Graphana. Ed, do you want to talk uh and introduce yourself? >> Absolutely. So, uh, yeah, I've been at CRFunnel Labs for I think my seven-year anniversary is in January, and I've been basically building Loki that entire time. So, um, I didn't start my career in logging, but I I am certainly I feel like I've become an expert hopefully over the last seven years or so and, uh, you know, looking forward to to talking about, uh, maybe some best practices from some of the things we've seen over the years. So, thanks, Lia. >> Yeah, thank you. It's exciting to have the back end representative along with open telemetry representative here. And Nicole, I I think people know you, but please introduce yourself. And you're also not not Yeah, you're also not a guest in the logs world. >> Yeah. Hi, I'm Nicole Vanderhovven. I'm here because Ludmela asked and I said yes because I like her. Um, [clears throat] I I just passed my 5-year anniversary at Graphfana, so I'm waiting for my 5-year swag. I am um a performance engineer, but I've been a developer advocate at Graphfana, and I've been working on Loki, which is why I'm here. I'm here to talk about logging, and I'm learning about all things open telemetry. >> Awesome. And before we get going, uh we would like to make a few announcements. Uh quick ones first. Please if you're interested in talking to open telemetry people uh go join the hotel unplugged conference. It's on along with Fosdom. If you're in Fosdam go register for open telemetry unplugged. We'd love to see you there. Um and the other one is we have observability survey coming out. Uh we'd love to hear your thoughts on the state of observability world. Uh and would really appreciate your feedback there. Um with this um okay >> I have an announcement as well. >> Oh great. I wanted to call out that the CFP is open for for speaking at Grafana 2026 and also for submitting Golden for the Golden Grat awards. The Golden Grat awards are like this the it's a competition basically for cool dashboards and it doesn't have to be like a business related one. There's also a category for just cool personal fun dashboards. So that's a that's a great way to to get your work recognized. If you've been working on something that's just for your home lab, like share it with other people. And I also wanted to say that Graphonic is very adamantly um really for new community members to speak if they want to. Like we do a lot to try to help you get ready for your presentations. like if you if you're accepted as a speaker, we will give you the help that you need for like dress rehearsals and technical input or or like input on on how you deliver it. Like the developer advocacy team in particular has been roped into um giving a lot of of hands-on in one-on-one help for that. So don't feel like you have to already be an accomplished speaker to speak here. This is one of the best places to speak at for a newbie. So, please consider speaking if you think you have something to say that you'd like to share with the world. Yay. So, speaking about speaking, now it's time to speak about logs. Um so it's 2025 and we've gone through I don't know observability monitoring observability 2 observability 3 is is there a place in current in 2025 for logs and what this place could be and maybe I will put ad on the spot. What do you think? >> Uh, so I'm going to folks that that don't know me, sorry, because I I'm going to I just like to have a little bit of fun because, you know, maybe my opinion being biased here. I I feel like logs are the only true observability signal and, you know, that's just kind of unlikely to to really ever change. And so I I'll say the reason I make that comment is that it's it's the most accessible way that anyone writing software has to get any insight into what their application is doing, right? Like a hello world app is the first thing you ever write. And that's a log statement. And this is how most people build software, right? Like in in real terms is you use log statements to understand if it's working, if it's not working. Um we definitely come a long way from that. You can definitely do better than that, right? Like my argument here wouldn't be that you shouldn't use traces or metrics. You absolutely should. Uh but I don't think you ever escape logging and I don't think it ever really sort of goes away. >> Yeah. I think one of the problems is that because it's so ubiquitous and because it's one of the it's probably the first telemetry signal that people come across that they already usually have some way of handling their logs. And so now that open telemetry is on in on the horizon well in in the market they're like why should we why should we change what we're already doing? We already have a way to do this. Why do we suddenly have to care about semantic conventions and what why do we even need to have our logs um have anything to do with hotel? Well, just to get a little low level here, like I was just thinking about ad statement like maybe it's the the one true observability statement like you know can you imagine running a process without standard out and standard error like you can't get rid of logs because you know they're they're they're fundamental to running processes. So um even if your applications are doing something more fancy the logs are still going to be involved and so they have to be part of your uh observability strategy. And I guess a question for Lud Miller. So, uh I know we you and I went back on and forth on this in a while in different contexts, but like what do you think about zero duration spans? >> Oh, it's fun. So there are a lot of things that we uh try to to model as spans or as logs and we have a lot of conversations in the ecosystem and open telemetry ecosystem and like what what would you capture where uh and zero duration spans is something people used to record logs as spans. So in the past people recorded spans as logs now they record logs as spans. Uh and I think there are some reasons why people do this and I hope we can solve it but I I I don't support >> yeah that's it was kind of a leading question right so you know if if logs don't have a purpose then that means you have to kind of replace them with with spans and you know spans are hierarchical spans have a duration um so you know uh you can maybe fit a square peg into a round hole with that you can maybe make your spans kind of look like logish um but That's to me always the smell. If they have zero duration, uh they're probably a log. If they're not hierarchical, they're probably a log. >> So, I'll I'll ask a question here that I feel like uh only from a distance I think is controversial, but like isn't this what an event on a span is? Isn't that what a a log line is sort of characterized as? >> Oh, spa span events and logs in open telemetry are sort of one and the same. So, it's just like different vocabulary for the same thing. But you don't need to spend to log something, right? You shouldn't need a span to log your configuration error before you have any spans. >> Yeah. And I mean, if you really want to debate semantics, I think like when I had Joe Elliot on on this channel on a graphana office hours to talk about tempo, he said he said that logs he said that traces are just like struct structured logs. So when it comes down to it, it's just logs formatted a little bit differently. But I mean it kind of depends how you define it, right? Because still I think it's useful to define traces as their own thing that have different requirements for storing them and processing them and also slightly different use cases. I'm totally with you Lud Millow by the way that that like I I think there should be a difference. I I don't think we should create logs in span in traces or spans. Um and I also don't believe and you know we're getting into the the the three tips that we all have. I don't know if you want to jump into it or or talk a little bit more generally. >> I would have a a I think and this might be awkward to say for somebody that builds a logs database. Although I think I think tracing is a supererset of logs. I think you could entirely run an application entirely on traces with no logs. Um reasons we don't usually do that are um you know logs are like sort of traces are logs that have more bytes associated with them. So they're they're I guess in a way by default somewhat more expensive right so they they have you know some amount of additional data like is it I don't know is it important right does it matter like it certainly can right and so so traces are almost always sampled like from the get-go there's this understanding that they have some sampling associated with them which you know often then precludes them for a lot of the use cases that logs are for where you you know sort of don't want missing events you know you need to sort of reconstruct a sequence of events or you need an error message or things that you don't want, you know, randomly dropped. Um, however, I do think you, you know, could effectively do everything you would do with logs with traces, although the tooling I think has evolved to be sort of slightly different in how you sort of access things and search things or whatever. So, so there might be some nuance there that that would lead you to, you know, not completely abandon your logs. But add no the lines are being blurred between you know sampling and uh you know the log equivalent maybe it's called filtering where you know with with logs you do the equivalent by uh specifying thresholds severity thresholds for each logger um maybe there's other filters as well that can be sort of like um uh like rate limiting type uh type things but uh you know so okay you can still do filtering sampling things with logs that's inherent parent in it. And with with spans, spans are getting some of that more deterministic sampling with in open telemetry with uh this sort of sampling 2.0 API that is uh evolving right now where you can set up deterministic rules to dictate which of your spans are included and thrown away. So it's not just flipping a coin. So uh yeah, spans are getting more like logs. And and honestly that would be so so Loki itself is a is a you know a parallel essentially gains performance through parallelization and the result of that is that um it's actually hard for us to use traces. It's not uncommon for a query in Loki to generate between say 500,000 and 5 million spans. So that's a lot to ask for our tracing database which is very good at what it does. And so we uh you know like the reality of that though is that's 30 40,000 sub queries that all were uneventful and uninteresting and like you know two things. One is like if there was the concept of debug level spans we would just turn a lot of them off most of the time. Um >> oh should we you know >> this this is the the title theme for a different call but yeah there are discussions. [laughter] So there's that option. But what's actually what I want is I want to know what spans are different, right? Like like if there were 50,000 spans that all executed in 3 milliseconds, I want to know the one that took 50 milliseconds or 10 seconds, right? Like like that's what I'm you know it's it's not so much like hiding debug. And you could argue this would be true for the sort of limitations of log level granularity in logs too, right? like like you know debug log lines are mostly not interesting until they are right and then you get this very binary like on or off and and the volume associated with that is is typically massive right like the you know and so having you know I guess concepts around like interesting things is more like valuable than level right >> maybe we could >> yeah go ahead >> maybe we can answer this um question that we got from USANET.io who asks, "Are you working with the Open Shift team? They've started using Loki and Tempo as an observability stack. What are your thoughts on this?" >> I think it's amazing. I'm excited about it. Um, I have some some folks we've worked with over the years uh on the Open Shift team around when they were uh sort of setting up and using Loki. Um, but no, I mean, unsurprisingly, the guy that works on Loki is excited that people are using Loki. >> But I also think that uh, you know, this person doesn't mention Open Telemetry in particular, but that only makes sense because both of those products use Open Telemetry. The reason that open shift can choose something that is by a vendor is because um it's it's a vote of confidence that they believe that we are open telemetry compatible and so it doesn't really matter whether they're using our stuff or somebody else's stuff otherwise it's really locking them in right so that I think in in a roundabout way that is one of the reasons why it's important to still bring logging into hotel because hotel is it sets the standards not just for logging but just telemetry in general. And if if you are building a system now and you're not um and you're not trying to plan for that to be open telemetry compatible, I think I think that it's worth reconsidering because um it kind of locks you into a particular approach. >> Do you two agree with that? >> Sorry. Yeah, maybe this is the the broad question like there are so many login frameworks that don't block you into any specific uh solution like there is Python login there are like five different APIs in Java and maybe 10 in JavaScript and a couple inn net and a few in go like there people already have a solution for to writing their logs console std out uh some login management systems provide appenders to ingest into I don't know graphana lockis plunk or something uh with scrape cube kubernetes pod logs what why do we want open telemetry to also provide login API and I'm going to put a spot on Jack here >> oh boy um yeah why does why does open telemetry want a logging API when there's such a rich ecosystem that already exists um why why reinvent the wheel. Uh so open telemetry I think has to walk a tight rope with logging as compared to the other signals. Um because such a big part of it is interoperability with existing tooling. Uh it's not realistic to ask an application to say like hey like put down all of your logging tools and pick up the one true logging tool. That's that's nonsense. Um and so uh yeah when when open telemetry logging started it was uh the goal was only interoperability and we had this thing called the log bridge API that's what we were calling it at the time and its express purpose was just for bridging other log ecosystems into open telemetry. So we didn't want to we didn't want to compete with them. We just wanted to be able to consume those logs and you know be able to emit them to a network location over OTLP. And uh the story has kind of shifted that once uh bridge API is being promoted to being a userfacing API. And so we uh we we we want the ability to tell users like hey you have one open telemetry API that you can use for logs, metrics and traces. Not an open telemetry API that you use for traces and metrics and you use some other thing for logs. Um and uh so so that that's part of the reason is we want to have a kind of coherent complete picture for uh you know one API to do all your observability things. Um and the other part of it is open telemetry as a project has has gotten opinionated about uh what logs ought to look like. you know, we have an interoperability story that uh you know uh supports all the different ways that logs have been you know produced over the years from just simple strings to structured logs. Uh but open telemetry's vision for the you know what logs ought to look like into in the future and there's going to be a long tale for this. So we don't expect this to change overnight or even in 5 years. But uh open telemetry wants all logs to have a a type or a uh a classification of of the the the event name of what happened. And we want all logs to be structured. Um, and so by crafting our own API instead of just leveraging existing APIs, we can kind of take away the foot gun and make it hard to do easy to do the right thing and hard to do the wrong thing. And so that's what open telemetry's log API will be structured to do. Uh, so yeah, >> I'm kind of curious what Ed and Nicole think about it because we in open up telemetry world, me and Jack, we had tons of discussions on this and sometimes I feel like uh what we come up with like we're building the maybe the future as we see it in open telemetry, but what is the rest of the community like people who are not participating in every of this discussions think? Um, so there's there's kind of I I'll mention briefly. So Jack mentioned one piece of like the logging pipeline which is >> almost the like physical nature of like how you get logs from a place to be A to B and and uh I think open telemetry stands to like standardize that a bit which just makes life easier for you know the sort of network operators and u you know infrastructure operators out there but it's it's also kind of like not the part I want to talk more about because it's still like largely we still capture log lines from files in weird ways, you know, like there's still like very little improvement on and and there's some nice aspects of that too. you basically get a little write ahead log, you know, for for So anyway, the that part is a separate story, but the part that I think has more interest in maybe for the folks that are going to hopefully be watching this is um you know, the idea of having a a a standards and opinions on like how you should do this because it's it's basically my experience after you know running Loki for the thousands of customers now for many years that like everybody does this in their own way and differently And when I talk to customers, one of the reasons they like Otel is because it it it's a place they can go look to say, here's how the industry is sort of converging on how we should do this. Um, and it answers that question of like, did we do something, you know, the right way or the wrong way? Like if we have trouble or those like, you know, industry troubles, like there's always going to be things that are difficult about this. Um so having you know some opinions on how to you know like you mentioned structure like what does that really mean right like metadata like I do think that the when we get into the details of this like there'll be differing opinions on on what that should all look like but at least we're sort of converging on some standard that you know it allows you know sort of companies to sort of benchmark themselves against the industry and each other and you know hopefully gets us into a world someday today where um you know I think one of the hard parts about running a logging database is it's just the sort of garbage dump of databases right so like can we get to a a world where like that's not true you know like where we have some consistency to to make just to make it easier to make these databases easier to run and more affordable >> yeah I mean I I agree with you all I I think I really love the idea of you know not needing structured logs and and having a database like Loki that can just accept everything in whatever standard and in whatever structure it is or maybe it's semistructured or whatever. I love the freedom of that. And then I and then you actually reuse it in anger and it's like, you know, even if it's just me, even if I'm not even working with anybody else, it's like, oh, I I talk about things in different ways in different places, like just as me. Now, imagine that. Multiply that um by, you know, a few like a dozen developers and and over several services and it's it gets very quickly out of hand. And then what happens if those people leave and then new people have to pick up where they left off? And it's like, yeah, at some point, you know, there's like a tipping point where beyond a certain amount of logs, uh, you just want some structure. you agree as a team first or as a company, but you know, it's actually better if you agree as a community, you know, so it's across everything. And it doesn't matter which job or team you're at. Like it would it's I think it's un an unfortunate compromise that I'm still willing to make to to have more structured logging. Still nice that Loki can accept unstructured stuff, though. I I also wanted to raise a question that's that came up. Um, Apest says that they're brand new to OTEL, but they're a big user of logs generated via SIS log. Where does OTEL logging land in comparison to SIS log standards for logging? >> So, I can take that, I suppose. Um so uh like I talked about at the hotel logging API level um you know the hotel logging API was originally designed for interoperability and that's true across um you know all sort of open telemetry components with logs and uh so a big component in the hotel ecosystem is this thing called the collector sort of a highly configurable and uh customizable ETL pipeline for your telemetry data and it has a it's arranged into uh a series of components that are called uh receivers and processors and exporters and um and one of these receivers which you you know you arrange into pipelines is is a SIS log receiver and so you can configure SIS log to point to this and uh the SIS log receiver will take care of interpreting you know the SIS log protocol and converting that data to the the open telemetry log data I can include a link to that I think. Um but >> yeah that would be great. >> I wanted to maybe uh raise this question uh for to add uh or Nicole uh should you have a single loyb for all environments or separate instance and how to deal with the latency uh for dev? Do you have any recommendation? >> Um, like if you're running Loki yourself, then I would probably run a separate instance for each environment. So then you also have, you know, environments that you can use to do change testing and roll out testing and things, right? So you you run your devloki instance and then you can upgrade that first and, you know, look for for troubles there. Um, you Yeah. Uh so so within a single instance if you wanted to do retention you can doesn't have to be done on multi-tenency like you can configure streambased retention um you know multi-tenency is nice because it gives you some isolation against I don't know mistakes people might make ing inest or um just some better separation of of data like so those are sort of both ways so you don't have to do it that way um you know you could run one loi instance for all your environments um you know you just got to kind of understand your kind of eggs in one basket problem then, right, if you need to test a change. So, you could consider maybe having like two instead of one to match all your environments or something like that. But I don't have any super strong opinions there. Maybe just maps a little bit better to like how you're running and doing your rollouts. >> Yeah, I think it's a good idea to start out with as simple a setup as you can get away with and then meta monitor Loki. Um, I don't think I I wouldn't suggest like just having another a new Loki instance for every environment just just because with no with no data. I would see first like is that Loki instance actually struggling? Maybe, maybe it won't. It really depends on on your usage. So, I would give it a go with one and then and then be prepared to increase it. Um, there's really like you can start with one and then still add more later. you're not locked into one approach or the other. >> I was thinking maybe um it's time for a little demo to make our login discussion a little bit more specific. >> So I Okay, cool. So I have Python application. Excuse my Python, but that's the language of the world. Uh so I wanted to show how there are different ways to write logs and everybody does them in a slightly different manner and ad mentioned print and no don't do this please uh but let's let's go through the code. So we have a few uh different ways here. First one is we use Python logging here and we format a string. This is probably the worst way. Well, better than print but still uh your formatting string right away. You don't get any performance optimizations. Your login framework cannot would never see the specific property that you are logging. You it would only see the whole string. We are fixing it here slightly. Right? This is probably what people normally do with login frameworks. This is the golden pass of the login. You provide a placeholder. It could be named or positional. uh you provide a severity. If uh the severity is not enabled, then nothing happens. It's just ignored. You didn't waste any performance on string formatting or anything. Um the way like to make it more structured, the way you write structured logs and also get performance optimization is a little bit uh different, right? So you would check if log level is enabled and if it takes any effort to actually get this properties you wouldn't uh pay the cost if it's disabled then you put all your dynamic context u in some key value pairs that you can later on query or at least reliably grip right and what it means in practice that frequently your user friendly message becomes static. you no longer need any dynamic context. Uh and you can also identify this log record by this static message. So this is like halfway where we want it to be in hotel world and this is the the way we don't have a convenience API yet in Python but this is the way you can uh do this in in the open telemetry way you use it's the same extra as attributes here and you would put the attributes that are defined in semantic conventions open telemetry or your own you provide the severity number uh and you provide a thing called event name um that essentially is the same. It's instead of your human friendly log string you have an event name and it's globally well almost unique like right it's unique for your system you can identify any record using this so let's I have an application here that does it all and let's see how the output looks like um so the first two look pretty much the same right that's what we wanted uh and then Uh things got blurry. So this is the user says hello. This is this friend. So uh where is the context? It sucks like because things around login sucks. Uh the way we I configured my console output is super simple. It's the best practice. You would find it in any Python guide. It does not include the context. It only includes the message. And you would think it's easy to edit here. No, it's not. You need to write a bunch of custom code to actually make it happen properly. Um, and let's see how it looks like in loia, right? Um, it should be better. Uh, I'm sorry. Uh, I am going to switch to a different window and I completely lost it. Um, okay. Let's take a look at our application in Loki. Uh let's one more time. So we have some logs for our service and we see that there are this example one and example two uh and so you would imagine that example one this one um does not include much context. It does not include the fu or or pass route. All right. It still has some properties. It has span ID and trace ID. We'll take a look in a sec. It has some additional information about the code uh that executed it. Uh example two is identical. Let's take a look at the sorry user says hello. Uh there is structured metadata here. There is this end user ID that we set and there is HTTP route. Now let's take a look at the auto log. It's the weirdest one. It does not have log line at all. And I I wish we fell back to the event name here. We we could have done it uh and we should and it has all the same properties. It has f it has the uh route. Um we can we would query them differently, right? So the once with uh end user the structured ones we would query as this uh and we will get our obfiscated thing. Uh the ones that uh don't include the structured data we would query with something like this. This is the inclusion, right? It's just includes and it would find a bunch of different log records. Um, and some of them we can identify, others don't. So, this brings me to the question I want to raise to our guests and Nicole like there is obviously a trade-off between humans reading logs and structured logs. So, what do we do with it? I say both human we can add human readable things in a way that is still somewhat structured like define kind of like defining the part that isn't as structured and then only stick to that. Like don't try to put unstructured things in somewhere that is is expected to be structured. What what what types of unstructured things like going back to these examples like the unstructured part is like the the string like the hello world and I think what open telemetry would say is that like the parts that are unstructured are actually structured and you're not you're just not calling it that and like you know the hello world string is converted to an event name which you know is structured Um, yeah, I so I agree that that that's I think that just breaks down in the real world though. Like I think that's the trouble is you can um I think you could agree that if if people sat together and like looked at an application and looked at its log output that they could sort of come up with a way to you know turn messages into events and then have them be like a fixed number of events and uh you know make it an entirely like machine sort of readable in an easy way. But in practice like no one's ever going to do it, you know, like and and also like when you build applications like you just don't know that information at the time, right? Like you don't really know, you know, what you you know, like like some of that stuff comes with some hindsight after your thing exists. And so most uh log lines are created, you know, when someone was trying to debug the thing locally to get an answer and then they exist forever. um you know the the particular to me the most interesting ones here are most people I don't know maybe that's not true I shouldn't say most people but the a very large use case for logs is is trying to understand why something is broken and the information that you're looking for in those logs was written by a human in an unstructured way most of the time so so you'd have to kind of turn that into like something meaningful, which means like an event name that responds to an error, which then ties to some database that has a lookup of like, you know, whereas if we get to our pro tips or not, my my logging pro tip is is at least one of them is if if you write an error message in your log line, um, write it as such that you tell the person reading it what to do about the error because that odds are that person is you and you got paged and you go read that error message and instead of saying, you know, connection to database failed, you know, have it say like connection to database failed retrying, you know, or go look here. Like give yourself some idea of like what a human should do about the problem. Um, that's, you know, most of the time because like most error messages are being like really generic and really not helpful and like you could save yourself a lot of headache there. Um, so let me I covered a couple things there. Let me let me pause and >> Oh, that's great. I I think it's a good idea to to get into the the actual logging best practices, like concrete ones. Um that I I was surprised you you like disclaimed this so much beforehand that you were going to come out with some hot takes and I was like, "Okay, I'm ready to disagree." [laughter] >> But no, I totally agree with that. That's that's a really good one. >> Do you have a more controversial one? [laughter] Well, let's I mean we can start the So, so that one was interesting in this context because like there is this really fascinating sort of progression of like what like a log line really should be or you know how much of it is human readable and why and and so um I do think that's one of the sort of cases where human created log messages are still really relevant right like a lot of times when something you know you're writing software and you have to either force handle an exception or you have an error or something and you have to figure out what to do with it. Like most of the time what you do is you log an error message, right? Like you don't know what else to do with the thing, you log an error message. So like you have the most context in that moment of anybody about what someone should do with that error message. So put it in the in the in the log line, right? And that's still like a very human sort of interaction that you're going to be having with your kind of future self, you know, or some future version. Um the other major thing that we do with logs that that we kind of talk about there is like we just you know we communicate metrics right like we communicate status we communicate um you know performance or whatever right because like we you know we can put like infinite cardality in a log line right like you can have as many key value pairs with as many combinations of values as possible and they're an individual event tied to a thing. So they're really really useful for you know getting info out of your your you know in the same way that traces would be except you can also just save one log line that has like all this useful context in it and and that in itself is useful whereas the you know the trace is a bit different but so in those cases where it's like it's just key value pairs like ultimately a database if it's going to show you a time series of this like has to impart structure on it somewhere right like you know Loki does this today at at query time by parsing things. But if you do it when you write your app and you know that gets serialized in a structured way in in open telemetry attributes and it gets stored in a structured way in like a columner store like you've made everything sort of more performant right like so there's advantages to just doing that when you generate the stuff right it just then creates this interesting world of like you know what Lumia's example shows which is like if I'm viewing those log lines like you know if it's just all event data like maybe you would never view it that way anyway. way, right? Like you very typically want to look at all the key value pairs from an event, but sometimes you do, but you're usually more interested in a couple of them. Um, and you know, then there's this other case of like I'm just trying to understand what's going on with my application and like that's usually like me trying to find some human giving me a clue as to like where to go look. Ju >> just to dwell on something you were saying, Ed. Uh so because um you know you were making some good points earlier about like hey open telemetry has these opinions about um you know you know all logs should have an event name and should have attributes but that's not how people think. They they they just want to log something uh you know as a pointer to themselves or um you know because something happened and they needed to understand the state of their application to get some information out of it. And as I was like, you know, I was thinking about that in the context of Ludm Miller's example code and, you know, I was just looking at that. I was like, yeah, nobody's going to do this open telemetry, you know, version of it because it takes, you know, four times the number of lines to do it. And so the burden is on open telemetry to say, hey, if we're going to be opinionated about how logs ought to be, we need to have the the friction be competitive with what people are currently doing. And if if if not then people just aren't going to use this. >> Jack, could you give us uh like one of the Sorry leader, I was just gonna ask um if you wanted to give us a a tip, too, like one of one or what are the one of the three that you had picked out? >> Uh yeah. So, you know, like you know, one of my tips is, you know, to to use Open Telemetry's uh opinion opinions about what a log ought to be. Always have an event name. Always be structured. try to, you know, move away from the this sort of legacy historical just like strings. Um, but I guess, you know, I think that kind of goes without saying uh from from my perspective being an open telemetry person, but um I think a more potentially controversial uh take is, you know, when you have an application, you have the opportunity to get your logs to some sort of centralized system in in two main ways. You can have the application uh you know emit them directly over the network. Um or you can have the application you know log them to to standard out or to files and then have some sort of scraping solution which tails those and ingest them into the the central system and uh my opinion is like the uh you know do the direct you know emit directly from the application as long as you can get away with. So uh you know there's just a lot of benefits with having the application directly emit overl and uh you know context propagation is is is is seamless. You don't have to kind of jump through hoops to have embed like trace context into your your log strings which are being written to consoles or files and then kind of coordinate with whatever is interpreting those to you know rec rebuild the context from those strings. Um, and it's, you know, it's just overall just way too convenient to be able to, um, you know, have the application be self-contained in terms of all of its metrics, logs, and traces and be responsible for getting all of those to your, um, you know, your your backend for for what's going to process and store those. So, that's that's my take. I would um I would add one suggestion to that which is um have a a I guess a collector in in the middle of that that you control um >> like on on the same node >> like somewhere really close to >> well yeah so so the so the reason is that um we've seen many times over the years where a customer is is doing something that is terrible for them or us in probably usually an expensive way, right? And they won't fix it because they they can't make a production change on a cycle like they they have some cycle that defines when they can fix it and it it might be weeks. Um and so in most of those situations, those same folks also usually allow for reconfiguration of telemetry like collectors and middleware, right? So like they they would have the ability to stop logging 3 gigabytes a second of an error message at a collector but they have no ability to make any changes to the code that's running that's generating that. So so if you go directly from your app to your telemetry provider you you your hands are tied right and everybody's kind of grumpy. So like you know the you know there's like little nuance to this right because like some you know frameworks might let you make runtime configuration changes that would control stuff like that but I uh it usually runs into a change control process where they're just like we're unwilling to make any production changes and so this has to be fixed another way. >> Yeah I think that's good advice. Um you know I I wasn't trying to express an opinion on whether you should go direct to the vendor or your backend or to through like an intermediary processing pipeline. Um, you know, I was just being opinionated about like whether the application should be responsible for having a network connection that it's, you know, emitting logs over because, you know, there's performance implications for that. It is it is funny to use standard out in the year 2025 in my opinion like it it's it's the the you know like in a modern Kubernetes environment like you're you you still typically are writing to a file which is on the node disk which is typically like a very underperforming you know disc attached to that machine for no real purpose right and then you have you know sort of like a weird bottleneck that you might not even ever notice is happening or how you would debug that your logger is slowing your application down because it can't write to that disc fast enough, right? And like so there's all kinds of like interesting side effects of like you know like you said and then also like losing context and like so yeah like it does make me laugh a little bit sometimes that like a lot of logs are still captured in the same way that they've been for like 50 years when we could probably do better than that now >> and and to go on on that it's like you know if you've already accepted network connections for your metrics and traces like what's the hold out on logs >> right yeah >> I'd like to bring a question from the chat which is a great segue for for our discussion. Uh the question up uh sorry if I mispronounce your p name. Uh why should we use logs if we can use metrics instead? >> I I was reading this question and yeah this is this is a good question. Um why should you use spans or metrics or logs for anything? And you know each of these signals has different characteristics. you know, if you if you squint at them or you use them, you can kind of get away with using the wrong signal for the wrong use case. Uh, but you know, they excel at different things. And so, like just to kind of use a an example to prove where uh metrics would be wrong for logs would be like let's say you just want to like emit an event, a record that a user logged in and you just want to like say like, hey, this user logged in and this is their ID. If like you could use a metric that counted the number of times a user's logged in, but if you tried to have a dimension on that metric, which is the user's ID, you're going to have high cardality and you're going to explode your metric system. So, um yeah, like a lot of the things that you want to use logs for will end up being high cardality and thus not good candidates for for metrics. >> Go ahead. >> I have a similar thing where I was looking at it from the point of view of traces. One of the tips that I wanted to mention was don't use logs when you should be using traces. I think that a lot of people um abuse logs because they're so abusable because they take anything really. You can start if with a log and then get metrics from it and you know like yeah you can but should you like if you know you're going to want a metric you shouldn't be using you know something that's meant for logs that's only you know turning turning metrics turning a log into a metric or getting metrics from logs is like good in a pinch when you're like oh no I don't have any other data I have logs great you still can do that but if there's thing that there's a metric you know you're going to want to query a lot then consider a metrics database and in the same way I feel like there are a lot of people who who have logs that are really like request life cycle logs like received request call calling this service retrying request this request took whatever 123 milliseconds and it can be like you can certainly have that as a log but But I wonder if they have considered using traces instead because that kind of use case lends itself well to um seeing how much time um a request took per component per span. Like that's that's what traces are good for. it inherently um shows the the causality like it follows a transaction and if you're kind of asking questions about like where did it go or what happened just before that like maybe you should be looking at traces instead of logs and as a bonus tracing um and already has like it's designed for sampling right so like there's different types of sampling that you can do and um if you log everything like even the happy paths, even the ones that didn't have an error. It's like you're you're spending a lot of time on logs that say the same thing over and over. You know, do you really need absolutely every single one of those? Because I would argue in most cases, no. Um, I've put some thought into this and like I kind of changed my my message on it a little bit over time, but the um maybe one way I would describe metrics now is so so you you can do everything with with logs like so I'll stand by my logs is the best signal because because it can do everything, right? You can do tracing like you can log a trace ID and query on that trace ID and you could probably build a UI like in fact you know most databases that support tracing or log apps are are very similar they're they're columner store in most cases like they uh you know the the login tracing world is is is similar you know it's very very similar but the typically the tooling is more specialized for like the view of something like Nicole was describing where you want to be able to see like what took a long time in a certain way. It's like much nicer than you know trying to do that out of a sort of a logs view. Um but under the hood that data is often stored the same that where where it's it's different like why metrics are different is like metrics are are kind of a materialized view of of log data right so so what they allow you to do because if you know almost nothing matters at small scale right it's like you know there's nothing you can do in a in a relational database with less than a thousand rows in a table right like there's no slow query there's no mistake you can make right like there it just always will be millisecond fast right like and That's true for until you get to a thousand, like 10,000. When you get to a million rows in like a relational database, like okay, maybe you need to think about index, you probably don't honestly. When you get to a 100 million rows, okay, maybe you need to care about it, right? When you get to a billion rows, like yeah, you probably like this is true of every database that exists, right? Like there's some scale where it it matters what you do. And for you know, something like Loki, like you know, if we can search through logs at 500 gigs a second, like great. you know, if you've got less than 500 gigs, I can tell you your query, it won't take less than a second. It doesn't work quite that way, but you know, it can be very very fast, right? If you've got, you know, if you're a huge company that logs, you know, 50 billion access log entries a day, right? Or like or or you know, some proxy log, right? That has status codes in it that you're trying to determine if your app is working or not. And you have, you know, even in a columner format, right? Like terabytes of data. Um, you know, that's why metrics exist because you can give a highly optimized view where you lose individual event level granularity and you roll that up into like windows of 15 seconds or 60 seconds, right? And counts, you know, and you store this half a bite per sample kind of thing. And then and then you build an index that's specifically built for the kinds of queries that do intersections on metrics across different, you know what I mean? you just built a thing that's is very very good and very very fast at this sort of materialized view of these things right and now that's not to say like you shouldn't use these things at low scale because also the nice thing metrics give you is it's like an outofband it's a second band for observing your apps right so like you know you have your log stream you have your metric stream one of those can break and you can still do your job right like so there's some redundancy that comes with that that's also actually quite handy right and you know in particularly like depending on how the stuff is handled or scraped like there's advant vantages or or disadvantages to like what you can know about how your app is working or your machines are working and so so anyway like you know you can do it all with logs but I can tell you we don't run our systems all with logs right like we we use all of these signals because like in almost any scale like you can get the benefits out of why they're optimized for what they do >> so if I can summarize maybe that if you put high cardality stuff in logs you cannot use this on metrics but you can build a metric as the index index maybe even derived from this logs are in the same place in your application and metric serves as the index or maybe your database is smart enough to build the index for you but it costs something and it's if you self-host it you pay for it if you're SAS it's you still pay for it but indirectly but essentially indexing over high cardality logs cost you something >> yeah always cost you something somewhere Yeah, there is a question I I there was an interest in asking uh about keeping the logs on the your machine. Uh Abby maybe uh so logs as JSON should be stored and not on your manage. What does anybody want to take it? Yeah, I I I wanted to comment on this because um you know, you know, I I gave this guidance to send your logs over to a network location uh until you don't until you need to do something else. And uh you know, I was comparing to how you send traces and metrics to network location. So why shouldn't it the same be true for logs? Um, I guess I I didn't qualify that because, you know, I still find I I think people have thrown out this idea, but I find it really hard to imagine running an application and just starting it up and not seeing anything in standard out like not seeing anything in the console. Like I want some sort of signal from this process that I can like I can tail these like, you know, the logs for it and at least like see that it's alive. uh and I don't want to rely on looking at a database over a network to be able to tell that my application is alive for and that that goes true for like local um development and also you know when I'm running in a in a production environment and so I think I think of this as in terms of like a belts and suspenders approach. which is like you wear your belt to keep your pants up, but you also have suspenders to double check that your pants are up. And uh yeah, so in this case like I I I like to think about logs is like, hey, you're going to send them to a network location uh over OTLP because it's convenient, but you're also going to send them to the console because, you know, we're all in these situations where we need to tail our logs um for any number of purposes. And you know, I I I would not advocate getting rid of that signal, that basic capability. Yeah, we are pretty close to the end of our stream and I I thought it would be useful like we talked a lot about different things that are hard or blurry. Um, and I wanted to maybe close this with a list of things that uh you can take away and implement or maybe we will just highlight that they are blurry. Um, so we'll do a small game. I'm going to show you a statement and um you folks uh who are uh live here you can vote in the chat or I would ask my dear guests and co-host to uh vote with your I don't know thumbs up thumbs down or something in between six seven if you get what I mean. Uh [laughter] uh okay. So the first one uh is it good or bad when you format a log string. >> Okay. Just two two. Yeah. Not clear. Uh so the next one uh sorry I for some reason yeah um we identifying log record type as subject property like event name. >> I have a mixed >> Yeah. Oh, but I think you should be judicious with with metadata like this. >> I haven't sold out on this yet. Okay. Uh, login all exceptions as errors. >> Uh, >> as errors. Every exception is an error. I think you and I have had this conversation. So, [laughter] I agree with you. >> I mean, you log things as errors that you as a someone trying to figure out what's broken can search for error and find something useful. So like if you know there is such a thing as an as a normal error like an unusful error you know so like don't >> yeah try to make the error signal as as useful as possible >> yeah somebody asked why don't you just take logs from std out this is why they are multi-line they are losing everything >> you should just never have multi-line logs and then you don't have this problem >> you should never but yeah there is a lot of software out Yeah, there sure is. >> Stack stack traces tend to be multi-line. >> Exactly. Yeah. So, no, no, don't do this. Uh, this is this a good idea to log request or response body. >> As the person that runs a database that has to deal with this, I say no. I [laughter] understand why people want to do it. I don't know that I have the best answer here yet, but Um, I would say don't log HTTP headers because you're almost always going to leak PII of some kind. [laughter] So, don't do that. >> Judiciously is probably the answer here. >> Okay. Now, it's the question for Ed. I I targeted it for you. Should you put every possible detail that you know about the thing onto a log record? I mean, all I can say is that every bite costs money. And you may not be the one that pays that bill, but somebody does. And it it it does add up. And even if even if you can make your database and your protocol magic, it's always more expensive to add more data somewhere. >> Yeah. So, probably no, not a good idea. Be be intentional. >> No. I mean, if it's like I don't know like your example earlier logged the the path to the application and the and the sort of line that it occurred on like I would I would not include that in metadata, right? I wouldn't I wouldn't include the version of the JDK. I wouldn't include the version of the operating system, right? Like the other side of this though is a log line with no context is is useless, right? Like like if you have nothing like if you have a log line that says process started, that is a useless log line, right? like you know or message received right or order received right like if you don't have the order number in there like ideally you should log a trace ID in every log line because that allows you to get unique you know history of events but at least have you know customer numbers order numbers transaction numbers something that allows you to make that line meaningful >> or put it in the metadata too that's fine with me just >> yeah whatever you do be intentional oh this. I love it. So, should you log u all your secrets or PII? >> I mean, >> probably not. [laughter] >> Have a logger that obscures them, but like it is actually quite useful to log the config of an app when it starts up. >> Exactly. Yes. >> Just try not to log your like access keys >> it. Well, the config include stuff. Uh the last I think this is the last one and it's the trickiest one. I don't have an answer for this one. Should you luck without severity ever? >> Severity is like I don't know. I'm not sure if log level severity is useful other than error. You know, like the the you know well structured, well-intended teams with like good guidance can probably make a few log levels meaningful. But you know when you we you write apps we just don't know like so you either as a developer typically pick to log everything at info or at debug right you sort of tend towards one or the other and then eventually what happens is like you need a line that's debug level so you always have debug log lines on right like um some sort of like go's bad at this right goes loggers don't let you do package level log like where Java is like way better at this right so you can have some granularity on like log levels per package which is nice. But um I do think the error severity ends up being really valuable and like arguably like info versus debug because like usually but I don't know a lot of times info log lines aren't that useful anyway. So info and debug end up being the same. >> If you don't include this information then you know whatever system you're using to query your log logs is going to make assumptions about what the default severity is and then you know you're going to confront this anyways. So I say >> true severity. I [snorts] I tend toward saying no, you should not log without severity. Just if if nothing else, like it prompts you to be more intentional like the the log writer. Um it prompts you to be more intentional about why you're logging this and who who the audience is. Is it you for debugging or like is this for production or like what? So I would say no. >> Yeah. 100% right on that one, right? Like you're going to have to deal with it. So you might as well pick correctly or you pick something you know like and I you know I guess I would say if you think of it in terms of like I think of everything in terms of volume right so like if you keep info to some smaller level then you can query less data and get results faster right like errors just need to be meaningful right like ideally you want error messages to be like this is what I'm looking for when things are broken and you know debug is everything else right [laughter] >> what about if you have 24 logging levels like an open telemetry Someone pointed that out in the chat, too. [laughter] >> It's like, you know, it's funny because like I do think people could get sophistically sophisticated to to use that, but like most people just like never never have time, right? Like we have deadlines. We're trying to make it work, right? We're trying to ship it like you know the but yeah, you know, just for fun then maybe throw a few of them in just to real quickly I'll address why there's 24 like there's another question about it. So um open telemetry logs were designed initially to bridge other existing log frameworks into open telemetry. Um and so if you can imagine let's say like in Java you know there's like typically log levels of like info and debug. Well, what if in a different language there's like something in between info and debug? Like how do you map an existing log system to open telemetry if you don't have enough granularity to account for like you know additional severity levels that don't exist like you know symmetrically across all your languages. So that's why it exists and you know open telemetry as we kind of get into this like this space where we want to have a userfacing log API we need to we need to find a way to hide that unnecessary complexity from users. Users do not need to be aware that there are 24 log levels. That's that's silly. >> Okay. Well, I think we're we're already over. I I knew it could go on for much longer. Um, did you want to end with like a single tip that did not get mentioned or that that you want to leave the viewers with? Lead Miller, you didn't get to say yours. So maybe let's start with you. >> I'll summarize everything we said here. It will be very general, very unusful. Be intentional when you write your logs. Think who you're writing them to, humans or machines. Uh, think about the information you want to include. Don't be overly verbose, but be verbose enough. It's a very easy advice to give and very hard advice to follow. >> That sums it up well for me. I didn't I got through my three points, so I'm I'm I'm happy. [laughter] >> Yeah, I don't have anything to add. Yeah, we we talked about all my things in one form or another. >> It was great to have you. I really enjoyed this discussion. Um and thanks for coming. Yeah, thanks everyone for watching and thank you thank you all for coming as well. It was great to have this conversation. Maybe you know by the way if anyone's watching here and and they're like you're like I wish you had talked about this more in more detail. Let us know in the comments because the chances are pretty high that we will have another one and we do listen to what people are asking for. So let us know what you want to to be discussed in more detail. Uh have happy holidays everyone whether you celebrate a holiday or not and um I guess a happy end of 2025. >> Yay. See you at 2026. >> See you. >> See you all. Thanks everyone.

