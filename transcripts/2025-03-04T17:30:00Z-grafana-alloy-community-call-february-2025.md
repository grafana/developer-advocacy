# Grafana Alloy Community Call February 2025

Grafana Cloud is the easiest way to get started with Grafana dashboards, metrics, logs, and traces. Our forever-free tier includes ...

Published on 2025-03-04T17:30:00Z

URL: https://www.youtube.com/watch?v=QT6MJFSpZyY

Transcript: hello everybody and welcome to the February uh aloy Community call So today we're going to jump in um we don't have any I don't think we have any predetermined topics but we'd love to open the floor to uh anyone who does have a topic you can either add it in chat raise your hand unmute yourself in chat talk whatever you want to I'll give a few minutes here to see if anybody has anything they want to talk about this can be questions this can be like hey what about our proposal it's pretty wide open um we can even take a look at you know if you have an issue more than happy to dig into anything so I'll open the floor I'll jump in yeah jump in how closely if at all does the alloy team uh work with the hotel teams hey Sam I think you'd be a great person for that why don't you give yourself a little background there uh yeah so I'm Sam I've been working with open to lemetry for a few years at a last position and now now here with G and alloy but uh recently became an approver in The Collector Sig um outside of alloy we also have a few other um grafana members who are maintainers or approvers in other sigs than the collector um so I would say we work somewhat consistently Upstream um you know we're we're a pretty small team so there's a balance always to what we're able to do Upstream versus working on in alloy only or alloy first um but yeah we're very committed to being good members of the open Telemetry Community well I think uh as I'm implementing otel in my app and then deploying alloy to get it into grafana and all the things sometimes they just have that question of like is this an Noel question or an alloy question you're always welcome to ask it within the allo spaces and if it is something that makes more sense to be in a different space we'll we'll redirect um but we'll help where we can as well so cool it seems like at least in the graphon labs Community Slack alloy is definitely one of the more responsive channels right now I I've uh tried to ask questions in some other channels and seems like crickets even though they have more members uh so I appreciate the LA Community all that to say awesome love to hear that um yeah we we don't so one thing that is different is is we do not support every um component that like otel cont Tri has in it so so there's a possibility that like you know there could be some differences there um you know part of that's just support cost because when we say we pull it into otel we pull it from otel into Alo that means we have to support it and and build documentation around it um and we we trickle those out as we kind of on customer request or just requests from the community um but in general we try to pay like Sam said good stewards is there a continuing effort to bring a little graphon agent but more so like promail documentation into the alloy uh documentation site we should uh we probably have reference documentation we um have traditionally had issues with uh we try to be very good on like reference like the uh nuts and bolts but not necessarily on the how-to side so that's something we uh us and especially Clayton who's kind of our dock Rider um is really keyd now granted we've been saying that for since Alo was released but uh yeah Paul I didn't quite understand the question which parts of the promt documentation do we need to bring over I've just noticed there's a lot of existing uh documentation on promp tail um example um howto some of it's in forums which you can't really migrate that um but just when I'm trying to figure out something in alloy there's been occasion where I'm like I don't really see this and then I go searching for graphon agent or promail and then I can find the answer it's interesting I I personally didn't realize there was so much in prompto dogs that wasn't in yellowy dogs I thought the prompto I thought that when people were pting all the prompto code and the agent they just used the same examples and the same uh comp entries and so on might be worth double checking then there's anything missing yeah and I can't think of a specific example right now um but alloy is my first time using like I'm not migrating from promil or from F agent like Alo is my first time doing anything other than Prometheus so trying to figure out how to get logs into Loki and traces into Tempo and what is a log and what is a trace all of that is been a fun learning curve so um yeah I mean that that's the great thing about the internet is that the old documentation the old questions are there that we can search for and can find the answers as you're investigating if you do find anything that was was clear in the promil docs or in the agent docs and not clear in in the allo docs if you want to bring that up either in the slack Channel or as a GitHub issue you know we appreciate that just for tracking because there's uh there's only so much we can internally find that is you know we're never going to have the same experience as a user um and especially promail was deprecated uh in the latest uh Loki release so there's going to be more and more promail us is starting to look at alloy sure I can't remember if if anyone else's stuff I don't know if I'm the only user here and everyone else is on the team or um I don't want to dominate the conversation but um one issue I've noticed just in setting it up is that um so our architecture we have the aloy agent on all of our primary services but we also have like a dedic dedicated alloy server which is a proxy into Prometheus Loki and Tempo and for that proxy server um the otel receiver OTP um that supports TLs but both the Prometheus I forget if the receivers or collect what what the name is but both the Prometheus and the Loki um components of alloy don't support TLS whereas Loki itself and Prometheus itself do support TLS um and so our our Loki Prometheus and Tempo servers are behind uh firewalls and uh vpcs so we're not as concerned about exposing those ironically but alloy is like the one public facing port for all of the injest and it would be really nice if um both the Prometheus and the loky supports could support TS so I don't know if that's on a rat I don't remember if I created GitHub issues or commented on GitHub issues for those offand I think you're specifically probably talking about the um Prometheus um receive HTTP that roughly sounds like the right name um yeah I don't we so we have I know we have issues for adding more config duration and off in general around alloy core if you will like you know Local Host 1 2 3 4 5 I don't know if we have anything around um the uh the actual HTTP yeah so the Prometheus receive HTTP and then the Loki Source API yeah [Music] real quick yeah go ahead and search that I'd say those those definitely sound like valuable things that we you would certainly not be the only user interested um so if there's not an issue we should make one we have a new member of the team joining somewhat soon and and a couple other open positions um those sound like great uh early tickets to uh to put to someone who's relatively new to the team so we'll we'll make sure those get added to that list of good first issues for for the folks who are joining thank you go ahead PA so I just realized P raised an issue for this just found it oh awesome GL I could not find it oh well by the way I've been wondering whether we should make a security label on G because I've been interested in working on these kinds of security related problems to be really nice to just generally improve security pure hard on the way little more um yeah be nice to have a label and just so I can pick up these kinds of things and find them more easy hopefully no bad guys will find them I mean we we we should be able to control those labels um oh that's dumb all right Sor right why I couldn't find it is apparently if I look up receive HTTP I don't see it but if I add prometheus. receive HTTP I do find it so I'm not sure if it's because it's in a code Block in the title or if it's only looks for like whole words um but yeah if you want to give that a thumbs up or add a comment Sean um something we can uh you know we can look at when we do kind of our planning and uh you know we do look at like how many comments or how many thumbs up something has uh and I would say unless Matt or I wants to uh jump in if you got more questions just firey them off um I do but I I'll just post it on the GitHub it's more RFC uh CIS log in just pipeline or we we use that we use R assist log sorry in the uh locomotive industry in the train industry for the communications between between the radios that are installed on it and we've had some good success but it's a little bit the way our approach is a bit tedious but I want to make sure before I ask that I've done my due diligence I mean if you want to chat about it right now right now is good time uh if you think you need to do some research that's fine too yeah I think let me do because the way I have it right now is it involves a lot of Rejects I'm not I'm not liking that uh so let me do my research and then I'll post post back thanks all right yeah when you do feel free to uh just ping it in the channel that we talked about it um and you know I generally if somebody comes to community call and brings up an issue that's more likely more engagement we're more likely to take a look at to be honest I think I did see Sean somebody posted something about CIS log recently on the channel let me there was a a user who was trying to figure out how to parse CIS log messages out of Journal D that was the most recent one yep that was the one let me see theirs was RFC 5424 or 3160 I can't remember is that the one you just added Sam um didn't you just add a something for it was a feature for RFC 3164 where um the the spec says there's no year in the time stamp and the default Behavior then is just leave it at zero which apparently Loki does try to handle but um the user was interested in it being handled um in alloy in the in the CIS log parser so added that but I also recently added the open Telemetry CIS log receiver and EXP as well so I've touched s log a lot the last month or two oh nice okay I think ours is yeah ours is 54 34 so there has been some work done for 5434 uh yeah it's supported both in the the Loki um CIS log parser and in the open Telemetry um CIS log receiver um should be pretty widely supported if there's any specific issues you run into let us know um I know one of the the reason we brought in both we had the Loki version for a while and we brought in the open themetry one recently is that they handle um due to the nature of the Loki model versus the open to elemetry model they handle the structured metadata differently so depending on on how heavy your usage is of that you may want to consider one versus the other um but you know like you said you had some research to do if you want to do more of a a write up or a conversation in the channel later happy to do that or if you have specific questions now that's great too but should be supported okay uh let me peruse the documentation and then uh I'll post in the channel things yeah one other thing that um uh had a request for that is not currently supported is having one port receive both 3164 or 5424 and figure it out on the Fly I don't think we have any support for that at the moment um I know I've seen issues in the the past with either I don't remember if it was in open Telemetry land or alloy where uh to get around that users just spun up I think CIS log NG to kind of act as a proxy that would standardize them to to one format but yep I've I've looked at that route too [Music] yeah I think there's also an open issue I can't remember if it's an alloy or in the Upstream Library [Music] um to have an option to like pass raw data in case the providers um supplying non-compliant CIS logs um but to be able to still capture that data and not lose it yes yeah currently we don't support that but I've seen I think I've only seen issues in the Upstream not in um alloy but I might be wrong on that but yeah that's definitely something interesting that we can investigate as well um yeah at a past work on the otel CIS log receiver um I have seen just how many different specifically networking uh devices do CIS log contrary to spec so it's it's definitely out there as a as a real issue go ahead pal I have a random question for the audience does anybody happen to use Windows because uh I've been meaning to work on this issue next the one that I post on the chat it's about uh having some kind of way to set a higher priority for the alloy process because some users they reported issues with a lawy not being able to send Windows related metrics from the windows exporter and apparently if you set higher priority for the process it works better but we don't want it to be the default so yeah I just want to raise awareness for this and you know if you experience this kind of problem feel free to leave a comment on the issue because I'm I'm curious how widespread it is open for if anyone have any discussion topics or questions if no one else has a topic do we want to plug what's new in alloy 17 I heard there's some good stuff in there absolutely let me go with change log [Music] handful of new open Telemetry components TCP log file log C cumulative to Delta processor uh pretty significant updates to uh the config syntax with four each um if second there yeah William poen you want to jump in with 4 each what can you give me the the elevator pitch for 4 each yeah sure so the idea for each is you can think of it as like a a for Loop in your aloy um file config file and you can with this for Loop like set a collection of item and for each item you can create a pipeline so the idea is that some prus exporter like the the radius one you would need to have like you can use uh Discovery and then for every like discovered redus instance you would need to plug a pritus um Rus exporter so every time you would have a new instance you would need then to modify your config but with this four each statement now you can plug the the discovery into the for each and then for every red discovered instance it will create um like you can configure a pritus um redis exporter and then you can plug this into uh a scrape pritus component and then into like reling remote right whatever you need so and there are quite a few exporters that works like this so the idea is like less manual work and more U like Dynamic uh work from the the auto instance that's really cool we're getting we're getting closer to touring complete every day right we also use the uh the hashy Corp tools quite a bit backer terraform Vault um and they all use HCL the hashy Corp configuration language are you guys going to get to the point where there's a GCL a grafana configuration language so interestingly enough the first version of alloy was a fort version of HCL um back when it was agent flow mode or it didn't even have a name back then um so it's definitely some loose inspiration there um but yeah I think the I don't know it's interesting to look at and I think we are you know we we've often had a long tale of things that we kind of want to do that are just from a kind of expand the language and cool perspective so for each one of them conditionals have been a perennial topic um there and there's two types of conditionals conditionals within like conditionals around components and conditionals within components um which using them right now within templates yeah we're not quite there yet [Music] yes sorry go ahead one more thing about the the new release uh if you're a Windows user and especially if you're using the low key Source Windows Event component so to to collect logs from from Windows then you probably want to um upgrade to V 1.7 so the the release that we just um created this week because there is a massive Improvement in terms of CPU usage without any need to modify the config so you should just be able to upgrade and see no changes in Behavior but just yeah massive Improvement in terms of CPU speaking of improvements of CPU and memory uh pea did a pretty big change to optimize our kubernetes Discovery um component um so in very large clusters we would see that that consumes a lot of CPU and a lot of memory um so this certainly took a good chunk out of it and made it a lot more performant um you know we're still going to keep an eye on it and and see what we can do to improve it but um we've seen some great gains there so if you're running a large kubernetes uh deployment um you know you can you can see some gains there we we've got you know users who are running you know tens of thousands of nodes and hundreds of thousands of PODS and that can be a pretty big bear um when dealing with kind of that scope and size sorry Sam I interrupted you as you were kind of cruising through the uh the uh list there if you want to see if there's anything else that kind of catch your ey I think I touched on I think with between all the conversations we touched on the big ones um don't think it's a it's a long it's a long change log um you know the the release notes uh only show Breaking and features but then significant number of enhancements and and Bug fixes so should be some just improved resourcing and ility and all kinds of nice stuff and we'll be shipping a 1.71 I assume today or tomorrow um today I assume because I think it's being built as we speak um that mainly does with um with that mentioned I with thing I mentioned before with the kubernetes discovery we found that there were some aggressions um so P has got that in there and then um there were some performance issues with the um Prometheus right q that we found in testing so I made some changes there so I should roll that today is anyone going to an obson or graphicon walking distance from my apartment oh which one um I don't think any of us are currently flated to be there but if we do show up feel free to hit us up I'll be at the obcon in Chicago in two weeks Lord that's coming up um so if you happen to be there feel free to give a shout out find all right other topics all right if no one has anything else we'll get done right at the 30 minute Mark and get everybody back uh 30 minutes I appreciate everybody showing up and I hope you have a fantastic day e e e e e e e e e e for

