# Introduction to eBPF with Grafana Beyla, with Nikola Grcevski (Grafana Office Hours #25)

Nikola Grcevski, Principal Software Engineer at Grafana Labs, gives us an introduction to eBPF with Grafana Beyla. We discuss ...

Published on 2024-01-06T05:19:40Z

URL: https://www.youtube.com/watch?v=ZEUzucqXUnQ

Transcript: everyone and welcome to the first grafana office hours of 2024 yay I'm Nicole vhen I'm a developer Advocate at graan labs and today we're going to be talking about application Auto instrumentation with ebpf and grafana baa and pretty much what each of those words means because there a it's a mouthful there's a lot loaded yeah loaded topic yeah here to help me go through it all are my co-host over here hey Paul bog another one of the G graffan Labs developer Advocates your favorite one of course that's debatable that part's debatable we're not starting off the year right you're already fishing for compliments you know I'm always yeah yeah everything to you know stroke my ego right you know gotta get that ego stroked and down there is the one who's actually going to be providing value he's Nicola gesi welcome H hi hi everyone my name is neski I'm a software engineer at grao Labs working on all that mouthful uh evtf Auto instrumentation at grafana Labs yeah how long have you been at grafana actually actually not that long it's almost coming up to a year so um just a little bit shorter than a year oh you'll be getting your mug soon your your one year Ann that looks Prett cool that looks Prett cool yeah they are a little bit different I mean they're all like customade or something I don't know they're uh or handmade yeah it's pretty good yeah I like one with the logo yeah mine is plain white Ikea I feel like I I should have I should have used that today but I didn't mine's just plain and transparent and it's just because you wanted your tea to match your hair you were going for that sure that that is exactly it that was entirely intentional brand Nicola what did you do before you joined gravana oh lots of things I guess uh um in many different areas I actually started my career as a compiler engineer I worked at IBM for 13 years um on what's today known in as open j9 so it's a jvm implementation by IBM um I worked on open jdk for a while um while I was at micros oft um and I I did a stint at a company Lo local Tron of startups uh that did SAS software for a while learned about observability monitoring and stuff like that I also worked uh for a bit over a year I guess almost two years at the last search on the um the last search core infrastructure team yeah and finally this this was uh big shift for me to uh low level observability with at beginning of last year yeah but yeah mostly I'm a I feel like compiler nerd yeah majority of my career has been in compilers and yeah okay well let's talk a little bit about that um one of the problems with observability is instrumentation I think everyone you know if you ask them if if they want to be able to see to their applications the answer is yes the problem is that that's not always as easy as it sounds can you talk a little bit about instrumentation oh yeah yeah it's a big topic I mean um you especially when I worked in a for a company that SAS it it was really difficult to pinpoint bugs in production and you always you know the time you're looking at it it's it's passed the problem is not there anymore or it happened something overnight and it's a blip and you're trying to understand how do we prevent that from happening again and you always need more and more data to capture that and and of course getting that data there's many ways you can get that data sometimes it's is an infrastructure level uh but sometimes you need more data of the application right so so what just happened when we had this incident or something work wasn't working um and adding that instrumentation to the application is an effort and developers don't like doing it uh it's sort of necessary but it's it's I don't know like it's not essential at some time like you're writing your code you have your features you have uh stuff you need to do then um to to actually for the for the application you're working it on um and then this is like sort of oh we also need to do this there's never enough time for it um so there's been Improvement in the last little while about this um there's obviously open Telemetry and now we have a lot of um Auto instrumentation libraries so you can think of it uh instead of me manually adding instrumentation to my library or picking a vendor specific solution I can just use one that's generic now I can send signals uh to multiple data sources uh so I can maybe Auto instrumental application rather than having to go through this drudgery of augmenting my code with various things um but there's some challenges with that too you know it it's not as easy as it sound sometimes um those Auto instrumentation libraries work for some libraries they don't work for everything that you have in your application sometimes you duplicate the signals like one you know you can have uh one Library use another both are instrumented and now you're getting double the signals and there's no way to stop it because both support the auto instrumentation um sometimes dependencies in your application just outdated you need to upgrade your dependencies to match what the uh Auto instrumentation library has as a dependency uh it's not easy to do sometimes that migration path depending on where your application stage is at to take months or years to actually upgrade a dependency um and you're doing it while is running your production and you know how much effort should I spend on just getting this stuff out there and of course when you have a an incident or something like you're on call in the middle of the night you need all the data possible um so that so this sort of um problem is what actually drove the the reason why we started working on this product Gan G baa is to how do we mitigate this so my camera is getting weird am I out of focus it does you are a little bit yeah we thought you just naturally got a little blurry yeah I got blurry yeah I was waiting for the internet connection to go out yeah I think it's my camera does this from talk to time I know get close to screen and maybe back out yeah it'll correct itself don't worry about that's all right um so it sounds like there are two different levels of instrumentation kind of two different approaches to it the first is you can manually instrument your code so you actually modify your application code and and in that way you're telling it what what signals or what information to collect and this is the approach of for example like open Telemetry which which you mentioned but also things like grafana Faro does this it it provides like a library like SDK for being able to instrument your front end to collect certain types of information and then there's another layer of like not not changing the application code but instead somehow modifying the binary at runtime um and it sounds like ebpf Falls within the binary instrumentation method well so yes and no I guess to some extent right so Auto instrumentation can be done by in certain languages as possible like Java I worked on Java a lot so I'm going to use that as an example um Java the virtual machine in Java has this extensive way that you can extend it with additional agents so it's really built as a platform you can attach an agent and this agent has privileges that can sniff out data out of your jvm um so for them is in a J in a J World you attach this agent you add it to your configuration and all of a sudden you can see a bunch of stuff um and it's an approach people use in open Telemetry as well to gather signals from the application uh for application observability um with this approach so it's not necessarily instrumenting the binary there's no binary in Java really uh everything's done on the Fly um but there's this sort of approach and I think do net is similar to some extent in this in this way um but we we doing with Bay is some somewhat different we we either ta into the Linux kernel to extract some of the data that application at the end of the day is setting some HTTP data grpc data it's moving around through the kernel uh interface to be able to be sent out to another service or to be received from an incoming request so we monitor those signals and we stitch that story together about how what the application is doing um and in other cases like in case of go we do actually um attach to the binary with an external program sort of and we take out the events so we don't modify the binary itself it's sort of um like a debugger tool if you will where you can kind of with a debugger or like attach to an running process stop it look at it and in this case it all happens with this new technology or relatively new technology BF we we're able to um almost like I sit at a break point um in the application collect data and then move on let the application go it just happens really fast and uh it's really low overhead so we can actually capture many signals and then again we stitch those signals together with some additional tool that runs in the background so would you say that that's a third level of instrumentation then Source binary and kernel okay yeah so it's it's almost like external instrumentation it's not it's like there's appli there's approaches to instrumentation which like you said binary where after the application is built instead of developer spending a lot of time modifying the source to add instrumentation that there's tools that would instrument the binary rather than instrument the uh the The Source itself um two like that this is slightly different sort of at a system level if you will external to the application it only works on Linux that's the that's the sort of the negative aspect of it if you're on a different platform for some reason like using Windows um then yeah it doesn't exist yet but as far as I know they're working on it there's ebpf on Windows project that's on GitHub and we don't know when maybe that lands into the windows kernel and we'll be able to do something similar on Windows yeah I was just going to make mention of like uh you know with the the three different uh types or methods you know way back in the Java days when I was using Java um you know and spring Boot and things like that yeah you you had some of these instrumented uh libraries that you could just like kind of incorporate based on an annotation so you would actually be updating the source in a way but then you're not actually explicitly going and writing all this stuff they have actual nice listeners and it's it's lots of magic but uh it's it's a hella convenience thing I mean because as a developer I'm lazy I don't want to write all these you know I don't want to hit the keyboard all the time so you know whatever I can get out of the box from something else that's um with magic that's better for me yeah we've hit on this a lot of times this like I mean you call it laziness but I I call it Effectiveness dream for instrumentation is automagical instrumentation right it's like I don't want to do anything I want all this stuff just to magically come to me and somehow ebpf is always mentioned in conjunction with that like can you deconstruct this for us like how does how does this magic actually work yeah yeah sure yeah I'll try I'll try tell us the secrets of the universe yes yes exactly so I I guess and this is how the story goes but uh so ebpf came from without the e in the beginning was like BPF and it states for Berkeley packet filter um today people say the name doesn't mean anything it's just a name so just don't think of it it's a name ebpf it's an acronym just learn it as a word um and essentially it was this support added to the Linux kernel that you could extend the Linux kernels packet filtering capabilities with additional logic so you can just do better routing or different routing or for security reasons you may want to take packets change their you know internals um do something with them uh and later on people thought well this kind of cool like we added this whole thing that we make the Linux kernel programmable to some extent and why don't we just extend this and make it programable for everything right why don't we why do we stop at you know socket filtering it can do everything and it sort of is a way when you think about it that the Ence in the past when you need to externally extend the Linux kernels functionality you have to write modules so binary programs and you compile them for every kernel differently and um if they have bugs they may destabilize your system you add them and all of a sudden you have a problem those are not maybe secure you have a security hole and then all of a sudden your whole system is vulnerable right so people don't like them and they break often and you know each version is its own version of that module so so but evf is almost like the same thing you can actually extend the kernel functionality but it's done completely differently so what we have today where the technology is taken us is that we have a virtual machine into the Linux kernel built into the Linux kernel it's existed for a while and this virtual machine just like the jav virtual machine can execute uh instructions built for it um just like in jav you have a cross platform you write the application once you deploy it to any uh Java capable system you have the virtual machine or Windows Mac OS Linux it works right you just load this and run it so almost is the same way you can build this program for the Linux kernel for the virtual machine the Linux kernel have and as long as you're within the bounds of capabilities of that virtual machine you can execute your program almost portably across various Linux kernel distributions and extend the Linux kernels functionality and so how does this all work the so why is this better than the old L kernel modules approach because this viral machine has built-in verifier that verifies every instruction that's built by this program that first of all it's safe it's going to touch memory that's allowed to touch that it doesn't do something weird it doesn't break the kernel in any possible way it won't cause problems and it's sort of isolated if it doesn't actually work or there's any problem with it there's there's no side effect to the Linux kernel itself so maybe their functionality doesn't work but it's very safe in terms of um usage within the kernel so people do lots of things with this people for example monitor security with uh with this stuff for example you can monitor every time a new process is launched you can so um write a program this abpf program the cpf program uh you can tell it well get notified or run every time a new executable runs on my kernel and then once you once you actually get that event that you are running this uh this new executable was launched you get notified with a context around that executable start and you can find out what the arguments were on the command line what was actually running what were the maybe privileges this executable ran with as such things so maybe you can generate security events out of this right you can say oh all of a sudden I'm running something I shouldn't be seeing on my system you can report on that log it and send it to Solutions like Gana Lo low key and monitor these events and build something um out of it like a security solution we don't use it for that but we use it for something similar in our products so we monitor socket events for example you can um figure out every time uh somebody makes an external socket connection and you can check are they making an HTTP connection all of a sudden uh extract that information so build these programs that would do that and during that so connection we can extract information or are we sending HTTP package okay what is the server we're sending to what are the what are the method what was the URL and so on and that opens up the possibility for Building observability Solutions for uh web services if you will right the same thing like if you're talking to a SQL Server you can just figure out that the protocol is SQL okay so I'm making a SQL request maybe I have a way to extract the SQL statement I ran um and figure out what I was doing here um so essentially it's a way that you can write these programs and attach them to specific functionality into the cural to run when something happens and then you can have your program grab information about it in certain cases even write back it's some very limited cases and then once you actually collect the information you need you're free to do whatever you'd like with it there's ways to export it and then you can either make a decision on the at the time about this event or just simply log it or record it which is what we do does that explain or maybe do you want me to go into any more detail explain any other bits of it I don't know if I well let me let me try and and summarize in a way to like see if I got it right so it sounds like ebpf as the general technology it can do a lot of things it it sounds like it's aent driven it's based on you know the things that can be can be observed at the kernel level and it can actually be used for a variety of different use cases so you you mentioned using it for security and observability of course but also things like load balancing and networking but Baya kind of Zooms in on the observability part yeah exactly exactly um it can be I've seen people do all such uh interesting things with it like uh one big thing for example in um when you build web services and you deploy them it's there always people talk about circuit breakers or you mentioned low balancing and stuff like that so you can Implement generic circuit breakers like essentially like if your services um need circuit breaker in a sense that uh if a downstream service is failing or Upstream people there a discussion about what's Upstream mon down but you're calling the service and the the service is actually failing um you don't want to be keep calling it right because you you are just putting more pressure Downstream because they're um they're already in trouble and you're just making the problem worse so you should stop maybe try again after 10 seconds then progressively and eventually stop that's a good behavior for service consuming another service but many people don't do it many people just you know you have an incoming request you need something from somebody else you call it and if it fails you retry it and retry it again so on or maybe you don't retry it but um and get retry storms yes yes you get retry storms and all of a sudden every everyone fails right but it's not impossible to see that uh at evf you could Implement a generic circuit break where you're calling something Downstream or Upstream but you will um you do detect that there's been some number of failures right there and you tell the caller you simply reject that call so the caller will get even though they don't have the circuit breaker functionality implemented in the application you can implement it as a functionality extension into the konel so they have to respect it because they simply will get a rejection without even calling any remote service because withf you can say I'm insuring the TCP connect to this uh service that I'm using and you can just say well that call did not succeed I'm sorry you can return a operation code say no we won't let you and that's a c break it Implement in evf that works for any service doesn't matter what programming language is written in it will be done right so um there's a lot of experimentation and people have done like hot standby replace with evf they would have um you know one service and another one fail so they can just reroute it to a different one just with kernel modules nothing needs to be built into the application itself right so this complexity can be done once for every programming language outside of the that's kind of interesting because I mean that's kind of like I never really thought about it with the circuit breaking pattern because I mean usually like uh use service meshes like you know with the uh ISO or Envoy proxy and in link or D in that they have a separate uh engine or whatever that's maybe rewrites IP tables or something so that it intercepts everything going through in or out and it can do the you know fallback policy or or you know yeah exactly looking up different Services you know instead forward to this other service instead if the one's failing but yeah I never really thought about it at the uh you know with ebpf to do it at that level same thing yeah same thing you you don't you can do it at as a colonal module deploy it and it will do it for any application running on that Linux system if you will um or for all the applications deployed like if if you make your EF program run for example in something like kubernetes cluster and you can make it work for any application running on that cluster so it just listens in the back and ensures that everybody is a good citizen right so um or monitor security for every container in that system all right well let's talk about Baya in in particular what is it exactly okay yeah so um our goal when we built Baya was to build a tool that could um capture signals that are related to application observability so not infrastructure monitoring but application monitoring and in this specific case application monitoring for web services so mainly HTTP https obviously and uh grpc to some extent um that was the initial goal we set and we were going to in the beginning only we started with go because go from the auto instrumentation part it's difficult to do right it's there's been a couple of approaches uh there's no easy way like in Java add an agent to your application all of a sudden it's Auto instrument it's that's thing doesn't exist for go applications so we started with go um so capture primarily um signals about HTTP um web services and grpc for go we actually didn't tap into the kernel but we use dbf there's an there's a different uh method in ebpf called U probes where you can do the same thing I described as for the kernel but attached to any binary in Linux so as long as it's a Linux binary you can attach um so we we built this tooling that can attach to various parts of the go Application assuming because go is really well behaved in terms of most web Frameworks that are built in go use the standard go uh SDK so we know specific functions in go that we can add ourselves to as a program so when HTTP serve request happens you're serving on HTTP request we can attach to it and extract information such as what was the method what was the URL um how many bytes did they send how many bytes are we responding with those kind of things right so and you can take this information and figure out how long the request took and reported as a regular HTP metric that people care about so we find error code if it responded with an error because maybe server has a problem or maybe it was like forbidden or whatever like the normal HTTP response codes and out of that we generate events for metrics so then you could um show these metrics or track them over time and build the road rules maybe your service is now all a sudden has too many 500 errors and you're failing on something then you can see this in visualization tools like grafana you know do on call uh support for it and so on that was the that was the initial uh step and so for this Auto instrumentation part we decided to use evf um so the there's no uh go develop of two chain changes so you can build your application whichever way you like uh as long you're within the go ecosystem uh you can strip symbols if You' like uh we'll still be able to find it uh you can build your go binary statically so um so it actually it's one single Linux binary um you can do whatever you like you don't have to worry about any sort of additional things you need to add to your go Application uh which currently most people instrument go applications manual right so they add Trace points in their code and um yeah which is not pretty it requires a lot of toil yeah it's a it's a toil and then yeah um and there's other things such as like copy paste is a problem right so you copy paste a instrumentation all of a sudden is for something else and you're reporting the wrong signals so maybe you don't add in this particular uh HTTP Handler and all of a sudden it's it's a problem right um so that was the first step and then we said well since we have this now um how do we try to capture kernel events as well and see what happens with the other languages so we started building out once we tapped into the kernel and we started collecting signals of about HTP requests uh we started playing with different languages and Frameworks we tried fight Pyon node.js Ruby build rust services and slowly over time we built up support enough to be able to serve and capture events from all these languages so now we say we support any language and we've had people uh build services and use baa to capture I don't know like I think somebody did R I didn't even know that it's possible to write web services in R but somebody reported they they tried an R service which I thought it was like for data science people use that but some apparently there's a web services framework with an NR and somebody tried it and Baya was able to capture signals from that application so even for languages like like elixir or things like that which is the support is very limited where you can get with open Telemetry you get open Telemetry signals through baa because we support at the protocol level can capture all the signals um could you show us how to sorry go on yeah yeah and then we added support for op SSL that was another thing so we wanted to be able to track https Services which was done by go because at go level we tap into the go binary so it's already done the decryption and stuff so that was uh a little bit more challenging so we support op SSL 3 Now by tapping into lib SSL because just like in any add a Linux Spiner we can inject these programs into Li SSL and tie it with the kernel events so we have htps support um yeah sorry you were saying uh Co yeah I was just going to ask if you could show us how to get started with with Baya how do you actually set it up and use it yeah okay yeah sounds good um so what I'm GNA do maybe I'll try to do a little demo I'll put a simple a um kubernetes cluster yeah like any demo you may fail but I'll try my best let me see if I can that's all you can do yes exactly so I'm sh enough offerings to the demo Gods exactly exactly so I'm going to share my screen and I'm show you I have a little kubernetes application here this is based on our demo can you see it yes okay so I'm going to show you what this means and how we actually stole this from our demo which is in our repo it's open source repo right so so what I have here is some configuration is a kubernetes cluster but um so I'm going to pull this internet from not even graphon application this is the other developer that works with me on this project Mario MS uh so he's got this uh published some glob blog service that it's uninstrumented so this is something random of the internet if you will um an image that we're pulling here and then I'm going to show you so this is not instrumented there's no instrumentation in it so we're gonna in the same um kues cluster attach something else which is this grafana baa Auto instrumentation so it's all you got to do so you got to add a another in this case a side car container um we need some privileges because we're going to be touching things inside that are privileged and we finally have to say well this container of baa which is going to instrument something we have to tell it to instrument this um at Port 8443 which is what this service opens up so this go blog application which is a go application opens up Port 443 and we tell Baya okay well you there's some open Telemetry related stuff but we say when you launch look for any service in the system that is has opened this port and once you see it instrument please that's all we do so the rest of the stuff is just for debugging and finally in this system here I have grafana agent I'm going to deploy as well which is configured to send data to uh grafana cloud in this case I'm using mimer for my um metrics and I'm going to use tempo for my traces um so this grafana agent here has configuration this is very typical how the agent is deployed so in our application here I'm just telling uh Baya to send the events to my local agent and the agent will take care of augmenting those data with anything else this that he needs and uh eventually send it to um Gana Cloud now we're open source open Telemetry so you don't have to use the Gana agent if you don't like you can use the open Telemetry collector what your choices are for this third party sources don't have to be grafana products if you don't we hope you will use our products but if you want to push to Prometheus or uh to Jagger or anything else that can support traces you're free to do so right this is just a a demo um and eventually after I've booted everything up into my cluster what I'm going to do is I'm going to run some uh I know it's this a blog post application like a little tool written and go that can you can suppose you can put the various posts so we're going to simulate somebody opening up various pages of this blog and you can see the things um I've set up here to to hit sounds good good sounds good let's all right let's see if we can do this so I've opened three Windows because you're going need a little bit of uh stuff here so um I'm going to do kind which is uh so I'm going to create a little Comm cluster here um so wait until that starts up um yeah I am gonna make the the comment though on the uh so so Mario did he create that load script it really needs to be graphon k6 um dogs yes true true true yeah um maybe we can help you with that maybe yes yes um yeah that's true um okay so here we go uh so that started all right so what I have here so so um into my in this folder is the same thing I was showing you there what I can show you is my credentials because I uh to run this demo uh I should be really careful about not to touch that file uh so we have a credentials template in our demo so I'm going to show you that um so we can do something like this and you can see well essentially I've I've created a a free account in grafana um where I I'm able to get this end points uh for my Tempo what is my Tempo user I've created a kaana API key um so we give you a template where you can just do this yourself like open a freeron account um get this information and you're set to go once you plug it in that's all you really need to get this demo working so in here I'm just going to do cctl um Fly DF and so starts with 01 this is my my credentials now so I'm not using the template I'm using the ones that I've actually um added and so then I'm going to deploy this agent so so we goton agent so let's see what's happening here so I'm gonna start k9's over here hopefully with the screen yeah so so it's starting so I have a typical kubernetes system here uh and now so far I have my graphon agent hting we can see it's log nothing special about this um that's as good as it gets so this a little bit so we can see more things um okay so now that I've started the grafana agent I'm going to launch I'm going to add the application so you instrumented app so we said this instrumented app application has two containers one is this go blog servers written by Mario and the other one is B which is going to instrument the service so we can see what's going on here in this kuber system so uh we got a gold blog um so Baya is running um it's printing various messages and we have the go blog all right ER it is up and running so so far the demo is working um so I'm port forward so I'm going to forward this port here so what I'm going to do is I'm going to expose this port now to my internal port 8443 for this service the go blog um to my machine so let's try that okay seems to be doing something and I'm going to open logs yeah so let's see I'm going to open this so Bay is printing various messages in debug mode so it's looking for various executables that launch on my system here it's not important so we're here I'm in the same folder I think yeah so I'm going to Lear that loow gen that should be k6 and and it's running all this stuff in the background we don't want to watch that so I'm just going to close that off but maybe Zoom this and now you can see that Baya is tracking various calls that this little program is making at the back right um so we're printing on the screen here uh we can see the gold block service getting all these things uh as a as a load um and at the same time Bay is tracking everything that's happening right we track the time we took for each of those requests um and so it's kind kind of interesting I want to point out so we we have two times over here right so one is this millisecond thing the other one is this microsc and I'll get back to that I'll explain a little bit about that as well uh but for now let's just say we're tracking all this request so now hopefully I can open my screen here I want to switch to grafana to show you how this works I'm hoping I'm not going to cause infinite uh Zoom here but so this is my grafana cloud account uh where I have my traces here so here's my Tempo so open and explore so if I run query maybe not the last six hours search let's see run and here we go so in here I see all these events appearing so you notice how how like we so we have a specific trace and this Trace I I we have all the events collected we have various attributes picked up by Baya we know that what was the server Port what was the full URL path and then we know that we get it was a get request so now it's interesting you you see this thing that we we did here so for HTTP route we don't have the full Euro path um but we have this static with a star so Baya recognizes it has a mode where we automatically recognize hats and reduce the cardinality so that when these metrics get generated in something like Prometheus you don't pay a lot so we try to reduce the cardinality so you don't get a cardinality explosion and make your queries slow and expensive um so if you see over here I talked about this uh timing thing uh um where we had this two times so Bay is able because he doing this at the level of the the kernel if you will and tracking the go run time we're able to tell when the request actually started for real so it's accepting data and it's booting up inside the go run time and we're also able to distinguish that from the time it took to process the request um and why these times are different so whenever you have a go Application uh it internally has his go routines which run every request if you will every HTTP request now these go routines need a kernel or application thread if you will um to run that on so it takes a bit of time for this request to set up if you are instrumenting just the time your application took inside the go Handler you will see only this time the processing time you don't see this time it took in queue for this request to be served by your application so with baa we can get really much richer information something closer to what the client is experiencing not just the time it took for your Handler to run but how much it took for the go runon to wake up and actually be able to serve this request so just like I'm having my um uh a view of my traces here I can switch to Prometheus over here see if I can find it yeah and I can just uh I guess I have to select the metric um so we we capture many metrics for example we capture duration seconds and um we can see what that looks like and we see the various routes and as the application is running we know that this particular one which is I guess entry is the slowest one um so all this automatically happened without any intervention on the developer side right there's no particular thing and we reduce the routes to something that is low cardinality so we really have only five routes where the application was doing a lot more like if we see that script that Mario has has all these things right so we collapse everything that has entry that potentially could cause cality explosion under something automatically detected it's not a low cality route um and finally this what we produce here is fully compatible with our application observability so if we go into graphon application observability uh we should be able to after I refresh the page see our glob service here not yet last five minutes actually remove this let's see refresh and there we go so so we have go blog application here and this is our application observability plugin tracking all the requests um for any particular r that we have and so since we capture a little bit of information here this may not actually be the full um output that you would see from manual instrumentation but it does have enough information to go on I think uh be able to see some traces some most of these things will just work for the stuff what doesn't work is the service map and I'll get to that in a second you won't be see will see some data here um because we don't have that yet but it's coming soon yeah so that was it right you guys what do you guys think about the demo that's awesome yeah any way I can be lazy yeah so it sounds like um Baya can forward metrics and traces right yeah but you can choose one of the other if you like you can also say I don't care about traces s yeah or I could just say I don't have any I don't like metrics I don't believe in that I'm just use traces some people like that yeah so we recently by recently I mean like in the last month or two we had on Joe Elliott who came to talk to us on office hours about Tempo and we briefly touched on ebpf and he said he didn't think it was possible to do distributed tracing using evf what do you have to say about that lies lies um so in our main branch we currently do have distributed traces working we haven't released that yet for go um and so how do we do that um so the approach we're gonna we take for go will be very different than the approach we're going to take for any other language um and I'm not going to talk about any language yet because I don't know exactly if it's going to work so I'm just going to keep my mouth shat about that um but uh for for go uh what we do is we um generate the trace IDs uh at EF time now so so if you will a request comes into the first application uh assuming it's go Application it's all instrumented with Baya uh we we get the first request there's no Trace parent there's no Trace ID we generate one and then we track inside so how how so we track the incoming request maybe going maybe doing an outgoing request so this tracking uh works because we can plug into the go run time as well so whenever a particular go Application uh go routine handles an incoming request we get information about the parent child relationship between goru and go and so if it's going an outgoing request we track that well this go routine now created an outgoing request and here's another go routine perhaps there if they didn't do a synchronous call and that other go routine had a PA in the original one so we're able to track it through the go runtime as these go routines get and and actually uh start the flow within the go application so with that we're able to tie that this income request made this outgoing request so that's the first that um because we have tracking inside the go run we attach these probes into new proc one it's called um in the go around time so since we know that this incoming server request for which we have generated a trace ID does this outgoing server request now at the time this outgoing server request is going to write its HTTP headers we get access to the go uh if memory in this HTTP header and this we write the trace ID just as you would with a manual instrumentation so with evf we modify the go manage memory with the trace ID that we know at a specific time and a specific place in the go libraries where we know it's safe to do so we don't grab external memory this memory is already pre-allocated by the go program itself because it needs a buffer to send the outgo request we know which time exactly we're going to do this we're able to write down what you would normally do with um manual instrumentation if you will so you can manually add this Header information but we do it for you just like you would in by yourself um this doesn't work in some scenarios uh and as one particular scenario doesn't work uh for which is um secure boot on Linux so if you have an envir M which is rare in Virtual machines and kubernetes but there's are ones out there which use secure boot um and in that scenario we're not allowed to write memory but it's a restriction that's sort of obscure people running it on like myself I can't do it uh on my local laptop uh so I have to boot a virtual machine to actually develop this functionality myself because my Linux machine has secure boot on and I can't actually write memory with EVPs it's one of those apis that are locked down um so that's that's what we do for go so we are in the process of making the same thing happen for grpc uh we currently have something in our source that does grpc but it's not ideal because it doesn't catch all scenarios so um we're working right now to make that happen and once we've done with that we're going to try to do the same thing or something similar for other languages now um some languages will be simpler I would say um but the main challenge is not every language or framework has the same way of managing the internal threads so for languages such as maybe python or Ruby or no. JS which are primarily um single threat of the nature if you will um that would be easier for languages like it's almost impossible like if somebody's using something like a reactive framework where they do all this it's like impossible to handle to track the requests within the run time no it's not doable so I'm pretty sure this what uh uh this is what uh the tempo folks had in mind that it's extremely hard to do but go small steps at a time maybe certain Frameworks this may be what Jo thought it would never be able to do because simply tracking those threat requests within the application is impossible but fortunately for us some languages and run times this is actually not that difficult um but for others like doet and Java I have another question you showed us how to visualize the trace information on grafana cloud but you can also you don't have to use application observability app right like you don't have graph Cloud you can still use Baya for sure yeah so you can build your own dashboards for that purpose for me it was just you know I didn't have to build dashboards here so I could just show application of durability and have those nice metrics show up there uh but you have the underlying data that was the first thing I was shown with explore um and uh you could take the sources either like from MIM Prometheus or anything you have else you have which can support metrics and open Telemetry you can build your own dashboards and we have community members that done that um grafana baa we have a default dashboard that we put in our repo if you want to upload it and you can just attach it uh add it to your grafana instance and use it as well so I'd also like to if we can touch briefly on some other alternatives for Baya like the one that comes to mind for for instance is that grafana Labs has a partnership with ISO vant ISO veent and so how and they create psyllium how does celium compare to baa what what's the relationship there do do they do the same thing what's the difference yeah I think it's very similar to to what happens in terms of psyllium has this network overlay so they capture everything at sort of the network level similar to what we do for programming languages out than go to some extent um there's some limitations to that and I don't want to say some approaches are better than others but um we believe that instrumenting at the application Level or getting deeper closer to the application rather than a network level can give us richer information um for example with go uh we're able to extract information about the runtime um and for example in the future we could produce that information such as how much time the go applications takes time in garbage collection so these metrics are important for go developers or um for Java developers folks like that which is sort of unrelated to network events those events are specific to the application itself um we can track https calls or protocols at protocols for SQL or other language is much easier because it's at uh the level of application as well um so for example for go we do track SQL calls so you can have information about what what is the SQL request um sanitized we we don't let the the full SQL request appear because that could have private information as well um and yeah htps we track with lib SSL I know that there's some attempts that S I think there may have been talk I don't know don't quote me on this uh that they were could use H they could do htps now with some exporting of certificates U so their requests are decrypted at the time and their Network events um we tap directly into lib SSL so none of that setup needs to be done so application is serving with certificates that are in the application deployed there's no need to do any sort of management like that we intercept those calls uh live SSL um so I think in the future more information can be extracted um with EVP F by getting closer to the applications themselves um that would I as an application developer in the past working on sass application cared about these events um for example how many go routines do I have in Flight in a go application or how much do I time do I spend in garbage collection in a Java application those are really important events um and uh but we do use celium I mean at least part of the library ourselves so we love celum um way Bay is built with cium go U EF which is invaluable for the work we do so um yeah at some level this same information can be extracted I would say with tooling as well we think we can add value ad U with some of this additional metrics that's cool yeah and that's interesting too that you know that we're Baya is utilizing cium binaries to uh use to read I guess the ebpf yeah uh technology it's so it's like so it's like Baya psyllium ebpf some exent yeah some yeah yeah so many layers it's like an onion yeah it is hard to think of these things in many different levels and there are on each level there's an approach and on a higher level are the service meshes so we talked about that a little bit before how is baa different from a service mesh like ISO or Linker D yeah and they I think they you can I find them very similar to cium in the same in the same way it's they can extract some information uh about level layer seven TCP events like HTP but anything anything like how do you do http2 right where it's just streams of data flying through um and how do you do grpc and things like that so um implementing monitoring at that level for some of these protocols is going to be challenging and extracting more richer events for applicational observability it's going to be a problem and um if I can share my screen for a second more so sure I'm going show you what our goal is so I don't if you can see my screen so I goal with baaya is to uh do exactly this this is I'm I'm showing you open Telemetry demo which we have actually here in grao um and but this open teture demo is fully instrumented right uh with manual instrumentation there's been a lot of work put in here to actually get this data coming in uh so we have a service map because with this demo internally passes all those um Trace parents between the applications so we know that who's calling who uh we have all these different languages um and for if we open say like for example this ad service here we can see the jvm metrics this is where we're getting to with Bay this is our vision that we will be able to do the exact same thing with auto instrumentation that's our ultimate goal that you'll be able to wow get all this dat impressive all this data the service map everything how what calls what as well as these metrics without having to do anything on the applications themselves but adding baa into the system and I think some of these richer events require uh more than just what you can do at service meshes or network overlays because it's not just about the network events it's about Contex propagation between applications is about capturing some of these runtime information um and you know capturing error information maybe stock traces about errors you know I have errors and then getting information about what happened during that error um we'll be able to actually push the envelope on that in the future with the approach we've taken that's my belief and that's what we're aiming for those are some lofty Ambitions I'm surprised publicly committed to it yeah and just to say it's it's going to be in this year right um yes oh I meant yeah yeah wait it is 2024 now so yeah this month yeah sorry yeah thank you so much for for coming on we are out of time but this was this was really great to see exactly how to set up Baya and it seemed like it was pretty easy to to set up especially just Within kubernetes right yeah yeah if people want to know more about B where would you suggest that they go well we have uh repo has a lot of information um there's a lot of examples in I don't know do you need the link yeah it's right there down below it's also linked in the description on YouTube that's great um yeah so we have Nicole runs a tight sh y [Music] [Laughter] i yeah and so um so in here we have a lot of examples in terms of cetes deployments without cetes various modes you can run baa in tracking shli processes with systemwide instrumentation it's all in our tests um so and we found a lot of folks just dig through this in code and find the Obscure things we haven't documented but we have for the stuff we do support we have extensive documentation so another place to look for um yes exactly so this information here um so the documentation has a tutorial um extensive information about all the configuration options for f tuning and so on so that's the second place to look for um we've published we blog po account uh blog yeah I don't have a link for that but um but it contains mostly the information information um that we actually have in our documentation yeah okay great thank you so much for coming on and if anybody has any questions on Baya you can probably the best place is to go to either raise an issue on the GitHub repo or you can go to the Community Support Forum I think that's probably the the the two best places to go thank you everybody for for coming and watching and Nica thank you for telling us for for appeasing the demo Gods enough to get two demos out and for showing and for answering all of our questions yes and reminding me that I have a lot of stuff to look into still so do I so do I don't we all do all right thanks everybody for watching we'll see you next time bye all bye

