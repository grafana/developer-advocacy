# Grafana Beyla March 2024 Community Call

Recording of our second community call. We talk about some configuration options of Beyla and got super-valuable feedback ...

Published on 2024-03-14T10:34:54Z

URL: https://www.youtube.com/watch?v=TyAxmDjMH5Q

Transcript: so thank you to come and welcome to this second uh baa Community call uh we might we we will discuss some some topics but one of the topics uh I'd like to to demonstrate and talk about is about the decoration of the roots uh let me put some context I I have some some application s here deployed in in in a cetes cluster one is a simple a simple blog application there is another also another another application of of a service internally invoking other other services and I will instrument them with vaa so if you remember from the previous Community call we will just deploy uh baa 1.3 which is the latest version that has been released and we will send our data to um to open Telemetry I I got some uh deployed a credentials template here in which I put heers the grafana ofp heers and O um uh are you trying to share your screen or oh yes yes I forgot it it's it's okay because I by accident I I show some credentials and I was thinking okay I I need to erase that uh okay sharing the entire screen okay so this is the deployment file of a of a baa we deploy baa as a demon set so one instance of baa will instrument multiple Services uh it's important that in that case the baa the baap PO gets the host P ID access to the host P ID so it is able to access all the all the processes in in a given note and uh yeah we will configure baa with with the basic configuration we we will enable kubernetes metadata so it can decorate the the metrics with kubernetes metadata but will also be able to dis to discover the processes based on kubernetes on on on kubernetes attributes and here we provide just as as environment variables the uh open Telemetry end point and and credential the credentials is just a a a secret we already deployed um so a part of that it's important also to uh in order to let baa analyze the the the ports demo and and replica sets uh owning the processes to instrument it's important to create a cluster role with list and watch permissions for both replica set and and pots so we created a service account named baa the cluster role we bound this cluster role to this service account and then here we created this service account this is a necessary step when we provide a Helm chart or other means to deploying that should be more automatic and you you should do that manually uh in addition we have a baa configuration file already def defined here in which at the moment we only provide how to discover the services to instrument H we we will we which tell vaa to instrument all the services in two given name spaces the demo name space in which I have a demo service just to generate some some noise and the block name space in which you will see this in which is this block engine deployed let me deploy baa so everything is um everything is already okay baa should be running you can see here how baa found some some different processes this front end back end worker gener is this demo service and this go block is the is the block engine so after a few seconds we should already see some information in grafana let me just uh do some some invocations and we should start seeing some some metrics okay you see this uh diff the different function services for HTTP we could also uh we could also uh quer RPC services but this metc is only ATP we see this block go block demo back end and and demo frontend uh and they the metrics have an HTTP root attribute uh that is is actually the HTTP route but this is uh this is by default set to a wild card asterisk let me increase the size ER to avoid cardinality explosion because this cardinality cardinality explosion might lead to to some to some uh problems um I will H we can tell baa to we can tell baa to maybe just St any value in the in this or or the the row value of the path in the ATP route but to avoid cardinality explosion we can tell ba how to group The The Roots by pattern for example this this this block engine has some some some some common paths like for example the the path entry um slash er a given a given a given identifier of the of the of the page so here we can say a Roots section with the with the patterns to to capture for example [Music] something like that yeah so B is super cool because I can deploy it um sort of in a you know in Cube system or in its own namespace and it can provide observability for a whole bunch of different kind of unknown workloads running in my cluster um yeah have you thought of how of a like in the like right now you have to centrally write down all the routes um which doesn't like isn't necessarily very immutable to that pattern of like oh the infr team deployed baa to get a bunch of stuff and the application developers don't need to care how do you see like Baya evolving or the config surface Evol so that it's good good good good question okay yeah this is this is actually the the the the the what I was doing now is the path to follow when you know your application and you can provide detailed ER information here or information that is bounded to to to to what you want to get for example if I only wanted to get patterns about the entry I I could just do that and forget about the others but it's true that when you don't know the the patterns you can also so set this property on Match listic this way what will baa do is it will look for Gish in the in the patterns and then we'll we'll insert an asterisk where it found some Gish in in in in some folder assuming that this is an ID or this is a changing number let's let's first deploy with that and it it usually works pretty well uh for example uh let me redeploy that I need to delete and apply just to apply reapply the config map uh yeah now now we are running in in theistic uh her istic mode for these matchet patterns let's see how it works by default okay got some not yet getting it let me check if uh I sorry un matet I I misspelled yeah now it should work let me generate some traffic and let's go here to grafana now okay you could see this uh for example in the go block you will see that it it already added this entry static uh uh for example static entry is this is just the the is part of each each entry and static is for example for the for the images they have this static so uh baa already got this this by default theistically so that way we can get information about the paths without having to to specify all the all the roots but even in even that in some cases the Gish or this ER this sistic shouldn't work imagine we have a I don't know another kind of application in which you have a users and here the user is not a numeric but a user defined idea I don't know Wonder Woman info something something like that and this Wonder Woman will change across users y so now I get that document not found but anyway B will capture this uh in that case you can see that baa we will get a cardinality explosion so even in in some cases where theistic doesn't work in that cases we could apply the patterns that will be users ID info and in that case it will work okay that's good so you can override the heris stick with yes yeah you you in that case could provide more fine grain uh information yeah it accepts the the syntax or this syntax which also it's also used in in other in in other Frameworks so I think I redeployed so let me just call this for example users Wonder Woman uh users Luigi Bros and whatever and now instead of instead of getting or populating this route we should see this users ID info here this way we can it's a mixture between automatic and uh user provided information to deal with this complexity or or cardinality do you have you guys thought about at all any I'll say per application way of configuring it like as a really dumb example could I have a pod annotation that says here are my routes so that um users don't to um how would I put it like yeah that that's a centralized and like application team controlled yeah yeah that that that's a very good uh uh proposal we we we have been thinking we we are aware that uh this is a very very simple way to propose roots and even uh it is one single configuration for all the possible applications and maybe is not the best case always MH uh yeah we we without a per application configuration uh but your your annotated configuration it's also I have I just took notes because it's it sounds a good idea but since we we are just growing and the resources are limit we we were just waiting to someone to get this problem in order to to implement it and we we have been Focus focusing on other on other features but this this annotation based ER it's it's it's very interesting yeah I guess from my perspective the heris thing is really cool if I know all the applications that are probably going to be running um if I were to make like a blanket recommendation for someone to deploy this in a large cluster I would probably tell them yeah just turn off the route you'll get enough value from yourp stuff so like starting from yeah I mean I'm no user I'm a I'm a platform is person as well so I'm probably similarly in your shoes um and would look for user feedback but um to me safety is like a big or like not having cardinality explosion is like a big um a big win for something like Baya that can kind of sit in the background and and run um and not sort of cause any problems yeah yeah yeah yeah it's it's a it's a good yeah it's it's a I I I like your proposal also because I've been always thinking on one BA operator configuring it but it's true that this annotation based it will also help that each team will own or or will be will be in charge of uh an of configuring baa for their own services so it's it's a very good idea even if the card if you are not super safe with this cardinality with with this sistic because you might think that maybe in some cases it could explode cardinality you can always say a match it equals white card and it will just use the the patterns yeah and if if it is not able to to get them uh it will just set a well card then each team could add their own their own annotations yeah but yeah yeah I think it's it's a good it's a good idea I will I will I will annotate that feature yeah thanks and I I had another question about um kubernetes service Discovery so Baya seems at one point in time you recommended side cars but it seems like the the new and I expect like permanently recommended way to run B is going to be as a Damon set when you watch pod resources in particular do you know if you filter um that watch by the node name of the node that the Bor pod is running on or does it watch um all pods in the cluster um uh I need to look the implementation uh I'd say that at some point I I filtered by by note just to just to avoid having an memory copy of of of data you w use but I should I should the the implementation I I'd say we we we filter by by by note but I will make sure because this is something if it's not done it's something easy to do and and will save a lot of memory yeah but I'd say it actually filters and the only other if you have a large number of nodes in the cluster watching all of the like replica sets and deployments and stuff can get very expensive is is there a way today to turn off like the controller based metadata um uh yes in in that case actually it's disabled by default uh you you need to you need to set this variable at the moment it's disabled by the Ian yeah um I mean like if you enable that you get all metadata which means like ah yeah no no we we actually we Al actually only get we we have a kubernetes Informer implementation that internally uh it listens for for the the whole metadata but it stores just the information we need which is it's it's a very small stru I can I can even show it to you just to to get an idea of the of the information we get yeah I I guess I'm primarily coming from like I've done a number of security or scalability reviews for the GK team um and so I know especially for Damon sets it can be problematic to watch um replica sets or deployments or stateful sets or things like that because like with Pods at least you can do it the cub does and only watch the pods that are collocated with you on the Node for deployments there's no like way to Shard it by node effectively so if you have a thousand nodes that means a thousand things that are watching all the deployments and getting all those updates and such right um yeah yeah in in terms of memory we are just getting we are just storing this small just to reduce the the memory we are watching is this info in which we have this object meta because this is a mandatory field the Ty the owner so fear strings and even the owner is is a small so that that way we reduce the amount of memory in terms of consumption of CPU if you mean if you are getting always events and so on uh yeah I think we we we still need to to watch for replica sets because otherwise when we report the owner name or we are actually interested on deployment so uh when when you send a a deployment or when you create a deployment it will create a replica set and then the pods and if you want to get the name of the owner you will get the from the PO you can get the name of the replica set Y which which is some giv name so we we actually want to know the the name of the the deployment so that's why we still need to to listen for replica sets in order to get the the name of the deployment of of that of that P I don't know if it's a better solution or to to to to avoid getting too many notifications in the in the inform right well it's it's less I'm actually less concerned with the CPR memory cost locally um it's more that um it in large clusters it it uh it puts a lot of load on the API server just in terms of like okay okay okay I see okay and you say this happens especially for replica sets but not for po it so the reason it has to do with the interaction between a Damon set and because pods is a special case where you can filter by node name and the API server is optimized because of the cuet um to be able to um only generate the required watch events for Bas if you filter by node name when you're watching pods you only get traffic for um and they've done a good job of making sure that that works well um the details of which I'm not aware of but for replica sets and deployments and such there's no filter that you could apply so okay yeah now I understand yeah now I understand yeah and it's because it's SC with a number of nodes so and in an Ideal World in a large cluster you would have something like a cluster service or something that's doing the linking or that's doing the enrichment of adding replica set and deployment I suppose the the other option would be like make a guess you know it's like oh this this pod has a a funky or the the Pod has an own has a replica set owner ref I'm going to make a guess that there's a deployment behind that that has the the trim name or something like maybe you could get away with that but um yeah I think you understand the yeah yeah yeah yeah yeah it's yeah I I I I wasn't aware of these internal details so we never considered we never considered that yeah at the moment the only possibility is just keep this disabled then you won you won't get a kubernetes Discovery nor metadata decoration but right the thing I care about or the thing I would hope to be able to get is pod-based metadata okay okay yeah but not necessarily the rest of it because okay is designed to have things per node that are watching pods on that node right it's well optimized for that use case yeah yeah it's it's true we we we could yeah we could have an intermediate option metadata for base or yeah yeah yeah it's a good it's a it's a good it's a good point yeah yeah very valuable thank you MH yeah nice so yeah with respect to to to roots and how to configure it for kubernetes I think that's all we we already have oh we have another we have another topic it's basically about uh the B the debugging uh it's we can debug currently at three levels one is uh the log level we can specify it here or by environment variables we can also uh print to print traces uh that will will let or will show the traces in the in the standard output uh this they are formatted traces some Lo reader even could process them but is it the main intention was initially to to the back the to to the back the the traces there's a third option uh or or a third debuging option that is to uh debug the evf code but this is very internal to to developers you will need to to go to the to the kernel Trace pipe and the data is not really meaningful unless you are familiarized with the code this it's the other is really really the bugging but yeah at least to to get this information you can get this Lo level print traces and uh that will that will that in that way you will get some daa uh information or or some some traces printed here you can see you can see them uh there's also uh this this is uh more related for uh or or more aimed also at performance uh at performance analysis baa also allows to work in in profiling mode the documentation is is here in the the docs that's another that is the m profiling if you specify the baa profile Port Parable you will be able to use the go tool pro proof to analyze the the performance of baa it that that will allow us if if some uh user comes with some memory or CPU issue uh we just send them this receipt and ask ask them for for some for some different profiles and traces and that way we can we can analyze thatle if we redeploy baa me forward the bo uh so baa should be already uh working let me for example just send a a trace of just to load a a trace of the of the ah unsafe Port uh ah it's an unsafe Port I don't know okay I don't know what what what this means maybe some satanic people already choose that port for something it was not my intention okay let me try again okay that way we have this Hep so we can we can already look it and we can analyze this I don't remember how was the uh something like that no okay I don't remember to open the port but yeah that how was the port ah okay I don't remember how to how to open the a HTML okay I don't I don't know uh yeah but uh that way you can get the the heat profile or or other profile so this is a a very useful uh also feature to to get or to diagnose any problem we might have with with AA uh so and we we usually recommend uh to to to deploy vaa already with this profile Port because the we notice the the impact of this feature was was minimal if you are not retrieving continuously profile information so yeah I think we covered all the topics we initially planned for today I don't know if there's something else you are interested to to know about or to discuss about um what are the best ways that I mean what are the best ways for for others to help out with the project I know that there's like a core group of Graff maintainers that's been doing a great job it mostly and like filing bugs and trying things out and yeah we have yeah we we have a public a public H grafana Channel at baa channel in the grafana public slack so many people come here ask they come there they ask for problems but they also provide or ask for requests or or or discuss some solutions another way is directly here in in in the issues file an issue uh or even better if you want to contribute you you can send any any any po po request yeah we don't have already organized a lot the the how to work with external contributions because we we are very re very young project uh we are starting to have our first Community contributions uh for example these um Helm chart of this these what you see here fixed metric names we are starting to have small contributions that can be usually don't need a lot of discussion we usually accept them but yeah at some point we we will need to to to organize and provide extra ways for for or or a better Organization for collaboration but yeah at the moment any of the of the two communication channels namely the issues or the public slab are are fine yeah okay well we'll see maybe I'll have time to um do a little bit of work here and there oh that will be awesome yeah I guess in particular right now I'm I'm interested in seeing if it's possible to run Baya without the privileged or actually not just without privileged without capsis admin um I had a a little thread on slack um to try and explore it but um I was digging through cilium's docks and they were able to do it by using a privileged init container um yeah yeah yeah this is one of the solutions we got uh in the table and yeah we we are some some of the of our team members already had in mind to to explore that possibility yeah for non kubernetes because baa is baaya is also designed to work outside of kubernetes we were thinking in on either in in two different processes one process that he needs and then launches baa with less privileges or even in uh we were exploring the possibility of a process uh down downgrades its own uh privileges so it start as as root and and then removes privileges from himself but I don't know if it is or how it is possible we we need to explore but for kubernetes the most feasible solution looks as the init container yeah cool um if you need any help with that I'm very interested because um I actually got the GK security team to review and that was one of the things they came back with so yeah yeah so yeah I think you if you are interested you any collaboration will be appreciated uh but also yeah I will annotate that for for discussion with with other members to to know the status because it's something that was mentioned but I haven't heard of dat it yeah cool and then I think there's oh there's one other thing um so GK has a I don't know if You' call it a feature but there's a thing called GK autopilot which is where um [Music] you you only pay for your CPU and memory requests as a user so you throw some Pods at it and you don't get's back and GK hides all the implementation details it tends to be locked down um and in order to run some you wouldn't be allowed normally to run something like Baya um but they have a process for onboarding sort of party well-known workloads um and so I I understand that like you probably have lots of priorities but if it's some point you're interested in making or in getting Baya allow listed for GK autopilot um connect you uh to the right okay okay okay yeah uh I will I will annotate that and we can discuss it uh later yeah and I totally get it if it's not like super high on your list of things you care about um because there no for sure if if if everything goes well yeah as we would like uh for sure some sometimes a customer will come and say I need that on autopilot so it's it's it's it's okay to advance these kind of issues and yeah and discuss maybe it's not our top priority right now but it's something we need to to spot in the rather definitely cool thank you MH yeah so I think we are ending uh on time the time is ending so thank you very much for coming and hon thank you a lot David for all the feedback uh because you you you brought some some multiple topics that weren't in my in my RAR and and are very important to consider yeah thank you very much you're very welcome and uh cool that you're doing community calls and stuff too yeah every month we'll be here yeah thanks a lot and also Mario thank you for the presentation was it was great it was nice okay so thank you

