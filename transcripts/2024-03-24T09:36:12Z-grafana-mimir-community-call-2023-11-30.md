# Grafana Mimir Community Call 2023-11-30

Grafana Mimir Community Call from 30th of November 2023. We have discussed changes in upcoming Mimir 2.11. Join us on the ...

Published on 2024-03-24T09:36:12Z

URL: https://www.youtube.com/watch?v=24unSUPw_ZA

Transcript: um this is November 30 2023 graor Community Co um we'll go through the notes we have um that's not too big up the recording thing um okay we'll cut that in in post processing um cool so we we're doing the 2.11 release um in the coming days I think we've uh We've cut the the change lock and now we're in the process of getting a release candidate so maybe in the next two 3 weeks um 2.11 should be out it includes a few a few features um and some some experimental features promoted to to stable and enabled by default um yeah Nick or I think the first is is native histograms with cryo speaking of yeah speaking of experimental features native SS is still an experimental feature uh mostly because it's experimental in promes as well so the the new stuff that we including 2.11 is um some basic documentation on Native histograms like on the concept and then how you instrument your applications for it how you send them in just them and how you query native histograms um and you can probably find this information uh not in an easy way but you can find this information uh around the pritus docs and and code as well but uh this is more like in one or in just a couple of places uh where it's easier to to find and and hopefully follow um and then uh we already had the feature for Native Storrs where you could reject native Storrs that had too many buckets because technically a native histogram can have a million or more buckets because it's it's a it's an integer like the 64-bit like and you can have many buckets but that's obviously not very practical to store like if you have one bucket per uh observation that's not going to be very useful as a histogram um so we had this feature to reject uh Native STS that had two main buckets but uh in some cases that's like a bit too harsh so we implanted the feature where if we see a histogram that has too many buckets we try to reduce the resolution first uh and just merge buckets and you know like half the number of buckets until we we fit inside the the limit um the native histograms has a minimum resolution so we can do this for everything but most mostly it should be possible especially if you have like a reasonable limit like you know above 50 at least um you can also turn off this feature if this is causing any problem because this is very new uh but uh we enabled it by default because again this is experimental feature so we're not afraid to change it um and then related to Native histograms um there's a lot of boxes have bent into pritus and thereby therefore into mimir as well uh also through pritus bug fixes went into graphon agent so um now it's um possible to scrape native hiss uh with graphon agent although this is available only in in flow mode and then um there were a bunch of uh fixes in in the graphon UI as well to make them more useful uh especially in the um histogram and the heat B panel and uh I mentioned docs um in the docs you can find how you should how you need to configure prome and graphon agent to scrape for Native histograms and uh in the MIM dos I mean so that U you can hook them up and uh there are some caveats as well there uh that's documented that's good to uh know about and uh just to talk a little bit about the future the next uh thing for for the documentation will be more around open Telemetry versus native histograms or as they call them exponential histograms um but that's it for for Native histograms for today um do you happen to have a link to the to the docs for for oh yeah I can link the docs sorry yeah I'll do that right somebody else speaks yeah um and then some some less big features um that we' got into this release first one is the retry after header which in worked on yeah uh we introduced the ret after header um in the response for all the recoverable recoverable errors like 500 or 429 uh because uh during the operation we have realize that some of the during uh some incidents that agent op will try way too fast and it will cause some side effects like thundering hurt um so from uh the release to. 11 you could set up that Hider to protect the MIM right path a little bit better so how that is calculated it is composed with a base and retra attempts uh let's say you have a base of a three retract attempts is equals to one that means uh the retract after will be set at three mtip by two power ret attempt minus one uh that means three and then uh random from three to six and the second ret TR will be from six to 12 uh it's still experimental feature that we have test ourself internally so please try it out and uh provide some feedback uh if you you do have any so this is disabled by default now yeah it's still disabled by default yes ideally sometime in the future it will be enabled by default um not not all versions of the agent support this and like Prometheus do you remember what version of ref agome I know grafana agent is uh uh 0.37 uh three uh but or two yeah I can double check that okay and then prus prus used to support this from a long time ago maybe I'm wrong I want to say it supported it for 420 9 but the support for 500s was new MH okay um thank you Nick okay I'll maybe we'll find this later um the next thing I want to mention was the store gateways pass headers so now they're enabled by default this was an experimental feature that go into 510 I think um into uh 2.10 um now it's enabled by default it should help by should help in loading blocks into store Gateway like way up to 90% so it's it's really helpful when you have lazy loading enabled which is which is the default so if you haven't touch lazy loading then this should help you so around scaling store gateways um and restarting them um yeah and also querying long into the past should now have much lower latency um another thing which was enabled by default was the ingestor to qu chunk streaming so this is a new way of the ingestor sending back the responses to queries to to quers um previously they they'll pinch up everything into one response and then send it over now they they send um chunk by chunk or I mean bit bit and then the querier evaluates from K in the in the background um so you should speed up in theory queries but um also reduce the memory of of quers um if I recall correctly I I think that's it yeah um and then last one is last one we have on the agenda is query blocking uh lck do you want to say word yeah this was a a community contribution from uh from Wilford um it is the ability to specify regular expressions for a particular tenant and block queries that match those uh if you have a user who's sending uh maliciously bad or just carelessly bad queries you can uh you can block them and they'll get a they'll get a message and then you know contact you say what's going on but you know just another thing to uh to protect your a your cluster yeah that's that's great yeah thanks to wford for for this we we had a use case for this internally um since it was at it um yeah I think we're done with the agenda unless someone has joined in the meantime we can J this cool thanks all for for attending um if there's anything find us in slck um or drop us an email nobody drops emails yeah find us in slck the gr Community exactly see you see you

