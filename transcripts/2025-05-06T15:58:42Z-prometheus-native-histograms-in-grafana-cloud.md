# Prometheus native histograms in Grafana Cloud

In this demo video, Gyorgy Krajcsovits, Senior Software Engineer at Grafana Labs, shows you how to use Prometheus native ...

Published on 2025-05-06T15:58:42Z

URL: https://www.youtube.com/watch?v=myP3mRIUFps

Transcript: Hi, my name is George Kuch. I'm an engineer at Graphonol Labs. On my screen at the top, you can see an example of a Promeus native histogram with standard exponential buckets shown in a heat map panel on the left and as a histogram panel on the right in graphana. Standard exponential buckets means that the buckets where we count observations are automatically calculated from an exponential formula. In this particular example, the observations are the response times for a service. Thus, a bucket shows us how many requests were served within the bounds of that bucket. For example, this bucket means that we responded to 144 requests between 110 and 120 milliseconds. Just for comparison, the same observations are also recorded in the classic histogram shown at the bottom. The classic histograms of Prometheus usually used just a few predefined buckets due to performance and cost limitations. The difference is quite striking. In this video, we'll show some of the ways to use native histograms in Graphana and in particular how those panels at the top were created. We prepared a script that you can run that sends some test data into your graphana cloud stack from a Linux terminal. In real life applications, you would set up something like graphano alloy bromeus or the open telemetric collector to send the data. But that's a story for another time. We are now in the Linux terminal where I have already downloaded the provided test script into file called generate.sh. So if I list files, it shows up. To run the script, I do need to make it executable. So I'm going to run change mode on it. That's it. The script is going to send some histogram samples into our graphana stack via the open telemetry endpoint. But in order for it to do that, we need some information about where to send the data and how to authorize the sending. I'll make the terminal smaller so we can see Graphana as well. I've already logged into my graphana stack and the information I'm looking for is under the home menu. Uh account in the middle and stacks to the right. So if I click stacks, this takes me to the graph cloud portal where I need to click launch on the stack that I'm working with and find the tile called open telemetry and press configure. To set up the script, we're going to set up some environment variables for it. So first we're going to copy the URL and set the environment variable URL to the value. Do the same with the instance ID. So copy the instance ID and set it as instance ID and then create an API token. Uh we can give it whatever name. I will just lock something and I keep the default scope and create the token also copy the token and send set it as the API token environment variable. The name of the metric that will be created is blog request duration seconds. So blog request duration seconds. On the off chance that you have a metric with the same name, you can replace the block part with something different using the environment variable prefix. But I'm just going to stick with blog. Now we can run the script that sends some histograms into our stack. The script is actually sending the histograms backdated to 10 minutes ago. So we don't have to wait 10 minutes for them to be sent. If you encounter any errors, please make sure that you have bos and curl programs installed and that you copied the URL, instance ID and API token correctly. You might be wondering why we are sending open telemetry when we talked about Promeus native histograms. But actually open telemetry expansion histograms are compatible with Tomato's native histograms with the standard expansion buckets. On the other hand they were a bit simpler to encode in our script and we can show off the compatibility at the same time. So we're close to finishing the script and now that the script is finished uh we'll move to graphana to show you how to set up a heat map histogram panel and a simple quantile calculation. We are back at the graphana homepage. Let's add the dashboard where we can have our panels. So on the left I'm going to select dashboards from the menu and from the right top new and new dashboard and we're going to add a visualization. The first thing I need to do is select the data source where the data comes from and it's going to be the Promeus data source usually ending in dash. And since we want to heat map first, I'm going to select heat map visualization type on the top right. Now all we have to do is get the data into the heat map. So I'm going to select my metric and as of now histograms in Promeus are cumulative which means they count observations throughout their lifetime like a counter. But it's more useful to show the rate of change over time. So, we're going to apply the rate range function and then the sum aggregation. Even though we only have one time series for this metric, in real application, it's usually more. So, it's good practice to do sum as well. And just as a side note, always always apply the rate first, then the sum to get the correct result. So, let's run the query and zoom in on our data. As you can see on the y-axis you have the buckets on the x-axis you have the time and we can see that we have many many buckets in fact the test data uses an even 100 and some things I like to customize on heat map is the colors first. Uh so I'm going to change the color scheme from oranges to spectral there. That's nice. And at the bottom uh you have options for the query and you can enable your exemplars if you have them uh which the test data doesn't. And also since the data that we sent is 10 15-second resolution we're going to change the step to 15 seconds which gives a better resolution on the time axis. And from the heat map we can see that the majority of the uh observations are in the middle. So we we will extract a classic bell curve in the histogram panel. So let's create the histogram panel. So I'm going back to dashboard. I'm going to add a new visualization and this time select histogram as the type on the right. Histogram. Got it. And we do the same thing as before. Select the Prometheus data source. Select the blog request duration segment metric. do the uh rate over time and do the aggregation sum and run the query and we can see that indeed it resembles a B curve. Now we did add a little randomness to the data. Uh so it's not totally smooth and you can see it's a bit randomized. Okay. So finally, let's take a look at the quantile calculation. So I'm going to go back to the dashboard and add a new visualization, but this time we'll keep time series. Again, we'll select the data source uh fromus-prom. We select the metric and as usual we are interested in the rate of change and we might have multiple series. So we're going to do the sum but this time we are going to also calculate the uh the histogram quantile. So we're going to apply the function histogram quantile and I'll leave it at 90%. So the quantile 90% will show us what is the estimated response time that 90% of the requests finished in. So basically 90% of the requests finished in less than 4.91 seconds at this time. And one thing to note here, if I look at the code that um for those that used classic histograms before, you will notice that there's no byle close here. So there's no sum by la um because for native histograms, we have a single time series that doesn't have the le label. All information is encoded in this single time series about the histogram. the overall count, sum and buckets. In fact, to get the overall count, we need to use a function called histogram count. So, let me demonstrate that by rewriting this query to have count and just the sum rate of the histogram. And that's how you get the overall count from the histogram. There are actually other functions for native histograms, but for now, this concludes our demonstration.

