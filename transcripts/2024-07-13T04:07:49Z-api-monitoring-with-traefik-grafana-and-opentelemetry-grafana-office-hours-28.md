# API monitoring with Traefik, Grafana, and OpenTelemetry (Grafana Office Hours #28)

Maytham Alfouadi (Solutions Architect) and Imm√°nuel Fodor (Product Manager) from Traefik Labs give us a demonstration of how ...

Published on 2024-07-13T04:07:49Z

URL: https://www.youtube.com/watch?v=1Buk3wPpJdY

Transcript: hello now started hello everyone welcome to another Gana office hour sessions uh my name is Usman Ahmed and I work in grian as a developer Advocate and today we have someone very special from people you know a lot from kubernetes which is known as traffic Labs which you use a lot for routing and load balancing and I'm joined with Nicole Nicole hi I'm Nicole vanderhoven also work at Gan labs just with usan and I'm really excited for this because this is actually the second time we're doing this because the internet ate the last time that we tried this so welcome to our friends at traffic Labs who thankfully are still our friends despite the first one being eatan would you like to introduce yourselves yes thank you Nico I'm Emanuel I'm product manager here at traffic Labs uh and uh I'm happy to be here second time hi everyone yeah my name is mam I'm a solution architect here at traffic laabs and yeah pleasure to be here and thank you for guys for having us yeah thank you um a little background for the context so uh I was in a conference last year in December it's called the uh API conference uh in Paris which is really a big one and I met traffic LA booth there and what I learned was amazing that they are doing a lot of amazing work a lot of amazing work with Gana and when I talk to them that if they're interested and uh yeah and it shows their commitment they are here second time despite the fact the first time as Nicole said the internet ate all of the videos so yeah uh thank you again thank you for coming here again yes at our boo we had a TV running with the demo and uh at some point graphon was visible and it really stole the show because so we did some uh uh very uh interesting stuff which we will also show uh in this webinar so uh yes uh we did let's say an indirect advertisement for you guys well we're happy to have you on our Channel this time and then I also met you at cubec Con in Europe yes cubec con Paris and actually when we met uh uh you were printing some models at your boo so I have this graph lovees muscot and this other one and actually I have a sock a pair of graph socks with me so but you still haven't used them yes it's unopened I I kept it like a souvenir yeah I also was using My Gana Socks today Mam and I we have to wait for our turn oh yeah and I'm als oh you can't really see I'm also I can represent gra here like this I have your oh cool okay so 3 to one gra oh yeah I know yeah well there we have a lot in common right I mean of course we our our company's names end with Labs so already a good sign but maybe you can tell us a bit about traffic labs and what what you do oh yes and also because you have an open source version of grafana uh that is also a similarity to traffic Labs because we have the traffic proxy op Source version uh which is widely known and uh uh now we are over three billion downloads on dockerhub we are top 15 image most downloaded image on dockerhub so uh it's going strong since Emil created traffic proxy u in 2016 it gained traction and uh we still uh even though we have some um uh paid products uh we still open source at the core all of our other offerings built on top of the open source proxy so yes and maybe you can uh tell us the audience a little bit about like how traffic Labs uh get the popularity when it comes to Cuban is how it works with kubernetes just a little high level information oh yes sure uh so uh the thing is that Emil fa at the time uh uh that day I'm not sure even kubernetes was a thing even Docker started to uh became popularity so uh the the actual challenge uh uh was at the time that uh those riverse Proxes those web servers uh at the time were not Cloud native were not operating with containers the dynamic configuration was uh uh uh something that uh uh was not existing service Discovery was uh in in in uh Early Childhood at that time and you needed to add uh manual configuration each time you loaded up a new uh um Upstream in your uh uh um environment with your application and uh this is where uh traffic uh uh the need for traffic was born because uh Emil wanted something that highly automated and uh can operate with thousands of microservices so we can truly say that it's a uh it's a truly croud native solution and uh it was born for containers and uh now that kubernetes has gained huge popularity uh we even call ourselves kubernetes native uh because everything can be configured through kubernetes CRTs custom resource definition s and uh this is uh uh what really differentiates us and our configuration model also takes into account that uh pods uh containers can come and go their life cycle is highly Dynamic and uh this is uh uh what a unique aspect of proxy is that uh we have a separate static configuration which is like boot time uh configuration that you set once and you probably don't need to touch for the uh um like a lot of time and then uh those things that can change frequently like routing configuration uh new Services New certificates and so on all these things that are highly Dynamic and go into the dynamic configuration that doesn't require full proxy reload when it's applied so you don't lose connectivity you don't lose any active connections uh you can maintain High availability or your slas are not affected at all so yeah yeah I can only say one thing that uh I I was also like uh start using or learn about knowing about graphic life when it comes to R routing in kubernetes because as you said it was very Dynamic and a lot of manual work needed before but nowadays it's very much easy so yeah thank you for creating a good product yeah thank you and uh and you know um even the the um uh a appreciation from the community all the feedback that we get is uh uh very similar to this that it takes away a lot of manual effort and uh probably this is why that now with uh ranchers K3 uh D K3 s uh uh this kubernetes distribution we are the default Ingress so whoever starts playing with kubernetes and even on the edge you can use it as tting res controller but it can also run on uh uh High uh production workloads in the cloud uh uh different environments uh like be meta virtual machine Hashi Corp Nomad and Docker swarm and so on so we have many many providers supported uh so over the years uh it's uh it's uh it became more and more uh uh popular and more and more uh providers supported and uh yeah this is something uh really production ready and we are now at the third major version which uh is uh I think awesome uh we can talk about it later Emanuel you mentioned a reverse proxy could you also just tell us talk a little bit about what a reverse proxy is and why you might need that yeah sure so uh as soon as uh you uh scale up and uh you start serving your uh workload not by one uh server instance but by uh multiple one you want to distribute the traffic you want uh to use maybe the same domain name uh for different services and because of Microsoft Microsoft service architecture sorry uh there is also uh the need uh that now uh you can put many services behind the same domain maybe put different services on a separate URL pass uh or serve different versions uh with the same uh uh URI uh but uh with different uh version headers and so on so you want uh uh uh to have something acting as a Gateway as well uh where where traffic comes into your infrastructure so you can put centralized control on top of it um and and uh also when uh traffic spikes happen you want to have some rate limiting and uh and and so on you you put this uh uh component uh in front of uh your services distribute the C set up some rules uh and and basically uh what the reverse proxy does is serving some other backend services so passing requests back and forth uh at the simplest uh uh explanation uh but uh here lies uh the the valuable uh uh the value proposition that now you can do a lot of things at the central location mam as you are a solution architect do you have some other definition or no no you pretty much sumarized it pretty well it's it's like you know having the English control the Engish controller is a way of exposing all your internal Services uh that is hosted on whether or your Docker environment or C's environment out out to the outside world and it centralized in more control uh manner so you will you can uh have a central point where all your services can be exposed uh and you can control access to these uh backend Services um and and apply um you know modifications or security layers um and uh all in through a central point yeah if you think of it it as a North South traffic maybe uh this is also a term that you can be familiar with yeah yeah so um the the reverse proxy it means that you don't have to expose your application directly you're like adding a layer between the outside world and your application and that layer makes it easier to Well Route the traffic which I guess is where you got the the name right um and there is that part of it where it's about accessing the right services but there's also the load balancing kind of bonus for it right because uh it it is also very useful for when you're experiencing your your application is under heavy load because then you can just switch the routes without changing the application is that yes correct and M mentioned also another uh interesting term incress controller and that is more or less kubernetes native uh uh term that now u a reverse proxy can also act as an Ingress controller so this is what handles the load coming into inside uh to your cluster so everything is uh that comes in it's like an Ingress traffic there is also ESS traffic that leaves the cluster yes uh but uh this is an interest controller yeah and uh this is like as you said it's it's a normal standard now to know uh to use this thing in production because traffic comes in which is ingress and going out agress and you need a controller to distribute the load uh and also do the routing and uh based on that I think uh you have some uh some slides for us to tell a little bit more about it uh yes if you can bring this up please uh I have a slide showing our product portfolio because what we were talking about so far is the application proxy uh this is the op Source version but uh as soon as uh because a proxy can expose anything it can expose HTML uh webites uh uh images assets uh and even apis and as soon as you uh uh expose more and more apis uh which are basically what powering the internet these days or the mobile applications connect to apis even the web applications with separate front end connect to the backends through apis and uh even machine to machine or llm AI applications connect to other services through applications so applications uh May uh has a main role these days that will probably even uh intensify as we move forward in time and for this use case specifically we have a special product called API Gateway uh this is the second one and uh this one is specializing in exposing apis with uh Enterprise uh ready middleware or plugins um and uh now you Cann add even more authentication for example proxy uh can support basic authentication or other means of authentication which are good for home lab are good for starting uh to use it um but as soon as you want something Enterprise like oidc or Json web token based uh uh authentication or o token introspection and so on you will uh want to have an API Gateway and uh even when you reach a state uh when okay uh you now manage uh all these uh things at the central location you don't need to uh Define Authentication on the microservice level you can move it up to the Gateway um authorization uh then you probably reach a point when you have a multitudes of apis you have a lot of Fleet of apis and you want to enforce some other governance uh rate limiting API versioning uh want to have a developer portal when you make all these things discoverable and easily consumable by your internet developers or external ones uh and this is when uh API management comes into the picture and uh because everything is based on uh the open source proxy it can uh run uh in all uh uh environments but uh what is very unique with us uh is that we have a model where uh we have a a so to say a seamless migration Journey uh where you start with proxy you install it and then you want more uh we give you a license key you do a simple Helm upgrade and then you land with API Gateway the change uh it in introduces is additive so you can uh still have your existing configuration it understands everything what you did with proxy but on top of that uh you added uh more uh uh configuration uh more uh options to leverage and then again we uh give you a new license do a h upgrade and that's it now you land it with API management you have a developer portal and so on but all these uh uh have everything uh what proxy has so for example with the latest uh V3 version release we are did um VM based plugins and uh now uh VM based plugins are available in all the portfolio but for example while proxy has a VM based plug-in uh as a v web application firework as a VM based plugin uh the API Gateway comes with a native integration which uh uh has uh 23 times more performant uh uh than the uh plug-in based one so so you get additional benefits more capabilities As you move forward so this is uh our portfolio but I don't want to uh push the sales side too much so that's it for me no that's very nice and uh the the slide you show so all this management uh and for example like I I know a little bit about apis and one thing which everyone encounter is the rate limit so do you have like a a UI or so how how you how you how you allow the users to manage the rate limits as an example yeah so for example VI proxy has a let's say simple rate limit that is perfectly usable which is great uh and uh many people are happy with it the Gateway comes with a distributed rate limit and uh what it uh how it differs from the let's say simple one is that uh uh when you scale up you have more and more proxy instances handling the load uh and uh uh then uh with rate limiting uh if you set like uh 50 request per second rate limit all these proxy distances will have uh 50 uh requests per second rate limit uh so you actually uh open up your infrastructure more and more as you scale up you can do some manual adjustments but uh who likes to do manual adjustments these days so with distributed rate limit in the API Gateway uh you have a shared counter uh that is shared between the replicas so as you scale up uh no matter which uh uh instance uh the uh request actually hits uh the rate limit uh is counted uh to towards the same counter so uh you don't need to make adjustments the system does it for you and uh uh how you can make sense of it is uh uh first uh you can uh see clear configuration through kubernetes crd or if you run it in Docker swarm or Docker compost you can see set some labels which you can put into G and you can have a review process over it and so on but uh with uh uh traffic a unique thing because this is something available also with competition but uh a unique thing is that traffic comes with web UI where you can uh actually see the actual running configuration and this is uh from the feedback uh we get uh it's very useful people like it and uh now you can see if there is something like a misconfiguration uh you did or uh uh it's easier to start debugging because now you have a full visibility of everything that's applied that's very nice yeah definitely one thing for sure nobody likes uh doing manual work when it comes to deploying in production either you delete it or make it work if you delete it yes then you in deep water yeah and you mentioned rate limiting specifically for example in API management uh the the highest level of the journey uh you will also get uh linters static analyzer what we call uh which you can uh uh hook it into uh git uh like if you um have your repository in hosted on GitHub you can have it as a GitHub action and then you can uh run it through when you make a PR automated checks so it outputs for you if there is anything like a syntax problem or even deeper understanding so it's not just syntaxis but also semantics uh uh when you change a rate limit which user groups will be affected uh and so on and uh this is something uh helpful yeah so I have a question um on the proxy front one thing that I've used in the past is engine X so what what advantages does using traffic give over using engine x uh I can say uh top of mind the level of automation uh the verbosity of the configuration uh I think with engine X is pretty high you get a a big boiler plate from where you build up uh your uh own uh configuration with traffic we try to focus on really what matters come with C defaults uh just set what you actually need U and uh and this is something uh that first comes to mind also the dynamicity the configuration also the plug-in system is a bit different because in enginex it's a Lua based uh which is uh uh uh simple language to write uh code but uh but uh with us it's a go based either go based uh uh with the previous plug-in system uh it's also available even now but the future as we see it is VM uh because with VM uh you can write your plugins uh in whatever language you are familiar with in JavaScript or PHP whatever uh uh you like and compile it to a VM binary and now traffic can run it uh say something yeah well he covered it the the dynamic configuration is is kind of one of the main differentiator um that we normally see because basically any changes that you make uh it get applied on fly and only U if there's any it doesn't impact any of the other services um which is kind of that's different from the behavior that we see with the engine and uh one quick question uh as you mentioned in the new release the code is I believe 20 or the performance is 23 times faster so is this something also uh covering like this uh new uh VM part component as well or it is just for for the core part uh this is this is specifically for the web application firewall because uh uh now we have a a partnership with corza web application firewall traffic is now part of the oasp uh uh uh Community uh organization uh and uh ovas uh you know the oas's top 10 uh for security and so on we focus on security and uh now uh novas project corazza uh which is a web application firewall let's say a successor of uh mod security um because you know mod security has some challenges now it's deprecated it's not well maintained or not even maintained at all and now kataa emerged as the new uh uh Cloud native firewall and we have an integration in the open source version It's a VM based plug-in but uh in the API Gateway uh the license product uh it's now a native integration so here here is the 23 uh times uh more performant when you have a native integration because you know it's not a uh a different binary you need to call in runtime but it's built uh baked into uh the traffic code base but uh uh in traffic proxy uh further uh release um I think it's around uh uh 3.2 uh as far as I remember the plan um we will have a fast HTTP support so this is not something like a secret I'm telling this was already shared by Emil in our recent webinar uh so uh we did some benchmarks and uh uh with the fast HTTP it's a new go binary uh new go Library uh that uh proxy will use uh we will gain uh 30% more performance compared to enginex so this will be huge well I must say definitely you guys are not stopping you are achieving one milest one after another which is really nice and this is how we thrive in the IT world yes and uh I must say that we are not a big company uh and uh we depend uh hugely on the community so we are very very thankful for every and each comp contribution uh the com uh the community makes so uh thank you so much and keep coming the PRS we do weekly triage and move forward with this uh so thank you we try to listen nice um yeah Nico maybe we could yeah please maybe we could talk a little bit maybe you could zoom out a little bit um you mentioned already uh that m in the in today's like more modern microservices based architectures traffic is particularly useful because it um it just takes care of a lot of the manual work for you and maybe we could also zoom out to observability for microservices in general because this is the space that traffic would play in and so yes and this is how we reach yes because now you have a center of priest uh guarding your infrastructure uh securing it and making it observable even and uh I think uh the observability is something you cannot ignore as a uh being in the IT industry uh being a devops engineer even as a developer because uh as soon as some problems uh come uh you will what you do you will uh do some debugging and uh where to start you see some dashboards uh when the error Spike happened uh uh how it was uh how it took in the first place how it happened and yes observability not just metrics uh where Trana graphon shines but also the tracing loging and uh uh so on is a really big topic uh yeah yeah um and sorry uh mam you want to add something here yeah and I I will be covering a part of this in in a demo where we go through the the different uh dound dashboard that we have developed to provide that centralized view uh on all the aspects of uh the application yes yeah I I just wanted to add one small thing here about uh What uh when it comes to observat yeah this is something noways not can be even ignored by even you have like a simple web application because there there there are multiple layers like when we talk about Docker Docker even has a lot of layers if you closely look into it you can find a lot of useful information and especially when it comes to on talking about on a more higher level or bigger level uh like uh uh routing scaling and uh load balancing then you need a component which is observ to check and see everything and uh definitely Ely we will be looking forward for the demo that M them excit us yeah maybe before we start I share couple of uh things uh we support uh prome studs D and um data dog and influx DB but recently we added open Telemetry to the picture uh which is a new format uh to ship metrics uh logs and traces uh maybe it's not new but for us uh the support previously it was open tracing and now it's open Telemetry and previously it was I think open metrics and now it's open Telemetry as well and uh this is a new standard uh with the go um SDK that open Telemetry provides uh tracing uh and metrics are production ready we use it you can leverage it it's inside traffic proxy V3 as well um and uh now the logging uh part of the library is in beta so uh whenever it will be uh uh stable and usable uh we will definitely uh want to incorporate it so you will have a standard way to ship all these observability information so when you say that traffic supports these um what exactly do you mean that it it's already that it comes with you already have preconfigured uh you know kind of a yo mthm I think you you're muted yeah you so it's it's a it's a native integration with the the tool so every tool has a standard of how you explore these information uh so we have it we we uh implemented this natively in our product you just need to add one line on how you Expo you want to export these information and it will export it to whatever um you know whether it's a preus or data dog um it's just the two lines of configuration that you add in your uh St and your information will be exposed yeah so I think that means that pretty much everything like all the databases in grafana Labs would also be supported through through otel and you already had Prometheus support so that's awesome yes and even an interesting thing that promethus can ingest an uh open Telemetry metrics format natively and because uh you can build your graphon dashboards querying promus with their prom ql language uh as soon as you switch the the format how you ship your metrics it's not not a text based promit format but uh now even binary uh open Telemetry format uh your dashboard stay the same you don't need to change anything all right shall we get into the demo yeah M them please all right okay so uh today I'm going to show you uh traffic Hub API Gateway and management capabilities and how we um use provincias in graph to um basically uh provide visibility into all aspects of uh API and ingress level metrics um looking at the um traffic Hub API Gateway dashboard you see a lot of similarities with the open source dashboard uh that if you're used used to traffic open source proxy uh or application uh Gateway you will see that it's quite similar that's because it's based uh on top of the open source uh but it adds uh many of the Enterprise level features uh if you look at the um we already have many uh application exposed uh through our uh API Gateway um for example we have uh our uh who am I uh app uh it's it give you kind of a nice overview of how is it exposed what kind of middleware Applied you can see those we're already using or IDC uh deployed uh with a header modification uh into the request so the dashboard is kind of it's great it give you a like a good overview of how your applications are exposed or how the traffic is handled for each of your backend Services um for more advanced API management capabilities uh that can allow you to manage your API at Scales uh we have the uh traffic Hub uh dashboard um it this is a just a simple switch in your API Gateway uh deployment uh and that will provide you with uh this capability where you can um manage all your uh apis from centralized view uh you can see all your um API Gateway status uh the health and you know give you verion check uh you can manage all your apis that is currently deployed on your cluster uh you can interact with a different version of the apis uh if you have one uh you also can see uh the access control level and if you have a granual access policy applied which methods are allowed to group and also from the access policy which is the most important things when you working an Enterprise is you want to see who access who has access to the API so this give you a nice overview on the relation between who's your audience in this this example we have a support group uh they have access to two uh different apis and also they are restricted to specific uh method that they can access the API um the other thing that we can um have from here is a URL for all the developer API developer portals that you can access through the API development portals uh you can um access the portal um each portal uh is automatically projected using a built-in identity provider uh but you can integrate it with a third party identity provider like uh uh OCTA or um Microsoft entra ID um once you log in uh you will only be presented with the apis that is allowed to you based on your access policy that we just went through so here the admin has access to all of them through the API develop portal you can actually interact with different version directly from the portal um you can see the the rate limit policy that is applied to you so you're kind of aware of how many requests that you can use um during your testing um also we have the capability of managing an external API so what I mean by external API is an an an application that doesn't actually reside on the comp need cluster uh so you probably have a few apis that are running on a VM or a Docker swarm uh that you still would like to expose uh and manage through the Hub dashboard and apply all these policies on top um this is we allow to have the exposing apis through Ur uh so now if I log out and try to look back again with the support account as we saw uh the support account has only two um apis allowed to it uh and kind of that's the two apis and they are restricted to the the method um that that they can use yeah please click please click on one of the operations that's the fun part because now you can even try this uh live here and so on so you get more documentation yeah yeah so everything that we've um deployed or everything that we've gone or saw is uh deployed on our kubernetes cluster um and it's since traffic is is fully declarative all the Manifest files are hosted in our G repo and we have flux CD deployed and our kuet cluster and flux ensure that our KU cluster is always in sync with our uh Reaper cluster our Reaper uh having all um all the files all the Manifest files uh declaratively defined and hosted in G it allows a centralized a place where everyone can collaborate and and and um in one place and develop make any changes before pushing these changes into the environment um we also offer uh I think a manual test on this uh a static analyzer that you can run locally on your cluster to provide um um ltering and and uh change um verification but also you can integrate that one as part of your uh github's pipeline uh which we what we've done here we've integrated as part of the uh GitHub action to run checks every time we try to make uh a CH a change so for example here if I go um and and try to make a change into my uh distributed uh rate limit that we have uh this is um I can quickly um change the LI so now I I was I allow I had uh 2,000 requests uh every 65 seconds and I'm going to limit it to 20 um this change um obviously you want to raise a PR request for it uh we can raise a PR request and then you can have a reviewer to ensure that if the this change is approved or not but for the demo purposes we'll just go with it and here you can see the static analyzer is is running uh and and is doing good job um what part of the job that it does is verify if the configuration is correct but at the same time provide you with the change assessment uh the change assessment show you that that line that you changed the number that you changed will have an impact into all these level of apis so if this is something that you expect then that's that's good we can go ahead if this is something that you didn't expect it kind of prevent from pushing misconfiguration down to your cluster so it give you kind of an impact assessment before you actually push it so now we we make the we mag change and then um flux will do his job and update our policy uh so just one one quick question so like this example if if a user gives uh uh rate limit which is not bound to bound to it like maybe the user is only allowed for 2,000 request and giving uh itself 5,000 so this also uh tell uh tell the user okay this is this changes are not going to apply because there are limitations placed as well and so this will be deployed by the uh the admin so the admin will have access to modify these access policies uh from developer perspective they probably will have access to only the their code uh uh to modify they won't have access to modify the uh access policies yeah but for example uh within traffic Labs we also do the same we have a repository describing our infrastructure internal clusters demo clusters whatever we have and uh uh anybody even I have access made them as Suess and in case we want to introduce some change or improve anything or ask for anything then we can open uh PR and uh the developer uh the devops engineers the platform team checks uh the uh change and if they approve then uh they merge but this is very helpful for them because they don't uh uh need to um uh maybe you as M them did just just changed one number but the effect is uh so wide that now it's very visible uh who will be affected maybe you just wanted to increase mm's uh uh uh rate limit but it turns out that you would increase everyone's uh so you can uh spot this easily yeah yeah definitely this is this is very helpful yeah please continue very yeah so yeah so now you won't have a centralized API governance without knowing how your API is actually performing and here where observ come U into play so as you can see um we've develop multiple dashboards I know sexy so we have a multiple dashboard that we've developed and it's available in the graph uh Lab website that user can download uh the the dashboard give you a good Baseline into your API level performance and how uh the API like is behaving so from here you can see the error rate latency the request person something getting uh and it's basically which apis are currently being accessed by uh different applications uh you also here you notice that the red line uh that's a beauty that having the work with the grafana that you can integrate multiple application in One dashboard to see the effect of a change into uh how that change reflects into your performance so here you can see that we created that PLL request just now now to modify the rate limit uh and that got reflected into our setup uh also we have a an API level uh um uh dashboard where you can uh drill down into uh each specific API to see how that API is uh behaving uh and also a a user level uh um dashboard to see how uh What uh each user is is U pushing web type of traffic and we will we'll go through how that each of these users are pushing and and these are these are like just the starter pck uh so you can build on top of it whatever you like uh we don't know your exact use case um maybe you want something more maybe you don't like pie charts whatever so this is just for a start uh you can quickly import it from the graphon cloud uh Marketplace and uh it's free it's there uh even if you want to change something in the Foods it's hosted on GitHub in the traffic uh G organization so you can make changes to it and uh and yeah uh and and these uh uh the data it's coming from Prometheus I believe right it's coming from promethus but the data actually uh shipped uh with open Telemetry uh to the promethus instance uh and uh there is uh no um open t collector in involved in this uh right now for the sake of this uh simple demonstration but of course you can put open metric collector which is a uh tool that can filter your metrics annotate those make some computations enrich all these uh things you collect uh so it's another good piece of software that you can leverage and U uh here the uh red lines are coming from the GitHub data source uh because you support a lot of lot of data sources and uh one of them is GitHub so this is how it appears but uh u in another setup uh we usually configure flux uh uh with uh annotations uh pushed through a grafana service account through the grafana API so uh you can even see when and uh even when a Reconciliation event happened through Fox even though there was no change but maybe flux check the state of your mid repository and make sure that uh uh it's the uh required State ins inside your cluster you can have all these events and uh the end is uh the your imagination yeah no definitely uh I really love the use of annotation like that marks like okay there is your GitHub request you you did and uh and you mentioned this this dashboard is like a default Dash P which comes uh which is available for users to download and play it correct yeah so this is kind of like a baseline they give you a a baseline if you're starting to um you know trying to monitor your apis uh it give you a good information but as Emanuel mentioned this is you can customize it and you can do whatever you want with so yeah part part of the so now you you notice that the error rate for all the API is went all into 100 so the we know the employer API was always 100 because we applied very aggressive raum policy but all the other apis are um going into error rates so I clearly see that that we made a change in the environment that had an impact into the performance of these apis so we could easily roll back since everything is declaratively defined and hosted into our G repo you can go into the red line you see that it's a p request 10 it's highlighted there uh and this is the FL request that we've generated we can roll back our changes pretty quickly um which will basically uh go through the same process of analyzing the impact of role and backed changes uh and you will see that the we going to change our uh access policy um sorry rate limit policy from uh 20 back into 2,000 so now that's basically what it's doing so once we're happy with it we're going to the change and flux will do its magic and apply uh these changes will be reflected eventually into this and we expect the behavior the environment to go back so while we wait for yeah sorry yeah sorry sorry uh so this even correlation is really cre in the incident mitigation uh process because now you did not resolve the issue you you just mitigated it uh you you returned back to a last working state but you still did not solve it um but now because everything is versioned in git you can uh deploy the previous configuration to a separate cluster or have some uh investigation uh run it send it to your developers open a Gyra tiet or or whatever uh your process is and now you can check uh What uh actually caused this problem because here it was clear it was an easy uh demo use case but but maybe it caused something inside your application maybe it's something deep down in your application code now you have time to investigate but you can ensure that uh uh production is not disrupted or just disrupted for the least amount of time possible uh because you can easily roll back yeah uh definitely and one one thing which can be added further or can be extended further is uh for troubleshooting uh uh is to check the logs and uh there is also low key by graffan Labs which you can use to check the logs and see okay exactly uh what errors are coming and you can actually pretty much visualize it uh instead of uh like the traditional ways to go on Terminal and check it out but uh with Loki you can also put this that also in this Hub dashboard like as a part and use it as well yeah yes and I mean other things too tempo as well for tracing oh yes yes and uh uh as in the background uh we are also working on publishing some guides uh and this is a use case we want to include uh uh to make it available to everybody who wants to play with it uh we explain how to install this and that uh component and uh uh something uh also planned we will use uh Loi uh to display logs from the agent so yeah uh oh nice you you already thought what we are planning yeah see I can read read your mind we'll have to we'll have to have you back for for that yes and I can also tell that our infrastructure team with uh our uh uh products are uh inside the company using uh uh Loi as well we are using the graphon cloud uh uh for monitoring and also some Integrations with alerting OP gen and uh yeah this is the how the oncore rotation is built on top of the uh alerts raised from grafana and so on so yeah this is very useful piece of software yes I mean just just a small info on the graan cloud side definitely it makes more sense if especially when you are deep diving the world of kubernetes because Gana Cloud gives you more uh more options uh for for the kubernetes deployment and management part uh like you can uh actually Mar work more automated way than rather than doing a lot of manual tasks so yeah so I see while we've been talking the that commit we can now see that annotated in the error rate and as expected um it looks like those those two apis at least have recovered yep so that that's that's the beauty of having this annotation so you know exactly how your environment is is behaving yeah and you mentioned that you were also using flux I think flux has uh Flagger as well right so if you were a little bit I mean this is a demo but if you were a little more conservative you could you know have Canary deployment and also track the progress of of that one so that you wouldn't see like a 100% error rate yes and you can even do an yeah sorry and you can even do an automated rollback um on the flagger documentation uh you have a guide explained how you can do it uh with traffic and uh this does not mean that uh we only support Flagger or uh you can do it with Flagger if you have Argo CD Argo rollouts also has a guide with traffic so um everything uh uh anything you use uh basically uh can be applied because it's not configuration The Tool uh is just uh executing uh all these and yeah one more thing that that I want to add is the all that this the traffic generated by the two users is we using the k6 um so by gra which yeah which is it's surprisingly a super easy tool to to actually so you don't need to be a like a very like a expert um but yeah if you are if you kind of know JavaScript JavaScript you can write your own and the documentation on the website was great so basically this is the the it's a basic script that I'm Dev like we have I love to hear that yeah and you can just use to test it and you will end up with a graph like this which is great great P demos interesting yeah so I think k6 is often talked about only the context of load testing but you know it doesn't have to you don't have to have thousands and thousands of users for it to be useful I feel like it's also just a kind of a good allaround tool for sres or anyone that just wants to to to figure out how the system is responding 100% 100% so yeah we we love the graphon and L tools and we use them every day in our like for me I use them every day with know my demo when I talk with customers and and explore different aspects in in term of the performance and the how the applications is behaving when we do a PC so it's great yes and uh even I can tell that in my home lab I'm home lab Enthusiast and also part-time devops engineer in my own over engineered home infrastructure which is totally unneeded unnecessary but it's a good way of learning and keeping up to dat with the technology so I have at least two graphon instances running one for my uh hypervisor and uh uh monitoring procm through influx D and what is going on I even brought some custom best scripts sending in data my UPS I even checked the local Ikea stores because you know Ikea yeah Ikea has an API where you can get at least in in Hungary you can get the the amount of people uh how many people are in the different stores so I the rate so I know when to go when there is not people oh I have to use this like on the Saturday Saturday's shopping malls oh yes yes yes and it was very very useful because after covid people started to rush into ik now I could know when when should I go and also monitoring my email infrastructure which i s host uh um other things my internet connection I run speed Tes in every 10 minutes so I know if my service is all right uh but I also run my own kubernetes cluster and using the promit use operator and the mixing that comes with it which uh prepopulates grafana with lots of dashboards related to kubernetes and for example this is how I learned that I need better drive for my kubernetes cluster because the at CD uh the database uh powering kubernetes uh there is a dashboard in grafana that that you can see and the synchronization the io synchronization was high too high and uh this is where I learned that okay I need to put it on an nvme drive and since then it's rock solid so it actually have solving uh even use cases for my homeland yeah no and definitely I I just want to add one thing like we speak a little bit in the beginning about like traffic and kubernetes and uh I I'm so happy so I also use kubernetes but now I have totally switched to k3s which comes with integration of uh traffic Ingress and I love it because it makes the job so easy uh because the past what I don't want to the names but uh it was pretty much hectic most of the time it does not work so yeah yeah and uh and on the special use cases you I remember uh when printing these 3D objects you were monitoring the 3D Prin printer uh the temperature of the printer head and so on so it was fun yeah yeah so what Emmanuel is talking about is in the in a lot of conferences actually we partner with prusa who make these um these really awesome 3D printers I'm actually looking at at maybe buying one I'm trying to resist but they're super cool they normally like those 3D printers have nothing to do with observability except that the prusa people are using grafana to monitor everything like monitor the the temperature of um of the machine and then how many you know the battery the the energy consumption the you know how many files they've gone through how much longer it'll take before something's printed and it's just a really cool thing because it's like visual but then also tactile because you see the final result which isn't what we normally do for we we don't normally have that when we're just measuring you know these virtual systems so it's kind of a cool way to see it in physical form and Emanuel has it two of them aome nice but I I also wanted to ask about um zero trust and and there's been a lot of interest in zero trust now and the ability like people are getting more concerned about security and having verification that um that doesn't require any trust maybe matam me could talk a little bit about that and then also how traffic fits into that picture so w with the traffic we centralize the access policies and we can lock it down into a specific method so you know that um the only authorized user can actually access this specific Service uh and use this specific method uh and and by having a centralized environment can upload all these security aspects from your back and services and have it all in one place where you can view and audit and and verify uh and and monitor as well to ensure that only authorized users can access uh their service yes and uh in proxy V3 we even have tail scale integration uh you can find more details about it on our blog and uh in know the proxy documentation and uh if you're not familiar with t scale it's a VPN uh like mesh network over wire guard and uh Now traffic has native support for it and a um and I have one question so uh definitely both like like graan Labs is also love the the community a lot of uh features in grafana comes from the community and we also learn a lot from the community as well uh maybe Emanuel or them both of you can explain and guide the audience like uh if someone is new to traffic Labs uh where they can learn it and uh maybe how to join uh the the community site as well yeah so if you are new to traffic or even if you want to learn some uh Advan load balancing uh uh terms and how it works we have uh Traffic Academy completely free video courses uh you can find it uh in the learn section of our website uh you can sign up and get access to udem like experience some courses some lessons some uh uh checking questions and uh it's interactive uh tutorial which you can follow and learn about these Concepts uh also we have a community Forum where you can ask questions of course there is our GitHub uh where uh you can raise issues bug reports uh send feature requests or even send PRS uh that are very very welcome and uh we always highlight uh who contributed uh this and that feature so is these are always welcome and uh yeah you can sign up to some mailing list and so on and uh there is uh uh I think even a Discord uh somewhere uh I'm not uh uh inside that server but uh I think you can even join that with uh the traffic ambassadors uh who are the most Enthusiast traffic users yeah and uh also uh on our grafana website grafana dashboards we have some dashboards available for uh which can be used for tra like the Hub one which is the primary one but there are some uh Community Based dashboard as well which users can also use to uh try it out and see which works best in their ecosystem so yeah that's also very use info for for audience yes and always there is the documentation well thank you so much for for coming back a second time yes and if you want to meet us in person uh we will be there yeah we will be at API days London and uh then uh cucon North America Salt Lake City in November uh and then API days Paris in December so come to our boost and and find us and we will go to yours and get some more swag yes absolutely and if I'm there you can find me and maybe I'll give you secret swag again like like a little 3D print you know that's only normally for internal graphist as you know oh nice nice all right well thank you so much I think the next in the next group on office hours we're going to be talking about lowkey deployments we're going to going to be doing it with our other co-worker Jay Clifford and we are having Ed welshon who's one of the OG developers of on Loki he's going to be talking about how to deploy Loki and just some best practices for the years that he spent looking at other people's Loki deployments in production uh thank you all for watching we will see you next time thank you everybody for joining us thanks for inviting us thank you all right bye everyone Bye Bye Bye by

