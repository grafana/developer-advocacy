# Grafana Beyla May 2025 community call

Grafana Beyla May 2025 community call.

Published on 2025-05-15T08:36:02Z

URL: https://www.youtube.com/watch?v=vjP2ByF6Ok8

Transcript: Nice. Uh I can share the screen just to just to show the agenda of today. Welcome to the May 2025 uh Grafana Baylor community call. Hello. Oh, okay. Those are the notes from another meeting we had just right be before. This is a good one. Okay. Uh so I think Martin you you added this this bullet. Yeah, I did. I um I was checking these two issues and um like some ideas came up in my mind on how this could be used. So, um I'm not aware of an possibility currently that allows you to have like an overview with one or more metrics that shows you well maybe allow would allow you to calculate a percentage of instrumentable targets that are actually instrumented or not. Right? So you could either say like if I have any targets where the instrumentation failed um then I would like to be alerted about it or even say like I accept a certain error margin of five or 10% of services not instrumented but if I have more than that then I want to know about it. So I was wondering if uh and and if that could maybe even be combined with this one where you might even have one metric with with a label where the label value could either be something like yeah the label would be called uh instrumentation or instrumentation status and it could be success fail or avoid or something like that and then you could do all of all three maybe in one. I'm not sure what you think of that idea. Yeah, I think so. Uh I I yeah all those sounds like a good idea. So we can have just one uh metric which exposes the information about what what succeeded, what didn't uh what we have enabled as features for a given service. Yeah. Yeah, that sounds good. I split them as separate issues because I was just I wanted to give an opportunity for people to take a smaller item. But yeah, are we at risk of um if if we I'm not sure because I think there's a current uh internal metric already that says something like this. Um are we at risk of having too high cardality? I'm not sure exactly what labels that metric has currently, but But if it goes down to the process ID, then we might have a pretty high cardality. Yeah. Yeah. Yeah. Which means we just clean, right? Yeah. I don't know. Do we clean those up when process dies? That's a good question. That's something we need to look into because I mean, even if we have a lot of process IDs, as long as it says process ID and then this particular I mean it will be thousands still fine uh because it's going to be a definite it's going to be one line per process right for metrics yes yeah so it'll be like even if you have thousands still not too bad I think uh because there will not be um yeah I think so I think it'll be still fine cardality wise I don't think it will be too much, but at least it doesn't go into the millions then it's probably and it will be a definite status and we could probably just uh just say this process we instrumented it or we avoided um avoided trace instrumentation because it's already doing its own traces. Um, yeah, because right now it's really difficult to tell when uh people kind of instrument with different technologies and all of a sudden they're like, I'm not getting my bailout traces on this service and we have we don't know what to tell them and we usually takes it takes a long time to investigate. It's a question that came up here as well where we had I think one system where all of a sudden half of the replicas of a certain services were no longer being instrumented and it had to do with some network issue in the cluster but we didn't really have an automated way of being notified of that. Um, and if we kind of attach the right things to it as well, maybe the service name as well, then we could even have like rules that are different based on which service it is. Whether you have certain critical services where you say, I I want everything to be instrumented here. And if there's anything that's not instrumented, I need to know, but there might be other less critical ones where a couple of uninstrumented services might be acceptable. Yeah. Yeah. Cool. Yeah, maybe we can start fleshing out some sort of design and proposal in here about what this metric will look like and then get some comments and I think we're good to go. Yeah, because we have all this stuff in the debug logs, right? You probably can tell, but nobody enables the debug logs. They're way too verbose and um you know, running in production and debugging with them is kind of hard. This would be nice to just kind of be able to surface that information and and maybe like you say show it in a dashboard or something. It can also be the trigger like the operational trigger to enable the debug logs. If you see there is something going wrong um then you might subsequently enable the debug logs to get more info but the debug logs are probably not the best way to get notified of something going wrong. Yeah. Mhm. Yeah. All right. Cool. So, yeah. Any other topic to talk about? Yeah, just going to mention that we do have this known issue seems like affecting a couple customers running with SSL. Um, yeah, there's some high cardality exposing. I think we get the wrong port. It might be related to a recent change we did for better correlating SSL requests. Um, and it seems like we get the port wrong. I got logs from one uh user and getting I'm trying to figure out what's going on. There's lot lot of discussions on the on the public Slack about this. Um yeah, is there an issue in the in the GitHub for that? No, it hasn't been open as an issue yet because we actually don't know what the issue is. Um it's just a report that it's a high cardality um problem uh with uh it's certain services we can't quite tell where because none of our tests caught any like this um so it's something unusual some sort of an edge case I do have finally debug like EDPF logs from this one client so I started looking at this morning I think I found the place I just not understand how this happen. Um, so hopefully we'll get a fix for that and that removes the last of the issues. Um, yeah, probably a new release coming 223 once we actually resolve this. And if that proves well in testing, then we'll update the health chart to point to this newer version. Okay. I was wondering is it possible to look over your shoulder while you do some debugging or look over anyone's shoulder or is there any like concerns with specific folks who might not want their things being looked at by someone who's just kind of interested in and in joining the project. Oh, no problem at all. Like we can we can schedule that. I we do that internally a lot uh when we book over sessions. So yeah, I can I can put a meeting link later when I'm looking at this. So it's about lunchtime here, so I'm just going to take a walk and maybe be back in about an hour or so and uh after that maybe I can I can ping you on Slack and we can get together and kind of look over this particular issue. Yeah, happy to do that. Cool. Thanks. Are you are you in the public Slack, Jana? Uh yeah, I was also going to ask which Slack uh is the public one that you guys are talking about. Uh yeah, let me let me join join here the or put here the should be the invite link for the uh graphana. Ah nice, nice. Thank you. Nice. Yeah, there's a graphana public slack that is like it's a free instance. So nothing lasts forever in there, but messages do disappear after 30 days. But we do use it for like and kind of like uh communication with people trying stuff out that didn't work or they ask questions that are sort of more less of about issues but more like I have this problem. I didn't know how to do this. Do I do this? And um Cool. Thanks. Pretty active. Yeah. Yeah. Um but then if something is actually a real issue that we need to kind of consider, we always say just go on GitHub because that never disappears, right? So this conversation here goes away eventually. Um, I did have one more question which um I guess is for Mario. It's around this pull request. Um I I assume this has something to do with somebody that reported that they were having huge memory explosion on the on the cache. Yeah. in in in some big clusters uh uh I I realized that the the the client of the Kubernetes cache is spending like maybe 80% of the memory and 90% of the CPU just because a huge generation of garbage uh so it puts a a pressure under the garbage collector too high. So, uh this is something this is an optimization I planned the day we we built this this catch but we left this as a to-do but basically what happens now is that when a connection is broken da just reconnects to the first available cache instance. Uh so it on each reconnection it gets the whole snapshot again of all the ports nodes uh nodes and services regardless of the information that it already knows. Yes, exactly. So what what we are doing here in this pull request is just to keep track of the latest or of of the newest event uh the newest revent event received. So in the every time it reconnects in the subscript in the subscription message it it sends a time stamp. So the service will only submit the data newer than this time stamp. So and and this is unfortunately this high memory and high pressure causes that sometime the cash breaks. So the cash instance breaks so bail needs to reconnect then puts more pressure then it creates more so it's it's like a like a ball rolling over the edge of the cliff so to say. Yeah. Yeah. I understand. Yeah. So if I understand it correctly, what you added is uh the in the subscription of the bail instance towards the cache, the bail instance sends a time stamp to inform the cache of I need everything after this and then the cash delivers everything after that. Okay. Yeah. So that's I was wondering if this would account also for the case if the cache is down the bail instance restarts um if that would still if that would not cause gaps. But then of course in this case we are back to zero so to say and the bill instance would request everything. Okay. Yes. Yes. Exactly. Exactly. If we looked I'm sorry I don't have here any profile any visible profile but if you look in in the profiles most of the memory generation is at the at the encoding and decoding of the of the protoraph messages. Yeah it's a lot of data. It's a lot of data. Yeah. So it's interesting you know like I it was last week at Graphfonicon and uh a lot of community members there doing experimentation with random stuff and this service is something that came as a topic somebody was talking about uh in in sort of outside of Kubernetes uh because I was talking how we have the Kubernetes service for this and people asked so what if you made this cache also writable by BA that it uh push information about the services it has locally so you can use it as a generic cache even when you're outside of Kubernetes because right now what we do is like Kubernetes has this nice API which gives us all the information about what are the names of the related services but if you're running outside of Kubernetes we rely on DNS which we don't enable by default because it could potentially overwhelm the DNS um server for uh if there's kind of we we guess information wrong and we start trying to DNS resolve reverse DNS like IPs of clients and and so on. It would be it would be cool if we can actually use an event where we can actually push to this cache and say I have this information about these IPs that are local to my node and and I have I have names for these services so that in in that case I don't know if it if it will be just simpler to provide a ready instance reddus rather than Yeah. Because this this service is not really uh is is distributed but it it's a stateless. Yeah. Yeah. And that's that's why it's easily distributed. If we need to start to manage share state and things like that maybe simpler just provide this functionality using using radius. Yeah. Anyway, so just a thought I had not no immediate action. I was just No, but it's it's an interesting it's an interesting topic. Yeah. If if we maybe there are enough use cases to provide some share status uh for BA some share status mechanism. Yeah. Because people don't like to see IP addresses in their traces and metrics. Yeah. And particularly in a Kubernetes environment when they're where they're really not that static. So, yeah. Yeah. They move around. Yeah. Mhm. Are there really so many people and organizations using BA outside of Kubernetes? No, not that many. Most not that many. Yeah. Mhm. See few of them but no I think most our biggest use case is coet. Yeah. It's kind of difficult to to do modern sort of deployments without Kubernetes these days. Uh unless you're doing any of the managed solutions at the cloud vendors and those managed solutions usually do not allow EPF. So it's sort of like it doesn't exist therefore no bailout and now I have not tried it on like more like container as a service kind of platforms. I think with AKS and EKS there is no real issue. I think the only limitation that we found, I don't remember exactly what the limitation was, but I think it has something to do with the like this kernel profiling kind of setting. I think uh Raphael, we had a call about that if you still remember. Um kind of remind Yeah, it's it's already kind of like a little far away, but yeah. Yeah, there's there's some I think I forget one of those that automatically manages. I know that I forget the names of products. Unfortunately, there is um there's an Amazon Kubernetes something where it's like fully managed for you, but you can choose to run VMs or Fargate and then Fargate does not work because there's no EVPF. But if you run the EK the the side of the manage Kubernetes with VMs then you can load data as a sidecar. I think that that works but it takes a little bit of convincing. There's some special settings and whatnot. Um and there's another one that somebody opened. I didn't know about this. There's a Google something autopilot or something. Mhm. I think it's uh it's like managed managed Kubernetes or something like that. It's a special mode of the of the managed cluster. Yeah, it's called autopilot or something. If you search here, you may go search for autopilot, you may find it. That one seems even harder. Maybe in the search if you search pilot or something. Maybe autopilot. There you go. So, apparently for this one, we need to become we are partners, but we need to we need to make sure our image is part of this program. So, we have to subscribe. But you see a lot of people put a thumbs up here. Um and if we allow BA to be in this list or allow listed for this then we can actually run as sidec cars in a autopilot. There's no dam there's no dam mode because they manage nodes automatically my understanding is but maybe there is an option with that. Um I think it's some kind of application whitelisting. So your application must be whitelisted to be allowed to run as privileged or partly privileged. Mhm. Mhm. Yeah. I found it again also what we were talking about before. This was this uh kernel restriction perf event paranoid. Oh, that one. Yeah. Because what we were checking was uh if there is any way on AKS and EKS to run BA without capsis admin and our conclusion was no not without doing strange things to to change this value. Yeah, that one paranoid is that that's an interesting one. I don't know how to properly um check for that even maybe we can actually poke at the file. Maybe that we can see it and then report as a as a restriction. Um you need some permissions to be able to do that and possibly just checking the value is not that high. So this paranoid thing is like my understanding is that there's Debian only that go above certain value like the rest of them stay but if it's Debbian based host OS they may go to beyond three which is not standard but if you go beyond three then bunch of EVPF features don't work Um I think what we found is that I think on both it was either two or three and this forced the requirement of capsis admin. So wasn't possible to uh to run it without capsis admin. Capsis admin. Yeah, I'm impressed with your memory. [Laughter] Yeah, I I know that I knew that was something with kernel and Perf and then it uh it popped up in Google and I remembered it. Yeah, AWS Far ES. Yeah, that's the Amazon elastic container service. So if you run with EC2 instances, there's a way to get BA but only in sidecar mode. Um I think somebody promised me they will write a guide for this but I don't think they have. So I should follow up. Okay. Um, Jana, I was going to ask you if you had any idea of what you wanted to start with, if you had any issues. I know you were asking about this a while back. Yeah, I'm still trying to figure out where the best places to get started. Um, I feel like there's a lot that I there's there's so much surface area. I've watched an amount of like Liz uh Liz Rice's um videos on getting started with EBPF. So I have some highlevel idea but uh full disclosure is like I come from the world of like psychology and neuroscience so things are still uh new to me. Um not to mention like I don't have hands-on experience with Kubernetes. I've used ECS. Yeah. Um, and uh, I've used it. You know, I think it's might be somewhat similar, but there's like a whole world out there of like containers and container orchestrations and uh, tooling that I would love to know more about. So, I'm kind of like coming from a place of like really excited and blurry eyed and bushy tailed trying to figure out where do I start? Yeah. Okay. I get it. I get it. Um, I don't know. A good way to start is maybe uh looking at if you're if you're new to EVPF maybe the user space side of BA which I don't know how how well versing go and stuff like that if you like go as a language then maybe we can find a small task there maybe like a test or something to start and just see what the development process is like um I don't know if that's better but that sounds good Liz Rice also Liz Rice also have a free book about EVPF uh that they distribute through I surveillance. Um I think you have to give them the email address though worth. Absolutely. Yes. Yeah. There's like if you look it up I I think I I I downloaded it because I gave them my email address. You can find what the book name is. Yeah. I past it on the chat. Thank you. Yeah. learning EBPF is her book and I like that one because it's recent with the recent tooling of of how we actually do EBPF at BA uh and how the other projects that are in open telemetry do EBPF like the this is compatible with the open telemetry eBPF profiler as well and uh some of the older books that are published even with O'Reilly and whatnot they're so have the approach something that was done five, six years ago that doesn't really work well across current laws and so on. Um, yeah, good to know. Thank you. Yeah, I think this is also kind of how I started out with uh with the BA project. I'm still not very familiar with the whole BPF part because it's um pretty complicated, I would say, and I'm also not very familiar with C. But I'm reasonably familiar with Go. Um, so yeah, I I started with only things in the user space as well. And I'm currently like working through like the initial parts of learning how the the BPF part works as well. I have made some very small admittedly extremely small changes there, but uh yeah, the go part is at least for me personally is a lot easier to understand than uh than than the kernel part. That makes sense actually. Um, that's a that's a great um I'm glad you said something because like maybe I find that it's easier to learn when like I partner with someone who's closer to who's also like closer to being at a beginner. Um, and if there's anything that you're working on that I could kind of like look over your shoulder or if there's any um, if we could have like um, a quick session on, you know, how you like model um, like veil in your mind today like maybe that could be really useful for me. Maybe. Yeah, could be like based on uh this metric stuff that uh we discussed earlier depending on the the final design I guess but uh yeah that's definitely something I wanted to mention there's also one interesting thing that recently came up uh and Martin you you've been involved in this in the past uh there is the um the puristic route um matcher then. So there seems to be appetite for this to become a full-blown like a collector uh feature that people will be like want to take this and turn it into a pipeline processor in the open telemetry collector. uh because uh people can easily create manually um [Music] um like roots uh from um their like manual instrumentation and they just get high cardality metrics automatically. So they're looking at just beyond bailout just going outside of uh talking about extracting the code and making it into a standalone project. Maybe that's something of interest. I don't know if um I can we can also walk you through that as well if you'd like. Sort of a separate piece of code. Um yeah. Uh I am more familiar with the collector. I have used that but um I'm not understanding how uh how it's connected. So extracting BA to be like a processor on the for the collector. Yeah, just one piece of BA. Uh there's some interest into making it a more generic tool. Uh so what happens typically is that people run APIs and they part of the APIs with maybe users and then they'll have like a maybe a hash of the user and and what you need to do for telemetry to export this as a metric. you technically want to leave the users but then replace the hash with maybe an asterisk or some other uh character because if you don't when that ends up in metrics creates these really high cardality metrics that cost a lot to host and expensive on querying and so on. Um so BA does this. So when we recognize parts that are not words in the API we replace those with asterisk those components and leave the rest uh remaining. So we have a mode where we kind of glam those down. Yes. When Martine placed it there. Um and and so we always had this from a very long time ago. We wrote this code uh we use an open source project um that that actually had built a database of English words. But actually it's not just English. I found that I tried French and German and It does seem to work. Um, and there are tests I think in three or four languages and they all seem to pass. Yeah. Uh, I think it's you want to find a file called cluster.go or something. Uh, that's the file I believe uh that does this URL clustering. And if you Yeah, if you go at the top Mario, maybe search cluster.go when the search box appears. Go to file. It's at the top right corner. Yeah. So if you go cluster.go. Yeah. Yeah. So this one does this sort of like clustering of URLs and there's a cluster test. Maybe the the test is maybe more easy to more visual. More visual. Yeah. So if you go uh cluster test. Yeah. So you can see there's all these parts that don't look like like users something job and on the other side it should be what that looks like. So we should be stripping everything that is garbage like this FDK LSD or 2399 and job 2. those are disappear. Okay, it does like two things. One is the this strange gibberish so to say and the other thing is purely numeric values and both of them are replaced by the uh by a wildcard character. Um and the character is also it's by default it's a it's an asterisk but it can also be configured to be something else and it prevents um high cardality explosions because you can imagine that if you have like ids randomized ids in your API path then uh this will generate huge amounts of label values and this kind of prevents that. Cool. Yeah. Yeah. I I mean I I do personally like high cardality in some places but maybe not when it's not particularly meaningful to us or someone. Yeah. So this makes sense. Okay. So people have found that uh we had a couple of instances this graphana internally where people use the open telemetry SDK and they just manually create a span and they'll just put the root in there and not thinking about it you know and what like what that does to metrics. So now there's some interest into like extracting this code and making it into uh like a project that can be used in the open telemetry collector as a pipeline that you can process your URLs through this. So of a paths. So if a span is named certain way and says with the full URL you go in and you uh perform the action on this. Um, yeah, this would be this would be great. I would love to use this myself. Yeah. Or extending this to do better. I don't know. Like, right. Right. Yeah, it could be something. I just thought that's that's a great idea. Uh, that guess brings us also a little bit to like uh the process of BA being donated to CNCF. Mhm. Um I guess I'm kind of curious what that's how that's going so far, what that process is like. Mario, do you want to talk about because Mario's leading that effort? Yeah. Yeah. The the we are currently working on we we move the bail code to to a new repository. Uh let me just telemetry this open telemetry evpf instrumentation. uh this the we clone the the veil uh code here and now we are doing some changes to comply with some requirements like small like removing some some functionalities that were very specific to Graphana cloud and also change a bit the configuration format. But uh now we are starting to refactor this to uh to be able to vendor it inside BA. So most of the code is here like this for example this cluster uh this will be removed from here in from BAS and will be will be vendored as a library from from this repository. This is not going to happen tomorrow nor the next week. It still needs needs some some work. We are currently working in parallel. So I'm working on on on porting everything from graphana but still there are some issues some bug fixes. So people is working in in the BA repo still providing new features or or bug fixes. Uh we we we are marking everything in baila all the all the merge or requests some of them are market with this label port to hotel evpfins. So before moving before using BA or or or using the OT instrumentation as a library inside BA we need to port all those uh all these patches to the new repository. Yeah. So if you do some contribution to BA to the BA repo it will be tagged from here and we will move it there. So at some point you can also contribute here directly. So now yeah now there are many people contributing upstream is is the same code as as BA we are renaming many things uh or doing some refactors but essentially is the same very similar architecture with fewless components. Yeah, the bail name is was not accepted in the donation because everything in open telemetry is named certain way like open telemetry dash something- something for example open telemetry java instrumentation or open telemetry eBPF profiler. So we picked a name like that. I know people are not happy with the name. So I heard rumblings that maybe they want to change the name of this project to something that's easier to pronounce because it's a mouthful open telemetry epf instrumentation. Um but uh yeah so our plan is to uh because with bailout we still have customers users that depend on this uh we can't just drop it and start working on that. Uh like obviously there's fixes people find issues that we need to fix. But the idea is that once we perform everything that we need to meet the due diligence on this project, we'll start to move all the fixes or improvements we've done in the in the past little while upstream to this repo and then uh essentially start where we can remove functionality from VA and import the code from the upstream project. Um and will you continue uh will we continue to maintain BA or you guys continue to maintain that? Well remains to be seen but for now we'll have BA for sure. Uh just if anything else as a build of the upstream project maybe in the future that is very thin wrapper on top that has some graphana cloud specific stuff. Um but the idea is that most of the things will happen upstream. Yeah. Um, and like Mario said, we this may not happen in in the next couple of months or whatever. It's a long process when you donate something and uh yeah, but we will definitely be working and committed to to make this happen. Um, cool. And then do they get like do once once it is do they is there another set of like maintainers? Yeah. Yeah. And we're looking for new maintainers here on this project for people to get involved. Uh it's supposed to be um maintained by multiple parties, not just graphana and um and it's managed by CNCF and open telemetry. So we're always looking for people to kind of join in and become maintainers eventually through uh contributing to the project. We currently have uh two maintainers from Graphana on this, Mario and myself. And there's uh Tyler uh Yan from Splunk and uh Mike Dane from Odivos are the other two maintainers of this project. And uh but hopefully we want to get to maybe 10 maintainers in the future um that will be u be able to contribute and yeah that's awesome. Thanks. Cool. So any other topic? Um yeah. Uh oh yeah, you were you you added another entry. Yeah. Um yeah, I'm going to go quickly over this. Uh so I think we're looking for better ways to correlate uh requests in uh Node.js. Uh I mean Nicola has been the one who's been actually mostly involved on this. I just uh pigged on on what's his research so far and and and just take a step took a stab at it. Um so Nicola correct correct me if I'm wrong but uh the problem is so with correlating requests so for those in the call uh just to give them some context you have a service written in in node or using NodeJS um that's receiving incoming requests from from let's say uh client A and then this triggers an outgoing request from the service to uh another service C. So the service B you have A, B and C. B is the node one. Uh but you can have multiple requests coming multiple requests outgoing requests uh and they can all happen in in in parallel. So and node is this black box where you know from eBPF from eBPF level uh at the kernel level at least all we we see is our incoming uh requests and outgoing requests but we don't know more or less how to tie them together which one belongs to which one so we can establish a chain and then Nicola uh discovered that uh for inside the nojs engine each uh a synchronous operation has a unique ID and everything actually that's a synchronous uh in the NodeJS runtime has a unique ID so not only a synchronous requests but timers uh any kind of a synchronous object promises and everything like that so um we thought maybe there is a way of correlate those using this synchronous ID to correlate these requests And um Nicola also discovered that an a synchronous object or a synchronous operation which is triggered by another asynchronous operation uh receives the ID of the parent oper the parent operation. Uh so we thought okay maybe we could use this ID to establish some some sort of uh yeah chain. Okay this operation trigger this operation trigger this operation. But when you when you're thinking about requests like uh you you get an incoming request that's uh inside the node node runtime from the incoming request being handled in the socket to the outgoing request going out there is a lot of synchronous operations that are not necessarily requests like timers objects being created. So u the trouble was how how do we put this together? So I I you know I took a stab at it. I don't know if this is sufficient. I'm going to share my screen real quickly. Uh Mhm. Um okay, this is something else. Uh where was I? Uh yeah, so um let me increase this. So I got an EVPF program here that's uh basically prints uh the trigger is the parent ID and the ID is the the these objects a synchronous ID. So they're both a synchronous ID. So you have one three one four five seven. Yeah. And then you got like this nine and 10. You can see 10 spawns 13 14 13. So every ID on the uh left hand uh on the right hand side here is unique and the other one is the parent. Yeah. So I mean is this N is this enough? Do you do you do you reckon or I mean yeah it depends like if you see there's gaps and the gaps are the ones that have been kind of the main challenge we're getting. Um and but if for the cases we care about the gaps are not important then I think that would be good. Uh right. Yeah. I mean essentially the test you wrote if you can pass it and you can correlate them by chaining then I think that works. Okay. So yeah for like 34 is 22 and then if you look up 22 is 20 is 22 here is 10 and then 10 here is nine 29. Yeah n 9 is four and then four is one four seems to be what you want to do in the end is like create finally a map that has like a an initial ID plus the last one so to say. Yeah. Yeah. Yeah. Cool. If you can do this, then it's perfect. Yeah. Yeah. So, I basically did what I mean I tried different approaches uh not going to go over them. Um but I I went for a probe ultimately uh like you had done and I the probe that I used is probably I don't I'm not sure if that's the one you're using as well. Uh it is called async reset. Async reset. Yes. Yeah. That is when the async request is a new one created. Usually they call reset to say my current new async request is this. Yeah. Yeah. But the problem the problem uh the problem is that the async ID is only set uh like not not here at the beginning of the function. Yeah. Right. it has this uh sync ID and trigger a sync ID set here. So what I did is basically I attach a probe here like and an address where after these variables have been set and then because these these are and then I can just access them from the uh under this pointer. Yeah, but you can put it on a one way to work around that if you don't want to inject a probe in the middle there is to put uh a probe on start remember the this pointer and then on exit uh you read those two values they're not changing this motion. Yeah. Yeah. Okay. Yeah, that that might be even better. Um but that's what we currently do. Uh okay. But it doesn't work any like concern or limitation if uh if there are too many of them too many steps in between. Yeah. True. True. So if you have more than I think we loop about eight times looking for parents. So if you have more than eight I mean EBPF has no loops. So you have to go limited amount of looping. I think we go up to eight. So I uh what I what I was thinking of doing and I I that's the part I haven't really thought through is on on the up probe on the part that gets the uh um this uh the socket um uh I guess it's called on on headers created or something in in node. Yeah. Uh I will there I have the trigger async ID as well and and then it it starts creating more async. So I I was thinking of using that one as the root and then for every async ID that gets created after that I can see if I can uh instead of storing as a tree I just store okay do I have a root for that like storing in a map and then if no I use that as the root or something like that I have to to kind of finish working that out. Uh okay. Okay. I don't know. I don't know if that work. And what version of node you have here? What are you testing with? This is uh hold on node 23. Okay. Good. Good. Okay. Yeah. Yeah. If you So the challenge that I have like we this currently does work but this example that you I'm see if I can paste it here. uh this example that you created which is something like this I'm going to paste it in the chat um this call on slash r for me when I run it with node 22 gets a trigger zero I don't understand why the trigger is empty so the the async ID is something but the trigger is empty and we can't find the change. I don't know like I with all the probes I put in that never actually worked for me but maybe some I have a bug in whatever I did. So Q and R Q&R like the first one the C whatever service C request that call slashp that one. Okay. Uh but slash r/q um no. All right. Yeah, there's a there's a gap and there must be somewhere to correlate them, but I don't know. Okay. Okay. Yeah. I mean that makes thinking I'm just thinking out loud. Uh yeah in in what I had in mind this won't work because I was putting I was putting a problem on on headers but will will the uh the radius request no that's also no that's a JSON one will that work with is it also HTTP request I guess that's what I'm wondering if it's trigger it's going to a different code path need a different probe yeah yeah need a different probe for that okay all right Yeah. Anyhow, just wanted to make sure that cool. All right. Thanks everyone. Any other business? Well, it was really nice meeting everyone. Thank you. All right. Nice meeting. Thank you all. Until next time. Have a good See you. Bye. Bye. Bye.

