# Deploying the Loki Helm on AWS | Grafana

One of our most requested Loki tutorials is here! Deploying the Loki Helm on AWS . In this video, we'll walk you through the ...

Published on 2024-11-07T08:30:02Z

URL: https://www.youtube.com/watch?v=5lXmWmofqwM

Transcript: welcome to another episode of Zero to Hero a beginner's guide to Loki buckle up and strap in today we're going to deploy the Loki Helm on AWS Yes you heard me correctly from start to finish we'll set up a kubernetes cluster on AWS we'll then go through and configure the minimum set of AWS resources you need before hitting that deploy button on the Loki Helm then for good measure we'll ingest some logs and monitor our new Loki cluster but before we begin I do have some homework for you check out Min Nicole's new architecture video if you've not already done so it's not a requirement but it will save you googling all of that Loki component jargon as we go through this tutorial and finally let's read through some small print number one the recording date is the 31st of October 2024 hopefully if you're watching this 6 months from now most of this tutorial is still relevant as we know though the software world moves fast so be careful your AWS environment hasn't changed number two I am giving you a very opinionated way of deploying Loki to ensure that you get up and running the Loki Helm though is actually pretty flexible but if you're a firsttime OSS user my advice is to start with this as bedrock and incrementally update your deployment as your needs change and lastly I have assumed that you have God level permissions within your AWS Cloud environment more on permissions in a bit but make sure you have the ability to create eks clusters s3e buckets and add custom I amm roles and POC IES or have a cool devops friend that can that will keep my lawyer happy let's get on with a tutorial like any good recipe we need some ingredients otherwise known as prequisites make sure you have the following installed locally on your PC Cube CTL a CIF for running commands against your kubernetes cluster Helm a software package manager for kubernetes that simplifies the process of deploying applications and services the AWS CLI a CLI for running commands against your AWS infrastructure make sure that you have already authenticated the CLI against your AWS instance as I will not take you through this and then lastly eksctl a CLI tool which reduces the friction of creating eks clusters this is a personal preference but I will be using it to deploy a fully feature complete eks cluster okay okay with that out of the way let's talk a little bit about what eks is how it relates to kubernetes and our recommendations on configuration and sizing for Loki elastic kuber service or eks for short allows you to deploy a K8 cluster on AWS while managing most of the complexity for you such as security networking and scaling one of the key features it provides us is the ability to authenticate directly with other services provided by AWS such as S free which happens to be our chosen object storage for Loki in this tutorial one area we still need to manage ourselves are worker nodes which can either be ec2 instances or fargate if you're looking for a more serverless experience we will be using ec2s with that in mind let's talk a little bit about sizing of our worker noes I'm going to deploy fre m7i 2x large nodes this will create fre ec2 VMS each with eight cores of CPU 32 gigs of RAM and up to 10 gbits per second Network bandwidth this is a great middleof the road starting point for Loki it gives you room to grow but does not oversize you from the starting gate now I would be wrong not to tell you that spinning up nodes of this size will cost you money Loki can run on smaller instances even those within the free tier however the config will need some tweaking and you have to be mindful of workload sizes a top tip in most cases you will see resource consumption coming from querying loky rather than ingesting bubbling back up there is an extra plugin we're going to need to install within our eks cluster to get Loki up and running Amazon EBS CSI driver enables kubernetes to dynamically provision and manage EBS volumes as persistent storage for applications we use this to provision the node volumes for Loki the next two should already be included as a standard but just in case we have core DNS provides internal DNS services for kubernetes clusters ensuring that services and pods can communicate with one another using DNS and then we also have Cube proxy this maintains Network rules on nodes enabling communication between pods and services within the cluster I would keep these on the most upto-date version AWS has talking of versions We recommend deploying Loki on kubernetes cluster version 1.30 or higher let's spin one up together to spin up my cluster I will be using eksctl and a cluster config in this config file you can see we're deploying a cluster called Loki K version 1.31 we're enabling oidc more on this in a moment adding the plugin which is not installed by default and we're provisioning our work and nodes now we can simply run the command to spin up our cluster and wait while that's installing we still have a little bit of time to talk about oidc open ID connect is an identity layer built on top of aarf 2.0 we don't need to dive into the mechanics here but we will use oidc to allow Loki pods within our cluster to authenticate and operate against AWS Services primarily s3e if you're using eksctl and the config I provided it should install oidc automatically to make sure you can always run the following command to install one before deploying Loki we need to create two s3e buckets one for storing chunks and the other for storing rules if you're an Enterprise user you will be creating three buckets one for administration but I will save that for another video I'm going to create both buckets using the AWS CLI now important s3e buckets need to have globally unique names which means unique for all Amazon customers so don't copy me be creative make your own bucket names once we have our buckets it's time to make some IM am policies let's start with the s3e access policy number one make a file and call it Loki SRE policy. Json number two copy this template into the file number three update the resource section with the two buckets you just created number four save the file number five use the awscli to create the policy that's one out of the way onto the trust policy and role creation number one make a file and call it trust policy. Json number two copy this template into the file like before now this is where it can get a little bit more complex free fill out the placeholders for account ID and region for where you installed your eks cluster next we'll need to Source our oidc server ID the easiest place to find this is via the eks cluster page copy this and fill out the rest of the gaps save the file and then use the AWS CLI to create the role next we'll attach our S3 policy to the role simply run this command making sure to replace your account ID with authentication out of the way it's on to the fun stuff deploying the Loki [Music] Helm one more thing to cover before we get to the helm Loki out of the box does not apply any authentication fine when you're running locally but we are deploying on AWS and exposing ourselves to millions of Internet users so huge disclaimer this tutorial will expose your Loki gateway to the Internet so check with your network in security team before continuing to safeguard against unwanted access in this tutorial we'll provide Loki with a username and password we will do this using a cube secret and a username and password generated using HT password to do this let's start by creating a namespace called Loki using the following command then we will generate our username and password file using the following HT password command before find finally loading this file as a secret Loki can now use this secret to create its authentication layer we will also create another Cube secret with our username and password for Loki Canary this will allow Canary to validate against the Loki Gateway while it conducts its test Cycles you will also be happy to hear that you can unexpo your lowkey gateway by removing the load balancer in our configuration I I will leave you to decide how you want to root your logs to Loki in that [Music] case the first thing we're going to do is add our grafana repo this contains all of the Helms for each of our storage engines and grafana now to be clear there are a lot of Loki Helms out there some are deprecated and some are Community Run the official Helm worked on by the in-house Loki Engineers is called Loki key and that is the helm we strongly recommend that you use so Helm we doing most of the heavy lifting here but there are some parts of Loki we must configure ourselves we will do this via a values file this allows us to control certain parameters of the Loki deployment we could spend a whole video going through every option and it wouldn't be very fun so I'm going to take you through the Baseline template for Loki microservice and tell which bits you need to configure a huge top tip here is that you need to imagine the Valu file having two roles the first being configuring how Loki deploys such as the number of replicas which type of object storage which deployment mode and the second role is creating the Loki config to tell Loki how to act if you have run single node Loki you have already generated one of these files before the water's murky here a bit so if you feel like you're repeating yourselves just remember these two rules starting off we have schema config this sets up how Loki will generate an index and the format the chunks will take I would leave this unmodified unless you are migrating an older Loki schema to a new one next up we have storage config in this section we are telling Loki that the object storage is AWS otherwise known as s3e notice we need to supply a region and bucket name we do not need to supply any end points or authentication as this is being handled by the role that we created earlier in this section make sure you fill in the region of where your S3 buckets are located and the bucket name for your chunks bucket next we have a new one which is pattern ingestor we're enabling this for explore logs in grafana it runs your logs ingest through a set of algorithms to extract patterns we have limits config think of these as your Global limits for all tenants you can provision on a per tenant basis but for the purpose of Simplicity we're going to go Global we have enabled some of the usual here so structured metadata for otel volume is another feature for explore logs that enables a metric endpoint and then retention which we've set to 28 days talking of retention we have compactor this fur configures our retention retention is optional so feel free to remove these options if you wish to keep your logs indefinitely next we have ruler this sets up the ruler components for alerting and recording rules if you're new to Loki this is quite an advanced function but it is worth setting up right we will keep our rules in files stored within s3e so we Define our storage type and make sure you fill out the bucket names with your ruler bucket lastly want an endpoint for your alert rules to go to usually this is Prometheus or mimir which can either be deployed within the same cluster or a remote alert manager moving away from Loki config specific parameters we have Max concurrent tells each query how many queries they can process concurrently at one time this is based on each node CPU so if you see your query as ooing you can decrease this number next we have storage this section does feel like a duplication of storage unor config but it is important this tells our Helm deployment about our object storage type in this section we need to specify the type bucket names and the region make sure to fill in the gaps with your own bucket and region deployment mode the style of Loki you're deploying whether that be microservices or monolithic service account this is the secret source of all of our am work here we Define the IM am role we created earlier this will allow Loki pods to talk and interact with S3 buckets then we have Distributors ingestor queriers compactors to tell the helm how many replicas of each component to run increases as you need but this is a good place to begin with a medium workload note that we allocate persistence for each of these components so increasing the number replicas direct directly increases the amount of storage required on each of your nodes and last but not least we have Gateway this tells the helm to expose the engine X Gateway directly to the internet using the load balancer so we can write and read logs make sure to consider securing this endpoint more on authentication can be found within our docs okay with all the placeholders filled and the values files saved we are ready to deploy Helm install should do the trick it's important to create a namespace called Loki as our trust policy is set to allow the I am role to be used within the Loki service account in the Loki namespace this is configurable but make sure to update your service account this will take a couple of minutes so grab a Couer and come back nice to see that you're still still with me now to check if we've been successful let's start by checking that all pods are up and running next let's check our S3 buckets for signs of life we should see in the chunks bucket a file called Loki cluster c. Json this shows us that Loki has access to our S3 bucket don't worry it can take a while for Loki to flush chunks so take a little look back later to check for new directories containing your your stored logs so while you've been grabbing a cup of tea I have been a little cheeky and installed some extra monitoring features using the meta monitoring stack as well as writing some logs from my carnivorous Greenhouse application I will teach you more about meta monitoring in another video for now here is how to write logs to your own Loki cluster to start we need to find your Loki endo and create a tenant ID to get your Loki endpoint we can run Cube C get CVC DN Loki you're looking for the external IP attached to your load balancer the tenant ID can be anything that you like but remember when connecting grafana to Loki to use the same tenant ID otherwise you will not be able to query those logs and with that I think we are done congrat congratulations your Loki deployment is alive now there are a ton of post installation steps to consider such as authentication IM roll refinement config changes etc etc etc but if you ask me enjoy the little things your Loki cluster is up and running make sure to check out our docs page however to learn more about all these considerations now Azure and gcp users if you're feeling a little left out don't worry we are working on these guides as well it's currently a race to see if me or Nicole can get there first until next time make sure to join our Loki community and also let us know what you think in the comments below my name is Jay Clifford stay curious

