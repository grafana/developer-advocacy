# Allocution d’ouverture | ObservabilityCON on the Road Paris 2024

Rejoignez Cyril Tovena et Cyrille Le Clerc pour le coup d'envoi de ObservabilityCON 2024. Découvrez les dernières ...

Published on 2024-12-13T16:25:07Z

URL: https://www.youtube.com/watch?v=zG2D6jZjclM

Transcript: mesdames messieurs bonjour c'est un plaisir d'être avec vous aujourd'hui pour observability con on the road à Paris nous sommes 150 personnes c'est notre plus grand événement graphanalabs en France jusqu'à présent donc merci beaucoup à tous d'être venu le moment est venu pour nous de nous présenter je suis Cyril Leclerc je suis principal Product Manager chez grafanaalabs actuellement je travaille sur l'unification nos produits et sur la stratégie open télémétrie avant ça l'année dernière j'ai travaillé sur le lancement de nos offres application observability et frontain d'observability Cyr et moi pour pour que soyez encore plus confus je m'appelle aussi Cyril et je suis principal ingénieur chez grafana en ce moment je travaille sur Loki notre agrégation système d'agrégation de log et avant ça je travaillais sur pyoscope qui sert à faire du profilage d'application donc n'hésitez pas à me trouver toute la journée pour discu un petit peu de de ces sujets là dans le dans l'espace as si vous avez des questions siril en a parlé vous pouvez à tout moment venir nous voir nous serons sur les stands dans la salle et pendant les séances pendant les présentations utiliseer ce QR code pour poser des questions par une application web qui s'appelle slido donc n'ayez pas peur il y a pas un virus derrière ce QR code on l'a revérifié s'il vous plaît posez des questions et aussi ce qu'on vous recommande c'est de voir si d'autres personnes dans la salle ont les mêmes problématiques que vous pour que vous puissiez vous rencontrer et échanger sur vos expériences voilà chez grafanaalabs il est très important pour nous de venir à votre rencontre de vous écouter de comprendre vos cas d'utilisation et aussi de vous présenter notre technologie c'est peut-être plus important pour nous que pour beaucoup d'autres acteurs parce que nous avons cette ADN Open Source beaucoup de nos produits sont incubés en open source avec des très fortes discussions avec les utilisateurs pour être à votre rencontre on a plusieurs types d'événements les webinars là c'est online à distance il y a eu 80000 inscrits l'année dernière à nos webinars merci beaucoup pour votre confiance nous avons aussi des workshops des ateliers où nous venons dans vos villes pour vous présenter nos technologies pour mettre les mains à la patte avec vous 7000 inscrits l'année dernière sur les workshop nous avons aussi des conférences grafanacon notre conférence aujourd'hui qui est notre principale conférence elle est à propos de nos produits de notre entreprise de nos clients c'est là on parle d'observabilité et à côté de ça on a pardon c'est observability con ça graphanacon qui est l'événement Open Source donc notre socle notre ADN est open source c'est un événement communautaire qui va plus loin que l'observabilité parce que les cas d'utilisation de grafana la visualisation sont très larges donc c'est un moment communautaire avec tous nos contributeurs on discute de road map euh de présentation technique et aussi on remet des Awards aux contributeurs donc voilà euh comment euh nous allons à votre rencontre ce qui est très important donc s'il vous plaît venez nous voir euh partagez avec nous votre expérience que nous apprenions mieux je vais aller maintenant sur euh quelques chiffres et quelques éléments de la société graphanaalabs euh pour donner des chiffres on va commencer par les chiffres Open Source puisque notre stratégie c'est d'avoir euh supporter des projets open source qui ont une très large adoption en gratuit et ensuite nous de monétiser seulement une petite part euh de ce euh ces utilisateurs open source et nous j'ai pu discuter avec vous ce matin beaucoup sont utilisateurs open source et nous vous en remercions donc cette année nous avons passé le cap des 25 millions d'utilisateurs Open Source actif sur grafana la visualisation merci beaucoup pour votre confiance c'est une croissance forte c'est un projet qui continue euh à se déployer beaucoup côté commercial nous avons passé le seuil des 5000 clients merci à vous merci aux clients historiques merci aux nouveaux clients qui nous faut confiance aussi qui est client dans la salle s'il vous plaît il y a des clients merci beaucoup et qui est intéressé éventuellement à devenir client merci bon les équipes de vente sont là n ne vous inquiétez pas 250 millions de revenus annuels cette année que nous avons franchi donc un seuil à nouveau comme je vous ai dit euh notre ADN est Open Source nous avons eu de nombreuses reconnaissances par l'industrie encore non seulement sur nos projets open source ce à quoi nous avions le plaisir d'être habitués mais aussi de plus en plus sur la reconnaissance de notre offre Entreprise nos solutions que nous construisons avec une facilit d'utilisation plus grande des produits Open Source en général ils sont utilisés d'abord par les early adopters excusez l'anglicisme par les bleeding Edge adopteurs et on en connaît certains dans la salle mais après il y a pour l'adoption entreprise il faut des solutions qui soi plus clé en main pour des utilisateurs qui ont peut-être moins le temps de rentrer dans le cœur des technologies Open Source d'observabilité qui ont besoin de facilité d'utilisation et un un événement clé pour nous cette année a été la reconnaissance par le Gartner Group où nous avons été nommés leader dans le Gartner Magic Quadrant pour observabilité qui ici utilise le Gartner Magic Quadrant pour fonder ses résultats voilà il y a un certain nombre d'entreprises et donc nous sommes au rendez-vous nous avons eu le l'honneur d'avoir été nommé leader je vais continuer avec notre programme start-up jusqu'à présent nous avions une offre pour les start-ups qui était composée de nos brick open source et j'ai pu discuter aujourd'hui avec vous nos brick open source sont utilisés à très large scale en production sur des systèmes critiques c'était déjà au rendez-vous nous avions aussi le free tier sur notre offre SAS et cette année nous avons le plaisir de lancer un startup programme de 100000 dollars utilisable sur l'ensemble de notre catalogue produit à la fois l'offre SAS à à la fois l'offre selfmanagé pour l'alerting pour le incident response management pour le monitoring les traces les métriques les logs pour le testing synthetics monitoring tout ce que vous voulez et au bout de ces 12 mois ou 100000 dollars dépensés après vous aurez 20 % de réduction sur votre catalog notre catalogue si vous êtes intéressé euh cliquez sur ce QR Code et euh venez discuter avec nous je vais continuer maintenant avec les piliers qui nous ont motivés encore l'année dernière pour améliorer notre offre et qu'on va vous présenter aujourd'hui trois thèmes une facilité accrue d'utilisation de lgtm notre stack d'observabilité deème thème eiml il peut pas y avoir de conférence tech sans parler de mieml Cyril vous euh parlera de tout ce qu'on fait là-dessus et un troisième point comment nous faisons évoluer le rout cause analysis le troubleeshoooting excusez l'anglicisme la façon de détecter les anomalies c'est parti facilité plus grande sur lgtm alors lgtm ça veut pas dire looks good to me pour grapanaalabs c'est ce sont les l'acronyme les initiales de nos produits l Loki les logs comme cy en a parlé grafana c'est la visualisation le G t tempo les trace et M Mimir les métriques promius et maintenant on rajoute P pyroscope pour le profile dont cy a aussi parlé et donc on facilite l'utilisation de toutes ces technologies un premier pas sur grafana la visualisation vous connaissez probablement l'écosystème des DAT sources qui permet de connecter jusqu'à 200 systèmes externes pour accéder aux données en plus de ça il y a 4 ans maintenant nous avons lancé les grafana integrations qui sont sur grafana cloud c'est une approche clé en main qui combine des tableaux de bord des dashboards des alertes clé en m par défaut avec les bonnes valeurs et aussi une instrumentation euh surétagère avec grafana Eloy autrefois appelé grafana agent et nous sommes arrivés maintenant après 4 ans d'existence à 100 intégration donc complètement clé en main vous déployer notre plateforme d'instrumentation votre middleware votre technologie instrumentée vous avez les tableaux de bord tout est prêt donc ça a été un gros progrès et maintenant nous avons le plaisir de voir que 25 % de la télémétrie que nous collectons sur grafana Cloud est issu de ces intégrations donc on voit que vous les utilisez largement pour collecter vos données nous avons en plus étendu l'année dernière au-delà de ces intégrations un cran plus loin avec nos ce que nous appelons nos applications grafana cubernetis monitoring grafana application observability frontend observability euh pour faciliter encore l'expérience et une expérience encore plus riche et cette année j'ai le plaisir de vous annoncer le lancement de notre application grafana cloud provider observabilité qui est issue des dashboards des alertes qu'on avait créé pour et notre intégration pour cette fois-ci vous fournir une expérience qui est cohérente sur tous vos cloud providers pour comprendre la consommation l'exist le monitoring de toutes vos ressources Cloud et tout ça avec aussi une installation simplifiée elle est serverurless dans le sens où vous avez pas besoin de déployer un agent de collect sur vos plateformes pour collecter vos maîrices AWS cloudwatch ou l'équivalent chez Google ou Azure c'est directement notre plateforme Cloud qui va se connecter à votre cloud provider et collecter les métriques avec vos créen les données matric log trace pas trace mais metric log avec vos credentials donc grafana cloud provider observabilité et generally available désormais essayez faites vos retours je vais continuer avec un sujet bien différent maintenant mais aussi on a apporté beaucoup d'innovation c'est lié aux tests et c'est lié à l'évolution à la fois de synthetic monitoring qui a été la première offre SAS que nous avons offert sur grafana cloud avec des synthétic qui était à leur début bien sûr assez simple et combiné avec grafana ksx qui est un outil de performance testing de l' testing de test browser qui est né dans l'OP source qui utilise grafana KX dans la salle c'est un peu un jam sur stéroïde donc voilà il y a plusieurs utilisateurs et nous avons le plaisir cette année d'avoir pu faire l'unification entre les synthetic monitoring et performance testing toend testing dans une forme de shift left où vous pouvez utiliser la même définition de test performance testing and user testing pour vos tests synthétiques et à ce momentl vous pouvez les déployer sur grafana cloud avec notre synthetic plateforme qui est déployé sur 25 points de présence au travers le monde un point de présence en France beaucoup en Europe beaucoup aux États-Unis et aussi en Asie et comme ça vous pourraz tester partout la disponibilité de vos cas d'utilisation critique en réutilisant avec une bonne intégration avec la QA et les tests on va continuer sur ces tests avec le lancement de KX studio jusqu'à présent nos tests de performance et de non régression étit définis par des scripts et on sait que notamment dans les équipes de QA il y a des personnes qui ne veulent pas utiliser de script qui préféent une interface graphique et c'est ce que nous permettons avec grafana cas studio qui est désormais disponible en expérimental et qui euh collabore avec un browser Google Chrome sur votre poste pour enregistrer vos séquences de test que après vous pouvez réadapter pour euh les mettre en production sous forme de test de perf et toute cette approche browser web serait insuffisante si on ne pouvait pas faire des tests synthétiques qui simule un vrai browser web pas seulement quelques appels rest à aux API euh de vos cas métier et nous avons le plaisir pour ça de lancer sur notre platforme de synthétique cette fois-ci des tests synthétiques qui simule complètement un browser on démarre un browser sur notre point de présence un de nos 25 points de présence que vous avez choisi et on va faire votre le test de votre cas d'utilisation métier bout en bout en chargeant toutes les ressources C en l'occurrence avec un browser headless chrome donc voilà on continue à innover beaucoup sur les tests pour vous et à les intégrer avec la production je vais changer complètement de sujet l'observabilité à de plus en de plus en plus important on voit qu'il y a l'essort en ce moment de open télémétrie comme standard des facto d'instrumentation et on sait qu'il y a toujours des difficultés de migration d'un vendeur vers un autre d'une technologie vers une autre et nous avons aussi beaucoup travailler j'en parlerai plus plus tard aujourd'hui sur la facilité de migration et pour ça nous avons cont b avec le projet Open telemetry en donnant à une capacité à migrer depuis dat dog vers open telemetry tout en gardant temporairement les instrumentations datadog peut-être que vous avez utilisé datadog avec des custom matrixs écrit dans votre code avec le SDK datadog où vous avez des agents datadog qui mettent du temps à migrer vers un standard open source et pour ça nous avons travaillé avec la communauté Open tellemetry pour implémenter un dat dog receiver qui vous permet de euh convertir la collecte de données dat Dog mtrique et trace en format Open télémétrique qui après peut être envoyé chez grafana cloud ou grafana en général si vous avez nous faites confiance que nous souhaitons voilà c'est un ensemble d'innovation déjà sur la partie test et la partie migration qu'on avait le plaisir de vous annoncer maintenant je vais laisser la main à Cyril pour vous parler d'un autre thème sur lequel nous avons beaucoup innové cette année merci Cyril BJ j'ai entendu une page tout à l'heure j'espère que tout va bien j'ai eu un petit moment de solidarité quand j'ai entendu le le téléphone euh alors donc pour poursuivre un petit peu notre discussion dans la simplification il y a 6 mois de ça peut-être même un petit peu plus on a lancé explor mrique et explor logs à laagrap anacon et depuis on a eu vraiment un retour d'expérience de la part de de la communauté de vous qui a vraiment été monumental on est vraiment content du résultat et on continue en fait depuis ce jour à travailler rapidement et à inclure tous les feedback qu'on reçoit le but de ces deux applications vraiment c'est de simplifier un petit peu l'utilisation de de vos bases de données de de d'avoir du retour sans avoir besoin écrire des requêtes lql pour loky et puis promql pour pour promoteus je sais que généralement c'est plus les SRE qui sont habitués à faire ce genre de requête qui mettent des alertes en place quand on parle des applications devveloppur des fois on n' pas vraiment le temps de de de de commencer à apprendre un nouveau langage on en a suffisamment assez euh du coup cette expérience là est plus point and click on n pas d'écran vide on démarre de suite avec une vue globale de de vos données d'observabilité puis on peut commencer à filtrer puis à rentrer dans les détails juste en faisant du point click donc la la vélocité de ces deux applications vraiment très rapide en ce moment je travaille dessus on a on a pratiquement quatre équipes qui travaillent dessus donc n'hésitez pas à nous donner du retour et puis n'hésitez pas à le mettre à jour aussi souvent ah donc je suis aussi content aujourd'hui de vous dire que ces deux applications expor logs et export matrix sont maintenant en ce qu'on appelle g general availability en gros ça veut dire tout simplement que nous ça fait pratiquement plus de 6 mois qu'on les utilise en production et que on a peaufiné un petit peu tous les bugs et puis on est plutôt content du résultat il y a quand même pas mal de nouvelles de nouvelles feature qu'on a rajouté nouvell fonctionnalités donc n'hésitez pas à aller voir puis on s'arrêtera pas là on a plein de de features qu'on compte rajouter dans le futur euh en ce moment les dernières les dernières choses qu'on a fait par exemple c'est du streaming sur le sur expor logs je sais que des fois il y a des requêtes qui peuvent être un peu longues euh du coup on va attendre jusqu'à 30 secondes on va avoir un résultat là on va commencer à envoyer des résultats avant on va petit à petit progressivement vous vous montrer un petit peu l'avancement de la requête sur explore matrix euh on a le support pour Open téléétri qui a été lancé récemment donc ça aussi c'est intéressant ça viendra aussi sur euh sur explore log on est en train de regarder euh on est en train de regarder ça attentivement euh on a une session euh euh aujourd'hui ou avec Alain cet après-midi où on discutera plus en détail de toutes les fonctionnalités je vous montrai la dernière version euh des applications Alain il fera pareil donc on va passer à travers toutes ces apps puis n'hésitez pas si vous avez des questions pour ces apps à venir me voir pour en discuter puis euh je peux vous faire des démos euh dans la salle là-bas si besoin donc forcément bah ça a été un gros succès donc on s'arrête pas là on continue euh on a lancé aussi export trace et export profile qui qui viennent compléter un petit peu cette cette solution explore point and click à travers tous les signaux d'observabilité que que l'on a personnellement moi j'utilise explore profile vraiment très souvent c'est vraiment très simple d'aller puis de rapidement avoir des informations sur la performance de vos applications euh donc ces deux là ont été rajoutés récemment pareil a à peu près 6 mois on les considère en public preview euh et donc le développement est encore rapide puis on rajoute donc n'hésitez pas à donner à donner du feedback si vous en avez puis on va on va on va prendre ça pu on travaille vraiment avec la communauté on écoute on écoute les clients donc ça se fait à travers les ripos open source de de de ces quatre applications euh et ces applications sont aussi maintenant et de plus en plus ça va être déployé automatiquement les grafana la plupart vous avez besoin généralement de d'ajouter un pluging ça sera plus le cas dans le futur en fait elle vont être automatiquement ajouté à grafana quand vous l' installer ça va être le cas de la prochaine version ou si vous êtes en train d'utiliser le le Edge vous allez l'avoir de suite donc euh après avoir complété un petit peu ce cette suite d'explorap on se retrouve en fait avec trois cas trois façons en fait d'explorer vos données moi je considère pas que en fait il y en a une qui est spécialement meilleure que l'autre c'est plus une question de ce que vous avez besoin selon votre niveau et euh euh ce que de de comment vous vous sentez à l'aise avec une des trois façons donc vous avez le code forcément si par exemple comme moi vous avez travaillé sur li vous connaissez locel parkerur vous savez comment rapidement écrire une requête et et tirer parti de la de la base de données ben on va utiliser du code sachant qu'avec le code on en pour faire des choses toujours un petit peu plus poussées que qu'on peut faire en fait avec les autres expériences la deuxième ça va être ce qu'on appelle du Low code en fait c'est toujours du code mais on vous aide à fabriquer avec une interface les requêtes vous allez avoir des des des dropdown dans lesquels vous allez pouvoir choisir le type d'agrégation puis vous faites plus vous ajoutez une autre opération plus vous continuez donc c'est plus guidé et puis finalement ce que ce dont je viens de parler les les applications explore qui elles sont vraiment point and click pas d'écran vide on a on a d'autres petites features sur sur ces applications qui sont aussi intéressantes mais c'est vraiment beaucoup plus facile pour démarrer et commencer à apprendre un petit peu comment tirer partie de ces de ces de ces bases de données euh je vais passer une petite démo enfin une petite démo un petit peu de explore trace qui est le dernier qui est le dernier dans le dans le dans le voisinage je suis désolé je cherche mes mots des fois en anglais et en français euh donc je vais faire une démo rapide on va pas on va pas on va pas y rester trop longtemps principalement parce qu'encore une fois cet après-midi avec Alain Alain il va repasser au travers de tout ça donc là j'ai une instance graph an cloud vous pouvez refaire cette démo à n'importe quel moment chez vous tout ça c'est Open Source euh donc dans le menu grafana au niveau de explore si vous cliquez sur explore vous tombez sur le explore que tout le monde connaît d'habitude où on tape les les requettes et en dessous vous avez les applications les nouvelles les quatre nouvelles applications donc si je vais sur explore trace euh par défaut il me montre en fait ce qu'on appelle les Red red matrix donc rate euh error et durations donc c'est les trois là qu'on a en haut hein et puis c'est généralement ce qu'on ce qui est la méthodologie la plus utilisée pour voir un petit peu la santé de vos de vos services donc je vais changer un petit peu pour avoir un petit peu plus de données parce que là on est là il montre par trace on peut le changer donc vous avez plusieurs façons ici on peut le mettre par serveur span consumer span je je vais juste les mettre toutes ensemble hop donc là on voit tout toutes les span il agrège en fait par span pas par trace simplement donc je peux cliquer sur erreur par exemple et sur erreur donc là je focus et je suis en mode erreur je suis en train de regarder tout toutes les erreurs de span qui qui existent par défaut en fait en dessous vous avez un breakdown par service donc en fait il décompose un peu il vous montre dans dans quel service ça c'est en train de se passer imaginons je suis en train de je suis en train de travailler et je reçois je reçois une page et on me dit ben c'est le produit catalogue il y a quelque chose qui va pas vous pouvez facilement ajouter un filtre puis là on est juste en train de regarder ce qui se passe sur le product catalogue sur ce service là et donc donc on a plusieurs tables un table que je voulais vite fait passer dessus pour vous montrer c'est le la comparaison en fait il va faire une comparaison entre la la base où il y a pas d'erreur et les traces où ou les span où il y a des erreurs et va vous sortir les spans qui sont vraiment différentes des autres donc rapidement on peut voir par exemple que on a un produit en particulier qui est souvent en erreur par rapport aux autres et donc je peux en fait aller le chercher l'ajouter au filtre et là je vois en fait que les span de ce produit là et ensuite je peux aller voir donc les les traces et puis je peux prendre une des traces donc tout ça c'est des traces qui ont cette erreur là par spécialement cette erreur là donc je peux cliquer puis je peux commencer à essayer de de comprendre un petit peu ce qui se passe dans cette trace là donc si je hop je fais ça là je peux avoir des informations un petit peu sur l'erreur donc voilà une magnifique erreur qu'un développeur à écrit euh on peut fermer ça et puis je vais vite fait vous montrer donc je vais enlever les filtres donc vous avez vu en fait au fur et à mesure que j'étais en train de de de cliquer un peu partout sur l'expérience il a créé une sorte de petit filtre automatiquement et en fait il a créé une roquette derrière moi j'ai pas eu besoin à la prendre cette requette donc on enlève tout ça et je vais mettre sur Full trace je va revenir sur Full trace est-ce que SII je vais vous montrer pour ce qui est les duration donc la la la latence alors là c'est là ma vue est un petit peu différente en fait je suis en train de regarder toutes les traces et en fait toutes les requettes qui qui rentre dans mon dans mon application et je regarde celles qui sont les plus lentes donc on voit qu'il y a un service en particulier qui est un petit peu plus lent que les autres par exemple mais si on veut on peut aussi très bien sélectionner par exemple en haut et puis je peux m'intéresser que vraiment au très très lente et donc là encore on repart sur du breakdown et puis on peut essayer de trouver quelle trace en particulier est plus lente que les autres pour quelle raison donc vous avez tous les attributs que vous pouvez regarder et puis ça vous peut vous permettre peut-être d'avoir plus d'in formtion sur ce qui se passe dans votre système là juste juste avec les pulantes je peux aller sur montre-moier puis je peux commencer à regarder un petit peu le flow de ces de ces de ces traces qui sont lentes donc rapidement on peut les trouver ces traces là c'est pe près tout pour la démo on va repasser au slide s'il vous plaît ok on va parler un petit peu d'un sujet show eaml euh donc eaml moi personnellement je suis un grand grand utilisateur de eaml tous les jours dans dans dans mon travail j'utilise cloud principalement et cursor avant j'utilisais copilote mais j'ai complètement été copilote et je suis passé à à cursor je trouve que c'est vraiment génial pour écrire du code et tout ça pour dire que chez grafanalab on a beaucoup réfléchi on est aussi des utilisateurs d'ml on s'est beaucoup demandé qu'est-ce que ça voulait dire pour l'observabilité et on pense qu'en fait c'est un peu comme ces outils là que je viens de de mentionner ça va plus vous rendre plus performant plus rapidement et pas spécialement vous vous remplacer la semaine dernière j'étais en train d'écouter justement une discussion de de Jens and Wang de le CEO de Nvidia qui justement avait reçu cette question là et qui dis qu' ont lui demandé vous avez pas peur de de de couper enfin de de perdre votre travail est-ce que un ingénieur demandait moi je je pense que je vais perdre un jour mon travail vous avez pas peur de ça et sa réponse est intéressante il disait en fait c'est pas l' qui vaêtre remplacé c'est quelqu'un qui est en train uer l' qui va te remplacer donc l' c'est vraiment censé être là pour nous aider et pour être plus plus devenir un expert plus rapidement pourir un expert avec nous donc c'est un peu le cas de ce qu'on a avec ce qu'on a créé avec adaptive matric qui qui est en fait qui qui roule beaucoup de machine learning dans votre ingestion de de mtrique je sais que dans beaucoup de compagnies il y a toujours un expert de un produit donc par exemple promoteus donc chez nous il s'appelle br et cet expert là il il connaît tout sur le système et quand il y a un problème par exemple h trop de trop de trop de métriqu il y en a une qui est qui a trop de cardinalité où il y a un service qui qui qui qui qui déclenche beaucoup de de euh de de de cût généralement on va se retrouver à demander à Bryan est-ce que tu peux regarder un petit peu le système et m'aider à trouver où est le problème et puis Bryan avec toute son expérience il va il commencecer à regarder et puis il va all changer les les configurations promoteus puis va aller changer son votre ingestion aller peut-être même changer le col de votre application puis ça y est on est content le but de adaptive métrique c'est ça c'est d'avoir toujours Bryan avec vous qui en fait automatique mais le fait de façon automatique vous avez pas besoin d'être un expert et donc ça vous permet de réduire énormément vos coûts de métrique puisque il va aller automatiquement vérifier les métriques qui sont utilisées s'il y en a qui ont beaucoup de churn en fait qui change souvent et que vous utilisez pas et automatiquement il va aller les agréger donc on va vous allez vous retrouver avec beaucoup moins de points donc si on a par exemple une quinzaine de de labels qui sont sur des pafs que vous avez jamais couré une seule fois c'est dommage parce que vous êtes en train de payer 15 fois plus en fait pour cette série doncct on a vraiment vraiment c'est vraiment on a un bon retour on a sauvé à pe près 640 millions de séries ce qui à peu près 10 millions je crois qu'on avait fait le calcul c'est à peu près 10 millions de dollars qu'on a refusé de prendre à à nos clients et à l'inverse en fait ils peuvent investir cet argent dans d'autres produits je parlais de profiling tout à l'heure ou arm ou donc ça c'est c'est vraiment la stratégie qu'on a avec adaptive metric et euh récemment on a lancé adaptive log alors adaptive block cétait un peu plus compliqué ça nous a pris par contre beaucoup moins de temps forcément on avait l'expérience de de adaptive matric mais c'est beaucoup plus compliqué mais on a aussi trouvé un moyen en fait de aussi réduire les coûts au niveau des logs les logs qui comme vous le savez peuvent être très verbeux et puis on pe très rapidement en avoir beaucoup surtout si une application est est souvent poussée euh donc comment ça marche un petit peu rapidement adaptive logs en fait ça regarde les logs que que qu'il reçoit il va essayer de détecter des patterns donc des patterns de de de log de à quoi à quoi ces log ressemblent vous avez des exemples à l'écran et il remplace en fait vous voyez pas des étoiles une fois que ces patterns sont trouvés il vaer vérifier si c'est si vous voulez si vous faites des requêtes et sils sortent aussi si vous en avez l'utilité et puis il va vous proposer de faire du sampling sur donc de de la réduction de ces logs donc on les on les supprime pas complètement mais on va aller en en retirer une une forte quantité de ceux que vous utilisez pas et bien sûr ça c'est toujours à la demande c'est quelque chose que vous choisissez c'est pas automatique vous vous allez vous-même regarder les recommandations que le système fait pour vous euh on a on est entre 40 et 60 % pour nous-mêmes en ce moment donc on on roule on on fait de la on a quand même pas mal confiant avec adaptive logs euh et donc n'hésitez pas à l'utiliser c'est c'est maintenant disponible ok donc forcément il y a un thème là qui suit on commence à on a commencé avec ces deux-là on s'arrêtera pas là euh et donc on commence à regarder adaptive trace adaptive adaptive profile euh le but en fait de cette télémétrie adaptive c'est un environnement où nous allons éliminer tout le bruit qui n'est pas nécessaire et seulement garder les signaux qui sont pertinents pour vous euh pour ceux qui auraient souhaité qu'on soit pas spécialement en recherche pour ces deux-là j'ai quand même une bonne nouvelle c'est que récemment grafanalabs a fait l'acquisition d'une compagnie qui s'appelle tail control et c'est chaîn porteur qui est à la tête de cette compagnie et c'est lui qui va liid un petit peu cette ces deux nouveaux adaptive produit euh et donc sa vision à lui c'est à chaînne c'est vraiment s'assurer que toutes les traces qu'on ingère on en a besoin on parlera plus d'Adaptive télémétrie ce matin je pense de la session de 11h avec Rob qui est le manager de l'équipe de eaml donc et puis encore une fois n'hésitez pas à venir me voir je pense que je suis un peu je suis un peu en retard donc je vais accélérer un peu on a les donc on a travaillé aussi donc toujours dans le même thème de l'AII on a travaillé sur quelques nouveaux produits pour l'observabilité des LLM euh donc ces produits là il y en a trois c'est encore très expérimentaux on travaille avec la communauté pour essayer de de de de trouver les de bâtir les meilleur produit pour que vous puissiez observer les LLM donc on a une extension de ibpf sur baaya qui vous permet en fait de regarder les col CUDA que votre application est en train de faire donc ça permet de faire de l'observabilité sur vos colcuda sans changer le code on a une intégration open lit qui est un framework open source d'observabilité pour les LL euh donc on a des des dashboards qui sont tout fait pour vous des alertes et puis on travaille avec NVIDIA sur une application pour le training qui vous permet de voir la la qualité de votre training la rapidité et ça c'est fait en partenariat avec NVIDIA ok euh le le les agrafanal on a une culture très bottom up et on on chérit pas mal cette culture là et un exemple concret de cette culture là c'est le akaton interne donc tous les trimestres on a un acinton interne à la compagnie où on forme des équipes pas spécialement avec des gens qu'on travail tous les jours on peut choisir qui on veut et donc c'est des équipes de 5 pendant une semaine pas de meeting pas de pas de de d'autres en gros vraiment que que du focus sur ce travail là et on travaille un petit peu sur ce qu'on veut ce qui nous tient à cœur nous et ce qu'on pense qu' pourrait faire avancer l'observabilité c'est d'ailleurs comme ça que explore a été lancé et euh je vous parle de ça parce que en à la fin en fait de la semaine chaque équipe doit faire une petite vidéo généralement une petite vidéo qui est un petit peu drôle pour présenter son produit puis on a un jury qui vote et on a toute la compagnie qui vote et puis le premier gagne un prix un prix d'argent le dernier vainqueur il s'appelle incident room donc je sais pas si vous connaissez Gong est-ce que dans la ça il y a des gens qui connaissent le produit Gong ok quelques personnes donc je je rapidement je vous explique Gong en fait c'est un sorte de bot qui vient dans vos meetings généralement c'est plus les sales qui utilisent ça donc je comprends pourquoi ici il y a pas grand monde qui connaît et c'est honnêtement c'est vraiment pas mal il rejoint votre meeting il prend des notes en fait juste en écoutant en plus il est capable de prendre les notes et de de les mettre directement à quelle personne exactement a dit quoi et ça vous permet d'avoir en fait une transcription qui crée une une sorte de base de données puis après plus tard vous pouvez taper qui parle de quoi c'est quoi la tendance qui est-ce que mes C se plent le plus souvent de ça c'est intéressant il on fait un peu la même chose mais quand vous êtes dans un incident donc on va regarder la vidéo de le présentation de est-ce que je lance stay focused on resving issues while keepingurate records during the intensity of an incident it's easy to forget to document crucial details let's step into a day in the life of our incident response team before incident rooms so the problem is that the coffee machine is out of memory again why is our coffee machine equipped with memory it stores profiles for different coffee types I'm following the runook anded water beans and power have you tried power cycling it oh that's a good idea give me a yeah looks like power cycling helped i think that resolves the incident then right I think so can someone mark the incident as resolved looks like the coffee is brewing again everyone's going to be happy including me thanks everyone great work team I'll document the steps taken their expertise leads to a swift resolution notice their intense focus on the problem but also note notes and logs are sometimes missed in the process with no notes or logs they resort to using an ai to help when there is no context the AI hallucinates generating a report filled with inaccuracies now let's reimagine this scenario with incident rooms incident rooms is a built-in feature within incident enhanced by a helpful LLM bot now our team enters an incident room with the B seamlessly integrated into their workflow while the team focus RESV the issue the B keeps track of their conversations notes keys and responds to voice commands allowing them to stay fully engaged in problem solving but the B isn't just a note Taker he's learned a few new tricks too from executing grafana incident actions on your behalf to delivering instant ADH summaries via the grafana incident slack assistant the bot makes managing incid smoother and more efficient throughout the process stakeholders can interact with the bot for realtime updates on the incident status this ensures that everyone is informed and up to date effortlessly with the bot by your side sinking incident statuses providing updates or running actions across different media channels has never been easier or faster we're excited to see how incident rooms can revolutioniz your incident response workflow ok c'est à toi merci beaucoup et donc ça on va le productiser c'est ça c oui ouais donc ça va tre bientôt une une nouvelle fonctionnalité et c'est cette culture d'innovation en bottom up les idées des ingénieurs comme c'est le cas dans les startup sont convertis en fonctionnalité et après les produ managers comme moi ont la responsabilité de comprendre comment ça s'intègre avec le portfolio ce qui est pas forcément simple mais bon je vais changer de sujet complètement euh complètement pas complètement de toute façon c'est de l'obsability c'est rot cause analysis troubleshoooting je suis désolé les anglicismes là sont nombreux et euh on a repris un une affiche qu'on avait publié dans un billet de blog il y a 9 ans où il y a 9 ans on avait eu l'audace de dire que nous allions démocratiser les métriques et quand on regarde le chemin parcouru le succès de promius sur lequel nous avons été un Act un contributeur clé et le succès de grafana pour la visualisation des maétriques et en particulier de promitius euh nous sommes assez fiers de l'endroit où est l'industrie maintenant sur les métriques et de la même façon aujourd'hui nous voulons innover sur le troubleshoooting alors pourquoi innover sur le troubleshoooting pourquoi est-ce que le troubleshoooting est difficile la première raison qu'on a oublié de mettre sur ce slide je pense c'est qu'on n pass on a complètement changé la façon de faire de l'IT où avant on avait des applications très monolithiques et on a évolué progressivement vers du microservice et euh tout tout ça en passant aussi de data center avec des machines très fiables vers des cloud avec du design for failure avec des choses moins fiable et donc on a complètement changé les les architectures de nos systèmes et on doit changer la façon de monitorer de faire du troubleeshoooting et donc aujourd'hui ça se passe pas bien c'est difficile le troubleshoooting qui a des difficultés de troubleeshoooting aujourd'hui avec des problèmes d'alerte fatigue par exemple avec des problèmes pour trouver les pannes réelles ou être notifié juste des panes réell qui impactent les utilisateurs il y a des gens dans la salle qui ont ça il y en a un certain nombre donc vous comprenez probablement pourquoi on travaille dur à essayer d'améliorer ça et j'imagine que vous aussi vous travaillez à améliorer les pratiques de trouble shooting donc parmi les gros problèmes qu'on a identifié il y a le fait qu'on a des silos en notre nos applications avant les signaux trace mrique log profil étai assez disjoint et donc quand on voulait trouble shooter et trouver les liens entre les choses pour trouver les causes on n arrivait pas une des raisons importantes aussi était que les la façon d'annoter les données entre les traces mriqu et log ou entre les différentes instrumentations j'instrument avec istio j'instrumente mon serveur Tom 4 mon DNET mon Linux tout ça avait des labels différents donc j'arrivais pas à naviguer facilement d'un signal à l'autre d'une application à l'autre parce que j'instrumentais avec des technos différentes qui avaient des labels inconsistants entre elles et j'avais des architectures variées aussi donc tout ça causait des grands problèmes et aujourd'hui chez grafana laabs nous vous prop on une rupture là-dessus que nous appelons asserts c'est l'idée vous venez avec vos instrumentations tes qu'elles sont vous avez instrumenté du DNET du node du nginix du kubernetes avec différentes technos d'instrumentation peut-être des custom mariqu et nous introduisons un moteur d'inférence qui lui va consommer toutes vos données toutes vos maétriques qui va refaire un mapping pour redéfinir les reclassifier réidentifier ce qui est une RM dont a parlé CYR SUR response time rate error rate qui va ensuite faire une topologie de tout ça pour vous offrir après une expérience unifiée de troublehoooting qui va vous permettre de basculer facilement depuis un système à un autre depuis une techno à l'autre infrastructure monitoring application monitoring real user monitoring on peut basculer en permanence entre tout ça rien de tel pour vous montrer ce que c'est que une démonstration alors première simplification qu'on a fait toujours la simplification c'est qu'on a créé un assistant pour créer des SLO en suivant les bonnes pratiques de l'industrie et qui fonctionnent bien dans le monde grafana donc maintenant vous avez un Wizard qui vous permet de prendre les services que vous avez détectés qui sont détectés par vos instrumentations ou qui peuvent provenir aussi de vos custom mrique donc vous avez pas de migration trop compliqué à faire toutes les bonnes pratiques sont là Service Level Agreement à 4 199 euh ma violation je suis un petit peu en dessous actuellement et j'ai mon burnon mon error budget où je consomme actuellement plus que mon engagement ensuite si je bascule sur l'alerting il me faut des alertes qui ont du sens qui sont actionnables et c'est ce qu'on vous propose là euh avec la suite grafana et avec un lien vers une page qui va vous faire un résumé de votre anomalie et c'est là tout le root cause analysis Workbench où vous avez un un résumé à la fois du service qui a un problème et aussi de toutes ces dépendances pour comprendre commencer à chercher qui est la cause qui est la conséquences des anomalies pour chacun des services qui sont liés dans ce upstream downstream je vais voir quels sont les les warnings et les erreurs qui sont détectés pour ça on a utilisé ce qu'on appelle des assertions qui sont des indicateurs de bonne santé ou de comportement étrange euh sur le système Cyril vous avez parlé de notre utilisation de IML on le retrouve j'ai basculé sur la service m qui est un élément clé du troubleshoooting applicatif comme d'habitude où je retrouve toutes mes assertions mes warnings mes erreors pour continuer mon exploration et après je peux rebasculer pour retrier là c'est trié par un score d'anomalie et je vais basculer sur un algorithme qui va chercher quelle est la cause probable les problématiques connections là je parcours mon graphe et je vais rescorer mes services par euh la chaîne d'invocation et de ceux qui sont impactés ensuite je vais basculer sur les KPI d'un service j'ai envie de zoomer sur un des services donc là je je sélectionne les KPI et je vais pouvoir voir la santé de ce service je vois que ce service est un des points d'entrée HTTP ils sont tous impactés actuellement ils sont tous en rouge et donc je vais pouvoir rebasculer ici sur une vue orientée real user monitoring je pense que c'est un problème lié que je vais comprendre mieux m avec Real user monitoring donc on vous fait basculer vers une vue real user monitoring pour cette phase de l'investigation vous avez les données classiques de real user monitoring first cont pain et ainsi de suite et vous pouvez ensuite recontinuer votre investigation et là je vais passer sur une vue timeline une vue chronologique et je vais voir que il y a un événement sur ma plateforme on sait que beaucoup d'anomalies sont causées par des changements sur la plateforme des déploiements et là je vais avoir un événement qui est en ble bleu qui va être l'activation d'un feature flag la démo prend un petit peu de temps euh et donc un grand travail a été fait pour vous aider à corréler vos anomalies sur vos services avec les événements structuraux les déploiements sur votre plateforme donc là je trouve qu'il y a une activation de feature flag et je vais identifier qu'il y a un service en particulier qui semble impaccté qui semble être tombé depuis l'activation de ce feature flag j'ai une régression il faut pas qu'on ait peur des régressions quand on déploie parce que de de toute façon on est obligé de déployer mais il faut qu'on ait confiance lorsqu'on est des régressions parce qu'on est capable de les corriger c'est ça tout notre idée donc je rebascule sur les KPI là je vais pouvoir basculer entre mes logs mes traces ma vue kubernetes parce que c'est un service qui est déployé sur kubernetes et j'ai vu que j'avais une crash loop sur ce service je bascule sur ma vue APM application observability où j'ai mes indicateurs classiques red matrix mes services downstream upstream tout ça vous a offert par notre vision de troubleshoooting unifié je vais accélérer un peu avec maintenant donc cette nouvelle vision de troubleshoooting qui est disponible dans grafana cloud qui vous permet comme j'ai dit à la fois d'utiliser vos données instrumentation classique de type open télémétrie et à la fois de venir avec vos custom matric ou vos instrumentations autres micrometer exporte promitus et a ite ce système de troubleshoooting est déjà utilisé par des clients en production et ici on a une citation de notre client Blackrock avec qui on a collaboré énormément pour définir ces interfaces qui utilise désormais grafana Cloud aserts pour le troubleeshoooting de ces applications les plus critiques donc voilà c'était une présentation de cette nouvelle fonctionnalité grafana cloud asserts pour faire du troubleshoooting notre rot cause analysis workb qui unifie en plus tous nos systèmes application obsity fron obsity cubernettis monitoring SLO management et à chaque fois qu'on a nouvelle vue de trouble shooting de monitoring on l'ajoute à ça donc ce matin nous avons vu trois pilier d'innovation facilité d'utilisation facilité d'boarding AIML et root cause analysis voilà c'était les points essentiels qu'on voulait vous présenter lors de cette keynote on va dé ta est tout dans la journée merci beaucoup

