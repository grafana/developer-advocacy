# ObservabilityCON On the Road Keynote (2024-2025 ) | AI/ML | Easier Observability With LGTM | GenAI

In this keynote, Marc Chipouras (Head of Emerging Products, Grafana Labs) and Manoj Acharya (VP of Engineering, Grafana ...

Published on 2025-03-25T05:44:22Z

URL: https://www.youtube.com/watch?v=2idMOhCvl3I

Transcript: all right well welcome everybody I hope you enjoyed that extra minute of anticipation here there's a there's a lot going on so I just want to say thank you everybody uh for coming out today um this is the first time I actually done one of these here in Palo AO um I'm really excited we do these obson on the road events kind of everywhere we had one earlier this morning in Tokyo um I've done them in Dallas and New York and London London and Berlin but this my first time here um Mark chorus I'm head of emerging products with grafana labs and really excited about some of the work that we going have going on I'm also excited about everybody who is here in the room um we're here to dive into observability and tools but we're really here to talk about um engineering workflows and processes for you to help your um engineering teams be successful and we've got a slew of great Engineers from uh graphon labs and actually customers here to talk today and what I'm most fascinated about is they're not just Engineers building products they are actually Engineers who are on call for those products as well so they're going through the exact same challenges on how to use these observability products that you are and how do you make your engineering cultural better so I encourage you to talk to everybody share your challenges learn from each other we're all going through this together and I guarantee none of us have it right yet um great we have a slido here so if you have any questions go ahead and scan this QR code we're going to keep them and then there'll be an opportunity for Mino and I to answer some of those questions a little bit later today so as I mentioned this is um uh observability con is something we host um every fall that's our Flagship event here where we talk about um our Cloud products and where they're going it's really for focus on our products and customers and we get to bring this to you every single or after that so um we as Tokyo palato San Paulo London we get to go to where our customers are at so that you can have these conversations together and that's what really AB obson on the road is all about we also host another Premier conference called graphicon and that is where we get to focus on our open- source community and this really about projects and users coming together understand how you can use all of Gran's open open source tools to accomplish any different challenge that's actually going to be coming up um Raonic con is coming up in May in Seattle um so that's that's exciting as well but that's not the only way we get to see each other in person we run lots of workshops we run lot of webinars um and you actually have the opportunity if you're grafana customer you can work with your account team and you can actually get a graffa day where we can come in to your company and actually work on site with you in order to help you get better using our tools and understanding your engineering processes moving forward really one of the things that I love about grafana we are all remote company we are remote first but when we get together we're not just getting together as a team we're getting together with our customers and that makes it even better all right who is grafana well we've been doing a lot of growth over the last 10 years since we've been a company we currently can boast that we have 25 million active users users of grafana products that's amazing that's open source and paid together but that's an amazing number as far as the penetration for where graphon is in the community and it's unbelievable because anybody who is an engineer who's who's working in operations they have experience with Graff tools and products we are ubiquitous within the community and that's a great place to be we've been able to transition that open- Source momentum and be able to actually work with over 5,000 customers paying customers actually using our products today right so we don't we want a lot of people to continue using US Open Source but we're looking to work in a cloud um in a paid environment with a lot of customers as well and so we're continuing to grow and that growth is to the tomb of $250 million in Revenue we're actually real company these days not just a little open source side project we're out here um annualizing $250 million Revenue um and that means we have a lot of opportunity to continue to expand our investment in this observability space um and you can see a number of different opportunities that are represented here but one of those things that we're maybe proud about is actually we are we've been recognized as a leader by Gartner um as who's kind of evaluating observability vend vendors out there and how our sweet is Broad enough in order to be considered in that area we're certain proud of that and actually getting ready for the next round of the Gartner review coming up so I do want to talk a little bit about we have a new program here which is a startup program um startups I me we try to have products that kind of can work for everybody whether you're open source whether we using graphon cloud in the free version which has every every feature in graphon cloud is included in the free version with a limited number of usage there um we also of our Enterprise plan we want to be able to hit everybody here one of the areas in the market that we saw that we weren't really helping was with startups right startups have unique problems here where they may they're up and going with their new product and they need to scale up very rapidly um and they need to focus on user product Market fit rather than just their operations and so we announced um late last year a startup program where startups can get $100,000 in credits during their first 12 months of usage here to help them ramp and accelerate and get going with a full observability Suite during that time and after that time we're guaranteed 20 20% off for those customers moving forward and so this is a way that we want to reach out to help the startup community and for us again we're gon Labs we're a global company the startup Community for us is not just V VC back um um VC back startups here in the Bay Area it's actually all startups globally rather you're VC backed or not and we're working with them in order to be able to support that I think last time I looked we had over 200 applications for this program um already which is exciting all right so what are we here to talk about today it's really three things we're talking about how we can make observability easier through our lgtm stack that'll be kind of the first section of the talk after that we're going to bring up uh my friend Mano here he's going to talk a little bit some about the work that we're doing in a IML as well as how we're doing contextualized root cause analysis I guess I can't be doing talk and not say AIML here so I definitely want to bring that into the room while we're doing this all right what then is easier l lgtm what does that actually mean well lgtm stands for our open source projects it's Loki grafo Tempo and mamir those are our open source signal databases it also happens to be logs grafana traces metrics as we're going through here so that may be more relevant for everybody in the audience um I see some salese here so they like to think it means let's get the money um or maybe it looks good to me but these are our our signal-based databases which um have really been focused on Hands-On practitioners they've been using promql and Trace C and logq to get their data out of these databases in order to provide observability insights it's really Hands-On um we're really trying to help this stack appeal to a broader mainstream audience um and make this easier than your Hands-On adopter who needs to know every single line of code in order to be able to make it work and so that's one of our focuses with easier lgtm how can we actually make this appeal to a broader set of audience one of the first things we did is we kind of built an integration strategy um so about three to four years ago we embarked on this idea that we wanted to have default Cloud Integrations soon as you log into graphon cloud in one two clicks you can automatically get insights into your popular open source tools postgress Linux whatever that is yeah in fact the first integration we built was the Linux integration and it still happens to be our most popular integration and integration means that we're here to support the default metrics that are coming out of Linux we provide you a set of dashboards as well as a number of alerts in order to help you understand what's happening with that system and respond to keep it stable and available this is our default ation strategy I think we've gone from zero to I think we have 110 Integrations they're running today and these Integrations are not just maintained by us but we actually get to work with the community with these vendors in order to make sure it's one toone meeting what are the best signals we can be getting from those services so that you know this is what you should be looking at when you're looking at your spark cluster um one of I guess of the popular Integrations here we do have postgress we've got ISO we've got Linux as I mentioned the the docker these are all our most popular Integrations but you're going to notice in this maybe rainbow up here we're actually missing kubernetes it's not listed here and we've had a kubernetes integration for a little while was actually based off of the kuber an open source project called the kuberar mixin which is near to dear to me I actually contribute to it back in the day so that feels good um we've actually transitioned from kubernetes um integration from being just a set of dashboards and alerts to a full-fledged rea application so you can navigate from your pod to your workload directly to the the node and use that and flow between the signals inside of that it uses both your metrics as well as your logs together to give you a full understanding of what's happening with kubernetes and we realize this deeper level this application Level integration is really um what users like yourselves are craving and so with that um I want to go ahead and announce that late last fall we actually released three new fully-fledged application Integrations for cloud um Cloud providers and this gives you the same level observability you have over in the kubernetes app but now for cloud providers you can log into graphon Cloud go ahead and give your Cloud credentials and it will automatically pull everything from cloudwatch or Google pull that in and build it into that set of applications so now you have observability of all your Cloud logs together in one location you did it servicel lessly you're not out there installing agents and making all that happen and you have an interconnected unified experience to na navigate all around those resources we're really excited about this on the next step on how we can make it easier for your teams to get up and going what else are we up to um well we've had some testing products here at grafana for quite some time we've had for maybe six or eight years we've had a synthetic monitoring tester that's been actually running in production for a while um maybe 5 years ago purchased a a company called k6 and they um support the open- source k6 load testing product as well and both of these have been available in the cloud and open source for quite some time well recently we're working to bring these together to help you understand the full Suite of testing that you can do in production so synthetic monitoring is now running um a version of k6 in the cloud so all of the Pops that you were used to be able to test with synthetic monitoring were now running k6 in those um in each one of those pops so you can run tests what does that mean for you as end users well that means you can write a test once you can write it over here um in k6 and use as a functional test directly within your cicd and use that exact same script and run it in cloud and uses a smoke test from around the globe in production so you have this idea that your observability synthetics and your um pre-production testing are coming together and being aligned we're allowing you to write that one test once and deploy it everywhere and that's a big change along that lines we've heard feedback that actually writing list tests can be a little bit um uh writing those tests can be a little bit hard so we've gone ahead and built k6 Studios this is our first desktop application that allows to make it easier for you writing those k6 tests whether you're writing for a load test whether you're writing them for a synthetic test or whether you're writing for a scripted test um it also allows you to record browser sessions which allows you to write browser tests and that gives us the next thing we've been able to do browser tests for k6 quite some time but now you can do these is as synthetics tests as well so we can run browser based synthetics from around the world and understand what is the performance of my application wherever I am big step forward and again we have this really nice ability you can run it in your local open source or in your um in your pre-production environment and you can run in synthetics and tie those things together give you all your web Idols that you need all right where else have we been know I want to talk a little bit about open Telemetry open Telemetry we're all bought in that this is going to be the answer for everybody um it makes uh observability ubiquitous and it hasn't necessarily delivered on all those promises yet yes if you instrument your applications with open Telemetry you can send your data to multiple different vendors however if you are using a vendor specific agentry you can't go ahead and receive that data into an open Telemetry format well we have went in open source um and released a uh the open Telemetry data dog receiver this is inside open Telemetry and the open Telemetry collector and this allows you to send your data dog metrics to your open Telemetry collector whether it's the Open Source One or graphon alloy and then you can send it to whatever vendor you like we might prefer you send it to graphon Cloud but this gives you a way for you to migrate from um data dog over to another vendor this is really helps deliver on ot's promise of no lockin and we're really excited about this Upstream we also have the ability for you to convert graphon or data dog dashboards directly over to graphon Cloud dashboards um through that migration process to help assist you which is exciting all right next I want to step into drill down apps so uh we just renamed we used to have the explore apps but now we have the drill down apps and drill metrics drill down and logs drill down were G late last year these are new ways for you to interact with your login metrics data we've heard again and again that it can be hard for people to know promql and get in and really find the changes that are that are happening there and we wanted to figure out a way to really make your data more accessible and lo and behold the metrics drill down apps provide just this they make it possible for anyone no matter their experience to get curious and look through your data set and find the changes and how what metrics and which uh which labels are impacted in seeing the changes around this this has been really really exciting because we've actually seen it triplet in use uh over the last three months we've seen tripled use in these drill down apps in order to make this data more accessible and all of a sudden we're starting to unlock the data from just your experienced Engineers to everybody on your team so you can understand what's happening with your metrics and your logs uh metrics drill down provides uh we continue to innovate in this area so we now provide better related metrics there we allow you to filter your um drill down metrics by prefix we're also using machine learning in order to Bubble Up the related metrics to an individual one knowing which which metrics are changing in a similar pattern to the one that you're drilling into um with Lo logs drill down we're again improving on that as well so it now automatically visualizes all of the stored fields in your um in your structured Loki metadata that's really nice if you have happen to be using otel because all those structured data allows you to explore as you're going through that and we're work working on um this now supports streaming and you can actually get your logs are coming back and you can explore them as they're streaming and coming back so these the investment that we've made in these metrics and logs drill Downs has really paid off it's paid off to the tune of like hey we want to double down on this beted and right now we have public previews for traces drill down and profiles Dr drill down this provides the exact same experience for you to visually expl get curious and explore your tracing data and your profile data to understand what's changing in your system and moving forward from that it's really the next step on unlocking your data and all these are available in graphon Cloud but they're also available in open source as well um and unlocking your data so together this allows you to basically have three ways to explore your signals that you're sending to grafana you can do code and write prom ql write log ql and I know there's some experts out here in the room who can write the these queries in ways that you can find insights that I didn't even know were possible and we want to support those experts in the room we also have a low code assisted query Builder which allows you to um build your query based on the the metrics and labels that's finding and helps teach you promql and log ql as you go through that process and now we have this query list experience which allows you to get curious and drill down into that data and find insights with your own without knowing any of the query languages it's a nice step forward all right I want to go and step into recorded demo here of what explore traces could mean for your team so let's imagine a scenario I'm an engineer and I've been paged there are ton of Errors occurring on our website and my goal is to figure out what's happening so as you know we break down our red metrics by raid error and duration and we allow you to select one of those here in traces DM so I know errors are occurring so I'm going to hit the errors panel now this updates my view for me and straight away I can see that my Gateway service is in fact experiencing a lot of Errors so I'm going to hit add to filters and now what I want to do is dive in a little bit further okay so I'm going to hit the comparison tab which shows me the difference between my Baseline which is traces without errors to my selection which is traces with errors and I can see straight away that the attributes are ordered by those with the most errors of which name is in fact having a lot of Errors so I'm going to hit inspect and if I scroll down a little bit I can see that purchase is in fact receiving 100% of the errors at the moment so I'm going to add that to my filters as well and what I can do now is hit the error traces tab which shows me a list of those errors from which I can select any I like so I'm going to go with the first one and what it does is it pops out this Nifty side panel drawer which shows me the trace that is erroring and from there I can look through the various spans and I can see straight away that the car service is in fact um experiencing the issue itself now I can do this a little bit quicker if I like uh we have introduced exemplars which is basically a link between metrics that's Trace metrics and the traces themselves so I can see here that I have quite a lot of exemplars so quite a lot of errors in fact and I can hit any one of those that I like which will open up the trace again now let's imagine at the same time I am in fact receiving another page that is the website is running slowly for certain requests so what I do is I hit my duration red metric and from the breakdown I can see straight away that Gateway is in fact experiencing quite a lot of slow requests so what I'll do is I'll add that to my filters and what I can do now again is hit the comparison and the comparison will take tell me which attributes are the slowest essentially which are running the slowest requests so I know it's already in a URL so I'm just going to type in url hit inspect and I can see straight away the profile is in fact experiencing slow requests I'm going to add that to my filters and what I can do now is hit the slow traces Tab and that lists the slowest traces out for me 3.7 seconds is quite slow I'm going to hit that one take a look and I can in fact see that the critical path for this one is the slowest and if I look in a little bit further I can see in fact there is an event where the mutex acquire is taking quite a long amount of time so it would be best for me to sort this out and remove this issue first nice well thank you very much for that Joey and then just what I love about this is it allows people to get curious about their data explore around and actually discover insights that may not actually be related to an Insight but help you understand your system and then communicate about it I'm going to stop and introduce Mano he's a VP of engineering he's going to talk a little bit about AIML and root cause analysis thank you Mark hey everyone great to be here uh I live in Beria it was a short commute for me um so thanks Mark for making all the way from Denver and uh who is the Warriors fan here okay are you all excited about like all the comeback that Warriors is making I'm uh super excited about that and so okay let's Jump Right In so uh we going to talk about AIML so at grafana Labs uh we have been playing with this whole idea of a IML what it could mean for us for a while now obviously you guys are all watching all the new Transformations happening in this industry so today we'll talk about like how what's our approach what's been what we have been doing and where we going with this thing so let's start right away um so the goal of uh like the way we have been thinking about is that ml the machine learning has been around for a while and the it's it's a branch of AI as we all know it so we started a journey a couple of years ago uh to solve this problem where you know you're sending a lot of metrics to the graph Cloud but um you don't need them all all the time quite simply and uh you have labels in those metrics which you may need sometime but not all the time and we internally inside the graph Labs we run our Ops clust we were had the same issue so the team started figuring it out how can we really aggregate away all the labels which are unused by the user now how do we know which are unused so quite simply I mean as a user of the grafana cloud or your promeal system you are writing a lot of dashboards or building a lot of recording rules or you could be using a grafana Integrations which is already enabled a bunch of dashboards and alerts for you so we continuously analyze this uh list of queries and which ones are used most frequently and based on that we will make automatic recommendations on which labels can be aggregated away in your metric and now with the drill down apps that M Mark was talking about we will even analyze your search patterns so as you are drilling down through your metrics in random directions we'll look at okay which metric this user always goes back to so do not aggregate away the labels in that so it's continuously learning in the background through a uh through our machine learning and automatically making recommendations and most recently we added a feature where you can just you can enable the recommendations to be applied automatically you don't even have to go there and if you trust the systems you try it for a while and you trust the system you can have the system automatically apply that for you so that's been working really really wonderful for us you can see the savings that a lot of customers who been using it they've been on our obson uh talks in and probably somebody else start talking today about it but what we are most excited about is based on this learning we took it to the next level for logs the logs we always love right like metrics and logs the two fundamental foundational pillars of observability so we obviously are want those logs to be there all the time but at the same time we always throw those info logs you know what I'm talking about right you know so I mean I love those info logs and know when I'm in deep you know so I need those info logs right you know if this line of code is executing or not but it's almost like an insurance policy I don't need it all the time but I can bring it back when I want to so that's the idea of you know adaptive logs now so a very similar principles uh we literally went GA at opscan New York City last year and it's been on fire you know lot of customers are loving it you know there are almost 200 customers already on it in production saving at least 20 to 40% um this is the savings that we do it inside grafana Cloud but let me quickly explain how this thing works works right so back to the whole info example so I have all those logs coming uh to the graphon cloud and as they're coming in we are using this algorithm called drain you might have heard of it for it's a pretty popular algorithm so drain is helping us figure out all the different patterns in your log lines so we're discovering all the patterns and we are uh you know starting to score them so how do we score them uh the way scoring is happening is essentially just like we do with adaptive metrics where we're looking at user patterns so what kind of dashboards you have built or queries you firing or even drill down logs is another guide for us now to tell us like which log lines you often go back to so then you will start ranking okay you ingested a million lines or a one terabyte of info logs but you queried probably five of those in in whatever in last 15 days period it's a rolling time period we're looking at so you can probably drop them or keep only 1% of it it's will make recommendations do you want to keep 100% or 50% or 100 or just 1% of it but the beauty of that is you can if you are an incident and you want those info logs back with just a click of a button you can start bringing them back so it's it's getting ingested at the time of injection um it's getting dropped because you don't use it but when you need it you can bring it back at a moment's notice um so and you can even actually configure it per team per service so like this service is just going live in production you don't want to do the same rule to apply everywhere the info lock should be there for my low usage service because I just went to production absolutely go for it you can totally do that so you can configure it any way you like and a lot more exciting features coming on that come for the talk we are doing in the afternoon with Travis and uh Chris so they will be diving deeper into this talk um now so we almost uh I mean this is too cool to be true so we want to do this for traces and profiles you know all the signals of for observability so the Adaptive traces and adaptive profiles are basically inspired by the same the story of metrics and logs that we have been working for some time now and um so just last year um around uh September we had tail control uh which is founded by Shawn Porter sha Porter is the founder of senu he has been in the space for for all for his lifelong and Sean started had his new startup called tail control and he joined us at graan labs and we have been working on um what we're calling as adaptive phrases and that's coming out really well you know so and it's uh I mean I'm excited to share that we will have a private preview very soon so if you're interested again um talk to The Experts and then sign up for that but the idea is very simple um I mean traces have a lot more structure to the data so we actually know which are the error traces latency traces so we can have way more S faster and more intelligent sampling then even metrics and logs where you may not quite know which one is important which one is not so an Adaptive profiles is Al obviously also in works again come and talk to us in expert Booth we'll tell you more about it now um continuing on the track you know this whole idea of large language model is hot in many people's head and there are some of us were actually uh training those llms you know because we want to keep run our own llms you know in our in-house uh system systems so or using the big time right you know like we do in gra Labs so we have been working um two projects this is both an open source so you can absolutely participate um and it's it's in GitHub so two projects which is giving us insights into how the people who are training the llms can instrument the Cuda calls with our ebpf agent which is known as baa so baa agent can really it's a evf based agent it can now instrument Cuda calls so you can get data on that and then we also um now have a Integrations for open lit project which is catching up a lot of uh um is very popular right now to instrument like if are using LMS or using Vector DBS then it can use open Telemetry as a instrumentation signal to send the metrics and traces and now we have a grafana dashboard and a grafana alerts in the graph Cloud integration package so you can use both of these to start use start uh looking at yourm data either you're training them or actually using them in production application now okay let's me jump into the next section which is uh about troubleshooting now uh let me before I jump into that I'll tell you a quick story about myself you know so I joined gra Labs about a year and a half ago as part of an acquisition color asserts and uh so me and my team we were um all together in AB Dynamics for many many years before that and we had this big uh I would say uh like big trouble using our own product back in AB Dynamics uh which was like troubleshooting was still hard you had a lot of metrics and logs and traces with us but uh when it comes to correlating signals between infra and app and when I say infra I don't necessarily mean it's running something that I'm running myself I could be running in Cloud watch I mean running AWS or Amazon or Google so um often time the dashboard or the metrics are in different location in a different place in a different uh system altoe and to see them all together was always a challenge for us and only the principal engineers and the distinguished Engineers could do it all the people who have been around and wrote the code right so the goal was to how can we make it easier faster for every new engineer in my team so that was the Genesis of asserts and then when we joined grafana we kind of took it to the next level by um starting bringing together all the different grafana products into uh The asserts Meta model and we'll talk about that uh with the live demo shortly but the way the troubleshooting works today for all of us is that we have 20 many dashboards which are scattered around I mean including in grafana Cloud admittedly where there's a kubernetes app there's a front-end app there's open Telemetry app then there is the metrics and logs are not always labeled when I say label I mean like how do you know which one is the request metrics what's the latency metric so the labels may not be there always so how do you know which one to correlate where um and then the you know each of this uh we have synchronous architecture asynchronous architecture they have common patterns but they're not always uh how do you can you can you visualize them in a uniform way right you know so that was the challenge that we're trying to solve and the way we went about it is that you know so as you're ingesting the data into graan Cloud what we'll do is we will apply machine learning and learn about which are the different kind of signals we coming in and start labeling them so that this labeling will help us build what we're calling as a knowledge craft that will automatically stitch together your infra components and app components and build a graph database out of it and then after we and then we'll start running all the alerting rules on top of it you don't have to write them we have written that all that for you so when we will then we'll automatically figure out your anomalies your saturations your failures and your deployments and bring it all together into what we're calling as this workbench now uh it's going to be interesting where I want to next five minutes I'm going to watch myself a recording of me talking at New York city so I'm going to play the video okay so I hope I sound the same okay okay so let's get started now we know about symptom based alerts we all know about it um I mean we call them slos but um how do you make slos easy you know I go and talk to engineering leaders you know I don't know like I mean how do you even create SLO how do I know I should be creating SLO on this or not so the first thing we did is improve the wholeo experience in gra Cloud let's say I'm running a web app I have a frontend service and I pick up the service name I said Okay I want to create a solo for this you know I just a new guy I know there's a front-end app there I'll pick the app name and I'll create SLO for that right so now I've already done that here so if I go back to my SLO screen here now what's happened is like once you create SL SLO uh the beauty of what we did is that we are as the Telemetry is getting ingested we automatically tagging this metrics the system knows that know what's a request metric what's the error metric what's the duration metric uh what the CPU and disk metrics it's adding the add tagging those metrics as it is coming to the graph Cloud so it's automatic you don't have to do the work uh I mean if you already have a custom metrics just bring it on right we'll show you how to do that yourself um but that in this case the front end data coming from our phoh agent is already labeled so if you're using open source phoh agent send it on and we will label it and have it avilable to you so I have this uh SLO created pretty simple right you know uh R total request total look at the ratio and tell me if something wents wrong I mean it cannot be easier than this so now I have an alert that fired um and I'm kind of simulating some errors here it fired yesterday while I was in New York City and has a nice little link here calls you know take me to the RC workbench right so like I just click on it um now what happened here is that every time you create an SLO or an alert um it'll automatically link you back it look at the service label or the job label and automatically Al take you to the connected services so it's kind of scanning the system and quickly figured out okay the front end app is connected to all the services and I'm going to pull all the things and show you all the potential causes you know the troubleshooting Gates and in this case you know we call them assertions or checks um so there is a quick graph here if you want to get curious and want to take a look at this thing and quickly understand what part of the architecture is in trouble and here I have this thing called front end proxy that is sending all the requests to front end service and it's it's uh looks like it's ranked to the very top here so it's like you know highest score you know we have scoring this based on what you call as assertion score they get time and space analysis um so it's it's pulled to the very top so that's interesting now I want really curious okay this alert fire where my end users affected you know like and we always care for like Tom talk synthetic um I mean I love synthetic it's cool but there's real fun in real user monitoring right you know like synthetic will not catch real user monitoring so I'm going to ask the system hey dude um can you tell me if any users were affected so I'm going to click on this button called find me problematic connections so every time you ask this question to asserts what it does it again walks the graph right it will walk the graph and pull in all the relevant information so in this case um it is now pulled in the front- end client at the very top like rank to the very top and like um and I'm going to quickly launch the look at the summary view here well looks like all the different endpoints uh the product endpoint the card endpoint are having massive amount of hers so um when I and I can quickly jump into the front end observability right so we have a fully react app that is built for front-end data only right so grafana already has for kubernetes for applic obility for open Telemetry for your browser data everything is kind of built in um but now it is taking you to that part of the app and quickly you can start browsing and launch fronted observability and get into more details error logs and error sessions and everything else uh I will not do that now uh let's come back to the app right so okay this is all based on the score but what if I want to know like what order the sequence of things happened so I'm going to quickly start by time right so time and space the two Dimensions our brain is trying to weave this information and transcribe into uh a root cause analysis right so here um so when I switch to time I can see there's a feature flag service that was triggered on so somebody decided to turn a fature flag like you know we are modern um development continuously releasing features and turning them on in production right you know so um so when the feature was turned on right then there the frontend CL having a lot of errors and this catalog service seems to be the biggest trouble maker so if I take a quick look here it's having part crash looping and application errors so I want to jump into like the relevant again dashboards right so I want to look at my kubernetes monitoring data I want to look at my open Telemetry data all the data application avability kubernetes monitoring everything is already part of grafana cloud it's already there so we have weaved this intelligence into all all the graan cloud products it was like Avengers Assemble and we built it he thank you thank you for watching me so yeah so that's been a fun journey and we launched it at uh the New York opscan last year and uh it's been on pretty F I mean like Black Rock was there with us in stage they were one of our design partners and it's the world's largest asset management company and they have been using it in production at large scale and uh we have a lot 100 plus more customers now already running using asserts uh for the production traffic so very excited about that um and it's available as to all the grafana cloud Advanced customer so if you're already in gra Cloud it's a cloud only product it's not avable OSS so you can absolutely enable this feature on your data um pretty easy just to Quick click of a button now what I'm most excited about is to talk about the the next evolution of our journey here right so we all love our uh language models so what happened is last year it was interesting right and we have been playing with this large language models for a while so we started we had the knowledge craft that I was just talking about and we have been feeding it more and more data like we just talked about KU zap o the front and O data and now we are even starting to play with uh service catalog data like from backstage and for other places so the the knowledge graph is getting enriched with more and more data and more and more Integrations in the grafana cloud world and now the assertions are literally the signals that are constantly getting gathered so what if we could feed this graph data into an llm and see what it comes out and that's what we I'm most excited about this is still in research still in worked so what I'm going to share next is the screenshot of what we have been use starting to use it in our own internal Ops cluster and what it is producing so the idea being that you know the workbench that I was showing you before can get pretty busy for large complex apps you know we run MIM which is a very very complex system with lots of Kafka qes and multiple microservices you know it gets really complex very quickly so we have a lot of assertions and the bet you know what if we could have an llm you know help us you know literally look at the data and then build hypothesis out of that right and we can quickly say oh yeah I have I know this problem I know what to do with it right anyway it's early year early days so stay tuned we will be announcing it as we make progress with this thing but I'm super excited about all the assisted features that we can bring in with the large language models because this language models they love text you give them good text they come out with really good summarized text okay that's what I've learned definitely so that's working really well for us so thank you and uh with that I would like to bring invite mark back to walk take us home thanks [Applause] CH yeah so that was a lot we just covered here's kind of a little bit of an overview we're talking about making lgtm easier for all of your companies and make it easy for your entire organization to get going very quickly we're talking to how I bring in AIML into all of your signals so that you can use them more cost effectively and make them easier to use and then finally we're talking about how we're using the assert Knowledge Graph in order to understand what's been happening whether it's your infrastructure in kubernetes or what's your whe your applications in otel moving forward and this is a huge place that we're investing there are so many great talks today um they are going to Deep dive into a number of these um and moving forward from there so I highly recommend that you uh that you get engaged with everybody today

