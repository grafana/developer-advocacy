# Introducing Advanced Container and Pod Monitoring for Kubernetes in Grafana Cloud | Grafana

Kubernetes monitoring now offers detailed views of containers, pods, workloads, and namespaces, complete with CPU and ...

Published on 2024-01-23T19:15:13Z

URL: https://www.youtube.com/watch?v=cFaRYc-ZY08

Transcript: Hello everybody welcome to the new kubernetes monitoring release our latest update introduces detailed kubernetes monitoring views for improved resource management and cost efficiency key features include in-depth insights into namespace P workload and container performance historical data analysis for strategic planning cost tracking and optimization guidance benefits for our customers include pinpointing performance issues Origins identifying key cost drivers and saving opportunities utilizing best practices for requests and limits 360 drill down capability extending to The Container level the upcoming releases will include the cluster and no detailed views together with a entirely revamped alerting experience so now let's dig in starting from this landing page for kubernetes monitoring quickly we cck on cluster navigation where we see all the components then workload because this is easiest to start with give it a little second or two and now I know that this particular workload gives you quite nice Graphics to show and here we go now on top you'll be able to see the more static component as radi replicas pods which cluster and namespace it belongs to below it these are the time series for the CPU allocation in green the orange dotted line for the CPU request and the blue line that that represents the actual usage on the right you see one more line which is right and dotted and this is the limits which are set for memory only in this particular workload going down you will see how we promote setting up requesting limits here and here additionally we see we provide it with cost attribution CPU allocation memory allocation and total price that the customer pays for this workload on the right you you'll be able to see the idle cost for CPU memory and total idle cost that the customer will eventually be able to save we can click on a pod and see more or less the same view on a pod level here lies the container view which provides us a 360 drill down capability throughout all of your Fleet which is fantastic and something that we didn't have previously because we were drilling down only to pod now the container level is a little bit more sophisticated here we provide recommendations for sizing meaning CPU request sizing CPU request uh CPU limit sizing as well memory sizing for limits and sizing for requests I'll provide you one example here we see that the current allocation is 12 GB for the requests we're using around 8.6 free of them and the recommendation is that you can uh just downsize it to 3.3 gabt we again see the cost allocation and idle cost allocation going further down if there was CPU throttling some uh restarts or uh terminations you'll be able to see them here for this particular uh container there were no such things so no data is shown no logs and no events either now for the last minute I just want to show you one additional play where you'll be able to see a crash looping pod so let's start you go from here you identify a PO that it is Crash looping you check out the b optimization view where it is constantly bursting for both CPU and memory the scrash looping when you go to uh dig further you'll be able to see all of the containers and see that the CPU requests are far too low and that determination reason is O killed exactly because of these really low set limits and request and finally our recommendation is to resize the CPU request to a far greater number and for memory again for to a far greater number and get this Crush looping part issue resolved that was all for more information # k8- monitoring please uh leave us question questions and feedback thank you

