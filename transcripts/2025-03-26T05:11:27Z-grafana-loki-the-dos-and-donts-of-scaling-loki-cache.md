# Grafana Loki: The do&#39;s and don&#39;ts of scaling Loki cache

In this Loki community call, Poyzan (Staff Engineer on the Loki team) returns this time with Paul Rogers (Staff Engineer on the Loki ...

Published on 2025-03-26T05:11:27Z

URL: https://www.youtube.com/watch?v=3u8UxLfmq6I

Transcript: hi everyone and welcome back to another Loki community call We have a full house today We've got five people I am Nicole Vanderhuven and as always I've got my awesome co-orker here My name is Jay Clifford I've remembered my name once again this time Uh and I'm joined by the lovely folks of the Loki engineering team So we've got Poison Paul and Julie There we go Reverse Okay The pointing thing is always a little dodgy That one is is Poison Tanelli And over there is someone that we actually just roped in last minute So we're lucky that he trusted us enough to come and let us grill him Paul Rogers Thank you so much for coming Glad to be here And also we've got as always we've got Julie over there on that side She is the Loki technical writer So pretty much like everything that's on the Loki docs um site she's responsible for So thank you to Julie for letting us I mean I'm I'm on there all the time So thank you for for maintaining those A lot of docs So that's why I show up at these Yes and she gets to ask all the questions that she needs to update the docs So we're like "Yes please come." But today we're going to be talking all about the Loki cache the different types of caches that there are and then also how to scale them We've been talking a lot about how to scale Loki in general on Kubernetes just did one with Poison and during that Loki community call we were like hey what's this whole memcache thing and where does that fit in and she decided that there was so much to talk about on that that it deserved it's it's a separate community call all on its own So in this community call we're going to be taking some questions some that we've we kind of got in advance but if you have any questions particularly on memcache and scaling cash and you can put them in the YouTube comments in the live chat we will try to get to them We will be prioritizing relevant questions So if you have like more general Loki stuff we maybe we'll get to them at the end but we will go through the cash stuff first And before we dive into stuff um we actually are going to be going to CubeCon Jay and I are both speaking at CubeCon That's next week And if you if anybody is going to be there come to both of our talks Jay you want to do a quick plug on your talk basically we'll be playing a video game on stage which I'm quite excited for teaching the concepts of observability So metrics logs and traces all through a textbased adventure So um I'm quite pleased I get paid to you know uh play a game on stage Well I wasn't going to say it but yeah Nicole isn't isn't yours think about AI what's what what's your Yeah So so mine is called Azimov zeroth law of robotics It's observability for AI Uh the whole premise is that you know as Isaac Azimov has these three rules for robotics about what they need to comply with so that they don't take over the world But the law zero that I'm proposing is that a robot must be observable So how do we do that come to the talk to find out And with that let's get started Paul why don't you introduce yourself actually because Poison and and Julia have introduced themselves before Who are you what do you do at Graphana and how is it that you said yes to come on today uh hi everybody My name is Paul Um I've been at Graphana for uh two years I think Uh it might be this week actually was two years Um so uh I' I've been on the Loki team for the entirety of my time and uh I've been involved with uh a lot of the infrastructure over the last year trying to make sure it's scaled appropriately and to work on making sure that everything's uh running as smoothly as it can So I guess like fundamentally then Paul I feel like if we're going to sort of crack into the the topic here um for people that don't know what exactly is cache and and you know why why does Loki need cash um and why do we why do we use mem cacheed and what exactly is that sure Uh so cache is a concept that is uh it's ubiquitous in computing in general It's usually a a software or hardware designed to speed up certain operations Um and in this case we're dealing with software Um and MEM stand is short for memory So it's a way of uh quickly getting to information that you might need to get to very often Um for the the simplest case is if I run a query in Loki and I say you know I want these set of logs and then you run the exact same query Well you don't want to have to go back out to object storage and fetch all the data and all that because you just did it and if we cache it it's there It's fresh and it's quickly retrievable at a uh generally at a low cost Um so the technology that Lucky is utilizing um under the covers is a piece of software called Memcache It's an open- source project and it's uh very scalable It's a sort it's a key value pairing sort of a operation and it's uh it's a wonderful piece of software and we've utilized it for various parts of Loki so that we can do a query or whatever we need to do get our data and then put the information into the cache so that if we need it again in a short period of time it's there for our usage and in in terms of architecture memcache is its own uh container its pod when we deploy Loki it's not part not part of another service um within Loki that is correct and we often um will have more than one pod so that it's you we have you know some redundancy and whatnot so uh we don't have to have this massive pod we can have many of them um size appropriately and the data is shared between them essentially nice um so like sort of moving on there from you sort of touched on it a little bit Um uh sort of what are the telltale signs that you kind of need cash what's the what's the indicator what what do we look for to realize that we need this within our solution it's a great question and it's something that we're constantly monitoring and whatnot Um it if you are working and then you're looking at uh your data and you say my goodness we're going to object storage a lot our bill is increasing um or boy it's taking a really long time to get my query results those are all signs of boy maybe we need another bit of architecture in there and in this case it would be memcache uh it's a pluggable component in there that it will it should cut down on your costs for various object storage calls uh I mean we always have to go to the object storage you know the first time to get the data but subsequent calls if it's in the appropriate time frame we shouldn't have to go fetch that data which so we we save on cost there and then if we don't have to go to you know whether you know your S3 bucket for example uh things should go faster as well because it's basically in-house it saves all that back and forth between us and the AWS servers so you're saying um the if you start to see that there's a uh the performance slowdown basically high latency when when you're trying to retrieve um the results from from the storage uh that's when you should start to consider cache but we we have a question here from Jean Kristoff doshi who says could you elaborate on the different types of cache we can use in Loki with memcache chunk cache etc especially the right cache Yeah absolutely And that that was a topic that we are definitely planning on touching on but we'll just jump onto it right now Um the the the biggest uh cache that we have is the chunk cache Um and it's it's the the bulk of the data that you're fetching from object storage uh as whatever you've written to Loki Um that it's contained in under the covers what we call chunks uh and they they might be relevant for one query and not another Uh for instance we're going to write some Loki logs You know the first line might be for user A the second line might be for user B The same chunk has both but it may not be used in one query versus another but it's still from a time frame and when it's being used That would be an example of an item in the chunk cache and we we can leverage it for more than one query Um we do have caches for um our our queries that um do things like labels What what are the common labels that are used in a Loki instance we don't want to have to go fetch that all the time If we can we can cache some of that kind of stuff uh various metrics that we can uh create th those can be ha um done with a hash Um it's it's really uh it's pretty flexible Uh we have you know just we tried to separate it out but the big one is the uh the chunk cache So when you're talking about labels uh is that what we refer to in the docs as the index rights and lookups i believe so Um we are we are in the process of mapping all this out Um poison and I are new to extrapolating what's going on under the covers um to what is presented in our Helm charts and our documentation We're still putting all that together But yes that's that seems absolutely correct Okay so you said chunk Oh sorry Go go go ahead I me jumping in there like like Paul said we are we are mapping out because complex and things go out of date And um in the previous diagram you would see like um Paul described chunks is the massive uh bits which is where the data is But this index is is needs to be removed because this this refers to the bulk DB index which actually use the cache But since we move to the STB store see TSB store does not index its results What it does is in in the gateways it it uh when they start up and um they download the existing files and they keep updating it as the compactor um uploads new indexes So their memory usage itself like serves as a constant cache it's the data is always there and constantly update it from the storage Um so when if you're not using bolt DB you don't need what's in the values chart or in the JSONet which is called like index labels cache as type and the results cache is confusingly enough and we apologize this is the lucky style organically growing you will see in the JSONet as memach front end but you will see in the helm charts as um memcache results cache and um yeah Paul already mentioned but the results cache is is is just storing results and also um the information that a a result is not in the cache too So go and compute it is retrieved as an information from the cache as well Um their sizes are in line with with the drawing here Result cash cache don't store big chunks of data So they're quite small Um yeah we will be updating and I I promise when Julie is here we will be updating our docs and diagrams uh very soon We have another sprint doc sprint coming and I take responsibility to do that So sorry I think I got confused there What was the thing that you said you don't need to use if if you're using tsdb index index Yeah And and the name in JSONet is mammcache index uh queries Uh and then yeah I think it's the same in the helm chart as well Uh maybe it's even removed in the helm chart Maybe it's not even there now Um so I so to bubble us up back a bit to sort of summarize and getting so we can sort of track these So kind of what we're chatting about is we have free free apart if we exclude index cache we're saying that's gone if you're not using bolt db Um we have results we have chunks and we also have um do we do we still have sort of front-end cache basically metrics based queries like volume Confusingly enough confusingly enough results cache is the man cache front end So they are the same thing So we have two types of cache One for the chunks the data itself one for the results Uh got that's it We just call it two different things The results cache are called mammach front end or mamm cache results cache And then so the so the ro so if we bullet point then the results there So in the results cache we have things like like log volume Um we have what what are other things that we get in results cache uh it supports three endpoints the metrics queries the label queries and the volume queries They don't necessarily um store the resultant log lines because the log lines themselves are actually the chunks Uh so these are only for qu like uh aggregated query results in that in that sense Yeah Okay So Andre had just asked Andre is is a champion too Andre Zivani does the results cache uh cache only log lines or can it also cache metric results So I think you just answered that and it does Yeah Yeah Okay Okay Wow We just started This is why we needed this We just started and it was already confusing like break everyone in and we just went straight into the deep end like 2 meters deep but we'll get there Um I guess sort of like the to sort of jump back up to the the topic of why we need cache really quickly and then we can sort of get back down to the architecture and taring is we we touched on it again and Paul mentioned is what's kind of like the mo the queries that benefit most from caching Is it you know what what we looking at here is it like the the same data over and over is it only log queries is it metrics queries um what benefits from spec specifically from Loki caching i'm going to say that in general it the answer is always it depends but it depends what what how a user a customer whomever is using Loki But the intent is data that you are accessing very often should be in the cache when it's all said and done So it's it's designed to uh lower latency lower object storage API costs that also has the uh benefit of lowering uh bandwidth uh egress out out to your object storage provider uh any kind of throughput issues you might have there So but it's really anything you are using a lot or frequently should generally be in the cache So and and when we say using frequently I assume we're talking about dashboards things that you're monitoring in Grafana Yep And and if you're querying data you know I would say we tend to see certain query patterns that generally say it's recent data but realistically the cache should move to whatever is used the most Okay And I guess like when what you're talking about dashboards a lot of these I mean we want them to be as in real time as much as possible So um it would you be able to do to cache like everything basically would you be able to do a timebased thing so that you cache everything that is older because that's not likely that's not going to be changing that one you can just retrieve as is but also still be fetching the new ones So cash is it's a tricky item because ideally yes you want to be able to cash everything You want to be able to have it right there for your instant usage It's a trade-off You know we could cash a year's worth of data but that becomes very prohibitively expensive So it's a tradeoff on what are we using a lot versus you know if I have to go fetch this piece of data from a month ago and I only do it once a week maybe that sort of cost is acceptable and there's a balancing act that has to be done and each user knows best what uh works for them or that's that's the goal here Uh generally it's you know you want the last week's worth of data give or take because that's recent stuff That's most likely what you're querying in terms of Loki for logs You're saying what just happened what happened last week and compare them Uh you you you have the ability to look up something from a month ago but I would say that's often not as common Also Nicole let's not forget just because the data is not in cache that doesn't mean it's not served Loki queries will always be served with the latest data So what happens let's let's kind of come down what happens when a query hits right the query hits and then what we do first is um we're going to come down to this later but we we check if it's within the cache results we have a hand of time and then it will first look at the chunks cache Do I have this data in there and memcache naturally so let's dive deep into how do we find an item in in cache So Paul already said me cache is a key value um store So our keys are chunk refs So querers come and they have a list of chunk refs to find somewhere The first place they look is the quickest they can retrieve which is the chunk Wow even more caveat If it's less than 3 hours if it's recent data they know they it's not even storage yet probably that So they first ask the ingesters and then we look at the cache and then cache returns hey here are the items that I find for you You can you can retrieve the data the value itself and then it goes here are the items are missed which I don't have them Then the same fetcher logic goes in and query storage So what we reduce is is that storage percentage as much as possible But the the Loki as a as a software should always serve the correct data That's what it designed for So it doesn't really matter What we try to save here is like more um the cream on top so to speak if that helps So I guess sort of to to sort of finish off as well the the architecture of cash is when we focus a lot on like the chunk cache um and then this this idea of like I see in the Loki helm there's this idea of tiering so can the can the chunk cache be tiered can there be tier one and tier two and what what's the role of uh tiering in cash I'm not sure I follow the terminology in that So essentially I think it was a a user had basically created let me see if I can find it It's like between like L1 and L2 cache Um okay then let's dive deep into how we further complicate our trunk cache to make the best out of it The architecture Yeah Okay L1 and L2 is what you mean by tiering Sorry because the the terminology didn't one match Oh sorry Sorry Well that's that's why we're confused too like what so what is taring in in this context why why does it have to be tiered at all so I um I I see some questions in the chat about how to tune it So let's dive into how we run our cache at Graphana for Loki and touch up on taring but then let's come back on uh how like how we monitor it So what happened is is as Graphana grows as as you know at Graphana Loki handles in the order of pabytes of data uh a month and um the it is now like it about two years ago it became prohibitively expensive to hold as much as possible data in memory just in just in memory And then there was also one more um kind of yellow flag that was presenting itself We were pushing the bandwidth limit of uh cloud providers because we were asking for too much data at a time from storage layers because we weren't we didn't have it in the network So we had to always constantly go to storage Um so our lovely colleague uh Danny Coping as we uh um mentioned them in the last call came up with this uh idea of an extend like it's an extension is an again open source supported extension on memcache called memcache x store So memcache is an inmemory design but memcache x store attaches SSD discs to whatever container that runs the memcache and then by design the key key mapping is still in memory and memcache works as it does So it's it gets all the data in memory but then flushes to the disk So we increasingly like we exponentially increase the capacity of our cache So what we use is we we started rolling out that in GCP Um and I I see some questions about particularly uh about node types Uh it depends availability depends on the region but all both AWS and GCP um in most regions provide uh standard nodes and like um that support SSD attachments So we we generally choose those nodes What we try to optimize is a fairly generous CPU which is like generally around eight cores but a little bit higher on the memory uh at least 16 or higher Um and then we started using this and this is we call it L1 cache Now we have this huge storage in the order of terabytes of data that we can hold with a number of nodes um relatively few around like 30 to 50 let's say um and then we further came up uh Ed Edel came up with a further optimization on top so what he realized how does how does cache work right so we briefly explained a query hits we look at the chunks cache and then we say here are the hits you have return data from cache and here's the list of misses you have so what we do is now oh we need to update our cache uh so we serve the query getting those chunks from storage and then when we get those chunks from storage we also say hey write back to the cache because when they are asked again now you have this enhanced data and like larger period of time Um and what happens so this is coming into a like a failure scenario and if I'm talking too much do cut me off please But what happens when you try to write look so you provision let's say about 5 days worth of data and you have this user that constantly queries six days of data slightly longer than your periods So what does it what does this do to your cache is you'll get most of like 90% of the data from your cache but that 10% constantly tells your cache to renew itself and tries to rewrite which it comes back as like high compute unnecessary rights and a performance bottleneck for the cache itself So we introduce another memory inmemory cache a small one called L2 which is a spillover logic So we have the majority of data on disk on backed by exor and then we determine a handoff period about like couple more days more um and then we we hold as much as data in memory for that uh and then when the query hits we look at the handoff time so it says we first check if you're within the handoff time of L1 check L1 if not check L2 um and the spill over if there's there's this like extra day that constantly needs to be written then we we protect L1 from constant writebacks um because it serves all data that is asked and then anything else comes from L2 or storage Does that help it's it's fairly complicated to follow but uh that is the taring that we introduced Yeah No that's that's really good Um and we we also definitely want to get into scaling questions in in a bit as well but maybe we could maybe we could step back a little bit and then talk a a bit more about the different types of cash and what each of them stores just so we all are on the same page about the terminology Yeah Uh let me take it from the top So what like we we already talked about the two right the front mammcache front end or in other words result cache um we don't do much tuning on it It does its job It's it's fairly small We run a few replicas of it and then yeah uh for for repeated like um volumetric and label queries it it stores a result and that's it But for chunks uh now we talked about two different types Loki by default comes with memcache chunks cache you can enable it and it will provision when you increase replicas it will provision simple in-memory mem cache instances uh there is another type that we can do and we run internally that is the the same mem cache backed by X store that is supported like that supports the SSD discs So we still talk about a single type of cache but two different modes of running it and um and then to enhance the second mode of extor running version we also introduce a tearing alto So I want to take a moment here and and say when is this relevant I think this is relevant if you are dealing with at least half a pabyte of data a month we still have like uh a number of clusters that we don't need x store I mean it's even complicated to verbally explain right like we talk about this version and and an add-on and an add-on on top So it's actually quite hard to maintain as the natural organic query patterns change It's hard to maintain that handoff time we're we're trying to automize it like um as much as possible but these are all added complications in your um complexity in your system So I think when you're running production clusters when the storage costs become noticeably prohibitive uh then a solution like XTOR is relevant Cash is always helpful Um it should be started this is our message always right come come back to fundamentals and the simplest start with a few instances There was there's a question about that basically says uh well let's let's um go through the let's pull back a little bit and talk about the different types of cache first before we dig deeper into scaling just so we we get some of these other questions Um for example we have a question on chunks cache as well from Andre Zeani Uh let me just find that Um can you talk a bit about DDUP i believe that Junks cache is used for that What is a good expected ratio paul do you have any thoughts on that oh that's an interesting one That's an interesting way of looking at it Do Andre can you confirm if we understand it correctly because the so Loki creates redundancy because we have zone awareness and then we create duplication on storage layers but and if if there's duplication on storage layer and if queries pull that data they have to ddup the queries but if we get it from cache we get one copy of it Is that correct maybe we wait for the answer because Paul is that your understanding as well because I wouldn't necessarily link the duplication with immediately Okay it's a good question Um I mean I'll be honest I I mean I've been looking at the memcache stuff for a couple of weeks now I I think um but is Oh duplication on the right path um this would not be involved This is really more on the query side of things Uh we don't write things into the cache until they are actually queried uh as it's currently architected So the right path just puts things in as is There is some amount of duplication that is done Uh some some chunks are duplicated within low uh the storage We do our best to minimize that and we have efforts ongoing to lessen that But um when we go and do the query uh that's when things are actually written into the cache and for that metric Andre um like duplication happens when injector zones go out go out of sync So if like if one of them flashes often if if they scale down or up So if they're running happily um duplic like flush rates should be in sync and that's when we do the best dduplication but there's no particular intervention that we do in the existing um right path Uh and what I'm thinking is that the chunk refs probably are different I'm not sure about that So on two different ingesters if chunks are up are different and if there are two copies of the same chunk on storage you will have two copies of them in the cache too I need to really look at the code path how that works Um yeah but it wouldn't help with the existing duplication All all you can do is like keeping injustice happy and instinct as much as possible So I kind of want to just to I we've we've sort of like we've we've talked a bit about the chunk cache talked about the um the result cache Um and we've sort of dabbled in the the taring or sorry I refer to it as a tearing but the spillover cache Um what I think it would be really good to like get to is when we start sort of dabbling in the scaling side of memcache now is we I think poison you touched on it when you were talking about the different sort of spillovers You said roundabout in Grafana cloud for Loki we keep a 7 day worth of cash about the about the seven seven days worth and I wondered if you could uh talk us through the decisions that you arrive to to get to that and I think this will sort of help our community work out how to size their cache what's sort of the best practices to look at when you kind of visit how big your mem cache should need to be for your your own lowkey solution um the way we come to 7day um is basically we look at the query behavior of of our users and we we look at two things If if the ingestion pattern so if the amount of chunks that is on storage for that cell has changed for that cluster If it's increasing because one day vert of data now means more data we have to monitor that and then what is the average um query period that these like majority of the customers do and what we notice is and this is a very rough heristic that we try to now look back in and further verify is about like 7 50 to 70% of Um let me rephrase it Um generally keeping seven days of data is is good because most most customers a percentage of like a high percentage of it depending on the cell will hit that much data But there are such cells this volume is like insanely expensive for us There are such clusters for us that are so big Seven days of data is like quite a generous amount of data So then then we try to like tune it a little bit It's like then we ask another question So how much how much IOPS how much how many access to storage layer S3 layer that we save by provisioning cache and then we come up with a heristic it's like if we kind of try to save 70% of the IOPS that we do to storage if we have no cash then the cost of the cash offsets itself so what we save from not accessing um storage kind of pays is for our cost of cash and then that's what we try to optimize but that's um that's very hard to keep on top of So we try to now simplify that heristic by creating a recording rule on what exactly the amounts that we fetch from cash and then try to optimize around it and that's the work that Paul and I have been like diving deep lately Uh does that help yeah So essentially what we're saying here is for for people trying to work out how to size their cache is they should look at how much data that they're bringing in how what's their regular query workload to say if they're looking at constantly seven days back or six days back and they should be accommodating their Loki cache size to meet that requirement Um and then we can actually go through a like a numbered example if that helps So let's say yeah let's say we're whole like uh we have about a terabyte of data a month in in our lucky cluster right that makes roughly 30 gigabytes of data a day and then now we um the the storage and I'm assuming this is a setup that is connect to an object store like a cloud provider this is not on file or anything we are a little bit bigger for that um And then um we know the cost of storage for our site but the cloud provider um kind of says that and we can calculate and then we also know the cost of spinning up a pod with a certain uh CPU and RAM Um and then now we are dealing about 30 gigabytes of data and we often query we have a dashboard we always look for that day So if we provision five replicas of inmemory mamm cache that has about 10 gigs of RAM um that should more or less it's 50 gigabytes of data we should we should be able to cover more than a day and a half right and that's generally how I would start So I would look at how much data I have and then how much data I want to retrieve back frequently and that's that's the starting point and it's always further it's always possible to further complicate it but then let's provision that what should we monitor for the health of our cache right we should see a reduction in the storage access we should monitor how much we go to storage and there should be significant drop if we if we tuned it correctly we should look at the read path latencies and make sure that um reading or writing to cache does not introduce added latency uh to our pipeline and there and then further monitoring the mem cache metrics uh helps like can we write enough efficiently can we monitor the bandwidth of the nodes are we abusing something in the network that like slows us down then then we can further dive deep into diagnosing that Um and this suggestion assumes that there's no further tuning happened on the Loki So you use the Loki defaults about 1.5 megabyte size chunks that where memcache comes with two megabytes of um what's called max item size which is can be imagined as like a single box that memcache uses to put data values in So those are by default in sync But let's say if you played around with your Loki chunk size and if you increase that and then you didn't change anything on your mamm cache configuration you may notice a discrepancy where memcache doesn't work and then that comes down to going back to bases and like following what how you configured your loy but by default the three three signs is like how much data I have how much data I need back and what does my storage access look like and I think uh one other uh easily overlooked item is the fact that once you've set up the cache and you think you've tuned it properly you need to wait a little bit before you evaluate it because the cache is empty to start and it has to fill up and do its thing And then after the cache is running at more or less what we'll call a steady state uh then you can start looking at how well it's performing Um and I have run into this as we've been tuning the cache We have to wait you know four five six seven days before before we can actually look at the statistics from it Oh that's put terabytes of data in disk It's like is that super interesting So you you have to leave it a constantly running production time get those metrics in and then make basically you revisit that evaluation and see if what your hypothesis on like the scale is is right It's frustrating as a as a developer It's like I have to wait to get my results and that's not why I did computer science but that's it's the way it works Well this this ties into I mean we're already sort of answering it but I thought maybe we could um we could tackle this A question from Matt Vetas who asked earlier what are the key metrics to look at to know if a if the cache is correctly tuned and it looks like this is the approach that you're talking about where it's not something that you can calculate exactly beforehand You can calc you can start with like a rule of thumb but then there is an element of of looking at the metrics afterwards and then kind of like course correcting on the fly Um you mentioned a few things here You said IOPS the bandwidth usage the computation cost latencies Um is there anything else that you would add to that for the key metrics um sorry go ahead Um the uh the memcache software itself um is a fantastic piece of software and it has statistics that you can query directly So you can telnet into a memcache pod and run a command called stats and it prints out all kinds of information Um and it it talks about hit rate It talks about um eviction how how fast something is removed from the cache It it talks about um how often the cache is compacted to make sure it's appropriately shaped and um lined up correctly internally Uh so you can use that in conjunction with the outside metrics like looking at your object storage and your query latency and things like that So you there's all kinds of metrics that you can look at tune a cache correctly And I would add like memcache is designed to maximize all the resources that it has So a correctly tuned memcache should have about like over 90% fill rate and then it should have over 90% hit rate And when you have I mean that's at least what we aim And when you have like um abnormal query pattern that forces it to evict too much and write back too much there it's normal to have temporary drops in that but overall like close to 90% of utilization is is what we aim that's why mammcache has um so when you provision mammach in a pod the you provision a pod usually like you you set your CPU request request and you set your memory request but there's an internal memached um memory limit that you should aim to set around like 90% utilization because if not if it's like too much or too low memcache would limit its own memory utilization to that So a correctly tune mesh should never because the the software's memory utilization should be around 90% of the pods memory request So that it's like nicely utilizes um the max possible Um if that helps and these are can like these can be find in memcache open source docs as well Uh how to make best out of it Um that's why we kind of like to use it It's such a like proven software that is like easy to aboard Uh I love it honestly Yeah Okay We we also got a question about X Thor in particular from Lucas Yanushitis I think um Lavas and and atu for your question hello really enjoy this community calls kudos thank you when using memcached x store my god that's these things are hard to pronounce what is the recommendation when to scale chunk cache pods vertically and horizontally and when to scale the PV size Um so that's a good call They they don't actually have uh persistent volumes attached They they literally have disks attached Um so that's one thing to clarify Uh that's why you need to choose and provision a particular instance type based on your chosen cloud provider that supports that Um so that's that's one thing Uh I I think it's a great question is um I love it Like Paul said it depends Um we prefer to run our cache nodes on dedicated node pools So we have absolute control of our instances and which I assume will be the case for like most of the listeners here And um further than that we aim to maximize the utilization of those nodes So if what we did so far we can tell from experience is like we experimented a lot with different types of nodes that we looked at their Danny did most of this work uh he looked at it the bandwidth that they come with uh number of discach and the capacity and their their RAM and memory and we were able to run with them for about two years and now we are like um now we are come coming to a certain size this is the first time we wanted to re-evaluate that um so it's not necessarily quite often but I would just recommend try to maximize the utilization of the note type that you choose And like said before try to choose a note type that is relatively modest in compute like four to eight cores but then more generous relatively bit more generous like 16 um gigs of memory or more um RAM and yeah um number of attached discs that you want to choose Hope that helps And um in relation to the previous question one thing I want to add is you don't want to regularly like try to right size your cache vertically but what you want to regularly monitor is the change in your right volume and query volume If you start to to all of a sudden query more data frequently you may want to increase the capacity or from the other perspective if you start the um if you start all of a sudden logging more data then the set capacity of your cache now holds less amount of query period Right if you double your ingestion and if you used to cache four days of data now the cache capacity will only be able to hold two days worth of data where you regularly still query four days So you want to you want to monitor the use of Loki and then adjust the cache horizontally But I would argue if if chosen correctly you you shouldn't need that um to change them vertically Yeah So I there's a really good question in here I know it's sort of like changing the subject a little bit but I feel like it's been good because we talk about a lot about how we want to sort of size based upon like you know our regular intervals of data like um and I believe let me I'm going to butcher this name I'm so sorry Lez um so sorry lez or le um they're basically asking if if and this is like an ed query we were going to classify it um as where you do like a 30-day pull back of data Um what's the best way of preventing sort of looking into cache or I guess sort of writing back into cache where you might sort of hit like a failure scenario because you want to do a much more intensive query um in in this sort of situation Um so I want to I I want to call out like shout out to um a community member here their their GitHub handle is uh M betas or MV meas uh sorry for that but basically this this was a use case that they needed and they reached out about what three months ago So yeah they they had this rare use case that they need to pull the longest retention data which was like um erasing all their cash um evicting everything in there So they they introduced um um a flag that is called and J share the PR skip query write back cache older than some time Um and then this basically says like if it I I believe it's yeah if I remember the PR correctly if it's set to zero so it will just skip the cache altogether um which is a fantastic way of if you if you have this use case it's a great way of um yeah doing it and thanks for that contribution I'm so glad that naturally got plugged by a question from the community who was just like self-s served stages yes I I also have to have a huge uh kudos to Matt in the community as well as putting in that PR he is such a saint when it comes to answering questions and talking about people's sizing So massive thank you to him in the community He's always in Slack um sort of answering people's questions Yeah I think he's he's also here He's the one that's been asking some questions Is he is he yeah sure he is Yeah he's the one that asked about the the tuning the key metrics for knowing if the cache is correctly tuned and stuff So make sure to answer some of his stuff too Sorry I did not tie you together Yeah Can I Oh now I see it's mas Um I I see a question from Matt that I got excited about Is it normal to see a lot of timeouts when queries are communicating with the mem cache um we this was a this was a case that we run into a couple of months ago I I mean we think it's been happening but it kind of intensifies and get our attention is when when the cache timeout is so high uh we notice that the queries time out waiting because because we are graciously uh giving so much time to cache the querers are just waiting and go like I'm sorry I didn't get my data and then they go like sorry time out 500s Um so what we did is like we reviewed the cash timeouts we have and we drastically reduced it because it's under normal circumstance circumstances when cash is functioning fine It's not a compute heavy process It should just immediately find it and tell if it exists or not It it's a hashmap lookup So we reduce the chunk gash time out to 200 milliseconds Uh and then L1 even yeah we consider yeah I didn't merge the FPR it was late on Friday um we consider the same thing for for L2 to because it's in memory even drastically reducing so please try that out and if it doesn't work out or there if there's something else we can look into it um but that might be one of the reasons I I believe the defaults might be too Hi Oh we've lost you Nicole Oh sorry I hardware muted myself Maybe we can also talk about uh monitoring memcache in general and seeing if it's being utilized by Loki In particular there's a question by Jean Kristoff here and they ask how to check how do you check how the different caches are actually working for some cache like index queries and index rights has zero for the metric memach current items Yeah I think because this is the one where um they're using the tsdb I believe so Yeah because because the defaults are still there Um it yeah it exists but it's not in use If you're on TSDB you're yeah there's nothing that hits that cache Um we'll have to we'll have to check if that's in the Loki mixins under that Loki operator still or just get rid that' be a thing to check after this I uh I think Lucky Mixon's um if I remember correctly like they they pull in all types of cache because the container all is mem cache So whatever you have all enabled cache will be listed Okay great to verify that with junk Um so whatever cache you have enabled it will list all types Um we don't have a coming back to monitoring Um yeah no no use to set it up Sean Um yeah you can just get rid of it Um what was I saying uh monitoring me Oh thank you Other types of cash Thank you Um I'm I'm sorry I forgot that Uh we were working with Jay We noticed this We don't have a dedicated cache um dashboard that is in the Loki mixins If if you guys feel we can like we can try to invest time in that but what we have is in the loi operational there's a separate um role for that that shows the latencies that is uh I I think hits and misses from storage and then and then latencies um that can be enhanced with some more like mem cache provided metrics or we can also um come up with a separate one We have some internal dashboards that are dedicated to XTOR but we want to underline again that XOR is a very specific use case That is a significant complexity introduced to the system So that's not something we necessarily want to push the community towards that like you should do this Um Oh yeah that's that's cool um like out of the box mamm cache metrics should be good This is the rows that I were talking about in operational Thanks Jay Yeah I mean I mean that that'd be great to know if people do do want that Um just let us just Yeah I mean if you want to comment in the community just let us know because we can release the initial new version of this and then we can add to it as we go Um and did someone just say sorry did I just miss that that someone said there is actually already out of the box measurements for memcache that we use any dashboards that available from memcache themselves Yeah So Paul was saying earlier that memcache comes with uh some statistics You can just do stat on on it and then um it gives you a bunch of stuff And then uh Jean Kristoff was saying that there's already a Graphana dashboard for that stuff So can use that Not from us but apparently someone made it It's great We can pull that one in Wicked Okay cool Yeah Sweet Um I I wanted to know you know you mentioned I think poison you mentioned that you and Paul have been working on um on on the cache recently and specifically about about the recording rules Can you talk a little bit about those because I was kind of thinking that they're they're separate in my head It's like when do you use a cache versus when do you use a recording rule so I mean maybe you could uh give your opinions for that and then also talk a little bit about the work that you've been doing and how they're related Um I can do the clarification and then Paul maybe you want to dive deep into what we are doing So to me cash and recording rules are slightly maybe not apples and oranges but maybe oranges and satsumas or something That's basically because because a recording rule is when you yeah when you do the same aggregate analysis on a group of logs repeatedly that's when you need a recording rule and the context that I mentioned it in was um is now we want to get our how much data we have we get from chunks uh sorry how much chunks we get from cache And we have a log line for this in metrics.go that is logged by the querers So because we want to access that data particularly uh and regularly um we are introducing a recording rule for that So that's that's that repetition Cache is a way more generic concept that when you need any data regularly that you can put it in a temporary storage and then constantly accessing it Um so yeah make make use of recording rules separately and then when you particularly want to like do the same analysis or yeah like alerting or something o over the um periodically over the log lines that come in uh but c treat cache separately because cache serves all your queries whereas recording rule is a specific query um that you focus on Uh hope that helps and then Paul you want to share our work Yeah what uh Poison and I are doing is uh we had a another colleague that uh started work for trying to dynamically size memcache um because this tuning process as as we've certainly alluded to is complicated There are a lot of different factors And so some of what we've done has been introducing recording rules so that we have data that is easily obtainable that isn't costly And we want to try to automatically scale our caches up and down based on a variety of items such as how much data is being ingested how much data is being queried uh what's our hit ratio on our caches and once we see things out of a certain threshold then say we might need to add more cash or we might need to lose some cash so that it's appropriately sized And it's going to be a heruristic but it's a lot better than doing it by hand every few months That sounds cool Um we have a question from DJI 101 Love those drones So what are some recommendations for chunk pod sizing when ingesting two terabytes a day also is persistent volume claim storage recommended um like I said like no our mem cache config does not does not use PBCs Um and two terabytes a day It It's tricky I I don't know how much you access how many people access they access it Do you open it once a once a day and run one query or like is there during the workday is their dashboard open constantly pulls that data for like a week that's different So if it's again analyze your access pattern and there is there's data for that Um there's a metric called queried bytes on uh yeah I think loy tenants query bytes um and then you can see how many tenants how many yeah look and then you can further do like uh an analysis on metrics.go go line what is the period they hit and if we don't want to dive deep in in any of this you can start by just provisioning some in memory but because we're in the order of terabytes and if you want to kind of cache more than couple of data the extore config is available you can also start with that um we try not to do instance recommendations everybody like uses different providers and then providers recommendations do change depending on the region Um so you can also dive deep We can share at the end maybe in the comments that um Danny's blog post on mesh that's an excellent resource He also has contributions to memcache xto open source documentation um that specifically tells how Loki uh memcache xto is configured we can share those two resources and they can like serve as fundamental Um yeah that is the blog post and I'll find the OSS docs Uh Jay U Nicole and yeah I'm I'm sorry it's a very much a it depends thing but like don't be afraid to provision some see how you fare and then change it and then start with inmemory generously start with e-memory because it's so easy the configuration is already there provision like 60 pods I don't know uh but with but in in general like with I don't know 20 gigs of RAM right then then you will get some amount and then see how much you save how much it costs us and uh cost you sorry and then take it from there Don't don't try to jump into one or other solution without trying the simplest and most available first So so I guess my takeaway from this whole conversation on cash has been is like there's not a one-size that fits all It is an organic process that you should like measure and continuously re-evaluate like we do like every day now for our own customers So I think that's the cool takeaway here is it's we the depends make sense because you need to have a go and work it out yourself based upon what Loki's telling you in terms of it health statistics back Um so yeah I guess like I think that adds to my excitement to add memcache to um the Loki mixins and I think Matt also alluded to if we can like get the rules once you and Paul are done um if we can add those to the rule list in like the Loki mixins as well so they've got some idea if we can that would be pretty sweet Yes I'm I'm saying nod We're saying nods is it's going to happen community They're they're all on our agreeing More of an agreement but yes um Loki is wonderful in the fact that you can run it in a very simple way or a very complicated way You can run it just as a single binary or you can run it as you know hundreds or thousands of pods And no one solution is the correct solution necessarily It it's it the answer is always it depends but you know we need to definitely provide more tools for the community and some of these mixins and recording rules will definitely help with that A thank you Awesome Thank you all so much for for coming on We're already a bit over time We could have kept going on cash stuff If there are some questions that we didn't get to or if you have any uh if anybody who's watching this after the fact has any questions put them in the community forum actually because that way other people can can see it too and they don't have to go to YouTube to find it and we will get those answered for you Um any last word last words from Poison or Paul before we close thank you so much for having us and thanks for the great questions on the chat It it felt very like naturally organic Um yeah Um yeah thanks for awesome Great questions Glad to be here Glad we can help and looking forward to helping more Cool Well thank you everybody Uh have a good rest of your week before we lock up some question in the next topic And I know you guys already have a couple lined up Oh yes Oh Bloom Filter Oops wrong one Bloom filters Actually we already did one on bloom filters If you go back through the previous Loki community calls we we talked quite a bit about bloom filters a few a month a couple months ago or so Um so have a look at that and I'm sure we will tackle it more in the future again All right Well thank you everyone Have a good rest of your week See you next time next month

