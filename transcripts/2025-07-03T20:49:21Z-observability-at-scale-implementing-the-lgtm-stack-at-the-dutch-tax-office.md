# Observability at Scale: Implementing the LGTM Stack at the Dutch Tax Office

Published on 2025-07-03T20:49:21Z

## Description

Curious how the Dutch Tax Office brought observability to life in one of the most complex IT landscapes in the Netherlands?

URL: https://www.youtube.com/watch?v=cbz8r4A9FQM

## Summary

In this video, Frank Ferupt and his colleague Brah from the Dutch Tax Office discuss their project involving the implementation of the Grafana stack to improve monitoring and observability within their complex IT environment. Frank, a product owner with a background in IT consulting, outlines the structure and operations of the tax office, emphasizing the scale of their operations, which involve 27,000 employees and 900 applications. He details the tender process for acquiring Grafana, the project's goals, and key decisions made, such as the preference for on-premise solutions and the use of open telemetry. Brah then delves into the technical aspects of the deployment, including the setup of customer clusters, the use of OpenShift, and the integration of Grafana Alloy for enhanced monitoring capabilities. They conclude by highlighting the stability and reliability of the new system and the positive feedback from teams now utilizing it, as well as the ongoing challenges they face in managing data and ensuring proper labeling for monitoring.

# Presentation Transcript

**Welcome, everybody!**

We wanted to share the project we worked on using the Grafana technology at the Dutch Tax Office. Here's a brief agenda for today:

- Overview of what we do
- Discussion of the tender process
- Implementation of the Grafana stack
- Key decisions made during the project
- Technical insights from my colleague, Brah

### Introduction

First, let me introduce ourselves. My name is **Frank Ferupt**. I started my career as an IBM Tiffle consultant, working with many financial companies a long time ago. I joined the Dutch Tax Office because they were using the same tools, and now, 11 years later, I am the product owner for the monitoring team. We have transitioned from IBM tooling to open-source Grafana, which I will explain later. 

**Brah:** I started my career as a software engineer in the AV IT department for luxury yachts. Three years ago, I joined Frank’s team, and I’ve never been happier.

### About the Dutch Tax Office

Of course, everyone knows us from the blue envelopes we send out. However, behind that is a significant operation. Just to provide some insights, every day, we collect around **1 billion euros** in tax revenues. Our mission is to maintain the financial backbone of the government in a stable and transparent manner. 

To support this mission, we have a very dynamic and complex IT environment with thousands of interconnected systems processing millions of transactions daily. We have high standards for security, reliability, and scalability, all running 24/7. 

Here are some numbers:
- Approximately **27,000 employees**, with **4,000** in IT.
- Around **900 applications** spread across various platforms, including mainframe, OpenShift, Linux, and Windows.
- About **18,000 VMs** running across our two data centers, which we maintain ourselves.

### Our Team

Our monitoring team consists of six FTEs, including myself and five system engineers. At the tax office, we use various monitoring tools. In the past, we utilized expensive software like IBM and BMC, but about five to six years ago, we made the switch to open-source solutions, specifically Grafana. 

We have around five to six years of experience with Grafana, primarily as a dashboarding tool. In addition to infrastructure monitoring, our team also focuses on event management, ensuring all events come together in one place. We centralize the management of interruptions using IBM Netcool, which is an effective software for handling events. 

Our latest service offering is **APM (Application Performance Monitoring)**, also referred to as observability.

### History of the Project

We have two teams: the performance competence center, focusing on improving team performance, and the income tax chain, which required more insight into application performance. In 2018, we began the process of acquiring new software through a tender process, which outlined our requirements and allowed suppliers to submit proposals.

After navigating some complex compliance and legal issues, we successfully chose Grafana in 2023, which offered the Grafana LTM stack in an enterprise form with support. We started implementing the stack in 2024 and aim to provide it as a service to other teams, going live in early 2025.

**Key requirements included:**
- On-premise deployment (cloud was not an option for us for a long time).
- Support for open telemetry.

To implement this project, we set clear goals:
- Fully implement the product on-premise.
- Monitor an application with it.
- Ensure the service is reusable for other teams, complete with example configurations.
- Conduct a promotion tour to present and demo the solution to teams.

### Key Decisions Made

During the project, we had to make several important decisions:

- **Tenant System:** We decided to implement a tenant system, allowing teams to join under specific chains like car tax, income tax, etc. This decision came with challenges, such as monitoring data ingestion at the tenant level and ensuring teams provided required labels for their data.

- **Grafana Alloy:** Grafana Alloy was introduced during the project and provided excellent compatibility with open telemetry. We opted to let teams implement it themselves to promote empowerment and reduce maintenance burdens on our team.

- **Security Measures:** We established an intake process for teams wanting to send data—ensuring only authorized teams could contribute.

- **Dual Stack Implementation:** We built an open-source Grafana stack to handle generic data in parallel with the enterprise stack, allowing for cost-effective scaling and licensing management.

### Technical Deployment

Now, let me pass it over to Brah, who will provide more technical insights into our deployment.

**Brah:** 

Let's take a deep dive into what we deployed and how we did it. Our setup consists of the LGTM stack plus Pyroscope. We currently have two customer clusters: one for development, testing, and acceptance, and another dedicated to production systems. 

We also have two open-source clusters for big data and chainless applications. We aim to make all consumed data public for easy access without additional privileges. 

To deploy the clusters on the OpenShift cluster, we collaborated closely with the OpenShift team. We utilize the **Pass Operator**, which is available on GitHub, allowing us to merge requests and implement necessary software without needing admin rights on our own cluster. 

To deploy applications, we use **Customize** and **Helm charts**. Helm charts essentially act as recipes for deploying applications, enabling us to streamline our deployment process.

### Monitoring and Data Management

We also wanted to monitor our stack effectively. We collect logs, metrics, and traces from our enterprise cluster and push them to our open-source cluster, allowing us to continue monitoring even if the enterprise cluster goes down. This separation also helps scale our backend resources according to customer needs.

We built custom software called **LGTM Automate** to facilitate the addition of teams to our cluster, allowing us to quickly onboard new teams by automating the configuration process.

### Challenges Faced

During our deployment, we encountered several challenges, including:

- **Legacy Databases:** We have a massive legacy database, and many teams still run older versions of software that require monitoring.

- **Force Labeling:** We requested teams to include labels in their data submissions, but many are still not complying, making it difficult to identify data sources.

- **Identifying Useful Data:** We face challenges in filtering out unnecessary data and ensuring that sensitive information is not leaked.

### Conclusion

To conclude, the technology we’ve implemented is stable and reliable, operating smoothly on-premise without crashing or performance issues. 

We have observed new insights from teams that connect to our stack, especially in tracing and profiling, allowing them to quickly pinpoint problems. We've grown from zero to **250 users** in a short time, and we’re excited to empower teams to monitor their stacks effectively.

Thank you for your attention, and we now have time for questions!

## Raw YouTube Transcript

Welcome everybody. Um we wanted to share uh the thing we did with the graphana tech at the Dutch tax office. Um the little agenda for today. Uh we're going to talk a bit about what we do. Of course many people I think know for a bit what we do but uh I give him some more details. Um we did a tender. I'm going to talk about that. Uh and from that tender uh we started a project to implement uh the graphana stack. And during that uh that the project he had to make some key uh key decisions and we want to explain them run you through them and then uh my colleague Brah the we'll continue with the more technical part of what we did. Um well let's first introduce ourselves my name is Frank Ferupt. Um I once started my work life as a IBM Tiffle consultant worked with a lot of financial companies long time ago. um joined the Dutch tax office because uh they were using the same tooling uh and well time flies 11 years later um uh product owner for the team the monitoring team and uh yeah IBM tooling is kind of gone it's completely switched to open source graphana but we'll explain that later I'm braker I started my career as a software engineer at the AV IT department in the luxury yachts but three years ago I joined the Frank and I've never been happier there. Thank you, Ram. Um well, a little bit about the tax office. Of course, everyone knows us from the blue envelopes we send out. Um behind that, there's a whole lot of operation going on. Of course, um just to give some insights, every day I check it on the website, every day, uh 1 billion euro is collected, uh in tax revenues. And of course we do that to make the financial backbone of the of the government of the country uh stable transparent. Um supporting this mission this this this goal is to uh very uh dynamic uh complex IT environment. Um we have uh thousands of interconnected systems doing millions of transactions every day. Of course high standards for security, reliability, scalability uh all running 247. Um yeah by some numbers here also um we have around 27,000 employees um of which 4,000 only in it. That's quite quite the number I think. Uh we run about 900 applications uh spread out on all kind of platforms uh name it and I think we have it mainframe open shift uh Linux Windows uh etc. We find it difficult to say uh goodbye sometimes to the platforms. Um yeah about 18,000 VMs we we use uh yeah it's all running uh yeah in our two uh own two data centers also good to know we also have data centers we have to maintain ourselves also. So from the tax office if it works I'm going to our team. Our team is sitting there. We are with six FTE including me. So five system engineers. Um yeah what you see at the tax office we have a lot of monitoring tools. Uh I mentioned the platforms. Uh we have a mainframe with our own tooling. We have Windows with SCO. Um yeah from the old days we used to monitor Linux and AIX. That was our team uh main goal. Um we used the expensive software for that, IBM software, BMC software, but I think five six years ago we made the switch to uh open source. We did a P with Sabix um with Sabix and Grafana to to yeah uh give the data to the teams because Sabix was not very good at that. Um so I think we have around five to six years experience with Grafana already just the dashboarding tool of course. Um well this is what we do uh in infrastructure monitoring. Uh the other thing we do with our team is uh event management. We have like uh all the monitoring tools but we have one rule uh all events should come together at one place. our operations bridge centrally manage uh manage all the interruptions we have solve them uh they do standby in the weekends that kind of stuff uh we do that using IBM netcool don't know if people know it but it's a really uh nice software handles events uh very good um the last service the newest in our portfolio this is uh we call APM application performance monitoring or as you would call it probably observability that's uh the stack we offer to teams. Now then I'm going to talk a bit about the history behind this. Um we have uh well two teams I think performance competence center which main role is to be busy with improving helping teams with performance. Uh and the income tax chain they wanted more insight in in in application performance. So um I mentioned here 2018 I think we already tried to acquire the software um well that we had to do a tender of course we cannot buy software that we like we have to write down all our demands um we have to uh publish it and u suppliers can uh uh make an offer and uh supply their products. Um after some very complicated formas uh uh compliancy uh cost uh we get a winner um but failed a couple of times uh too expensive legal issues but uh we got a winner now that was Grafana and that was in 2023 and they offered this Grafana LTM stack in enterprise form with support on it uh trading that kind of stuff. Um end of 2023 the tender was successful. We used 24 to implement the stack and to yeah provided as a service to other teams and beginning of 2005 25 we are live with it. Um we had a couple of requirements I can highlight. It should be on premise. Cloud was a big no no at the tax office for a long time. uh it's getting more open now but yeah given the relations with the US it's uh it's getting more complex now um and also it should support open telemetry so that's also a thing that we uh really like to have in the in the tender well to implement such a a project it's kind of complex so that's why a project was started we always do that at the tax office a product manager they get some goals and the goals were quite quite clear here I think um implement the product of course completely on premise. Uh we had to monitor an application with it an MPPP. Uh the surface should be reusable for other teams. So we should have like a a example configuration available. Um and we should do a promotion tour. We should talk to teams presented do demos that that uh that kind of stuff. Um, of course in the project we need uh other platform uh uh other teams, platforms, storage, networking, all those teams. So then it's nice that you have a product manager uh running that part. Um because it's better I think to do the happy customers do the talking. Uh the first team that joined our stack, they were really happy with uh what what it can offer especially the tracing part. Uh they really quickly solved some performance issue with it. So we let them do the talking also because yeah it's best to let the users spread the word um beside the mere more technical demos that we give. Um during this project we had to make a lot of choices and I have some highlighted here. Um because we have the enterprise version of the LTM ST we have a tenant system included. Uh the question now was yeah what is a tenant? you can make a tenant per team that wants to join this deck. Um, also one of the requirements we had in the in the tender is we want like a chain level overview. So we want a income tax. We want to yeah see how the chain is doing. Um that's why we decided to do a tenant per chain. So I think we have like five chains car tax, income tax etc. and teams join under a chain. This has some disadvantages. Um, of course, because we have the enterprise product, we pay uh by data ingest. It was bit more difficult to monitor that because uh uh we do it on tenant level. We cannot see what a team is sending in. Um so that's why we made a requirement to send in uh your a required label team ID with the label graphana helped us creating a dashboard um in which you can see the data per team. So we still have insight in that. Um the other thing is that within a tenant by default the data is open so teams can view each each other's uh data and some teams for some teams it's uh yeah bit difficult but yeah we want the chain overview um yeah the next one is graphana alloy alloy came out during the project was really a nice product because uh yeah open telemetry permit is all combined uh so we wanted to implement that um We had some choices. Are we going to do that centralized or let the teams do it themselves? And well, after discussions and uh yeah, advantages, disadvantages, we decided to let teams do it themselves. Um we otherwise we had to put it down, alloy, uh configure it, uh onboard teams in it, add tokens, uh all the maintenance is coming to our team, uh all exceptions, data manipulations. Yeah, we didn't want to do that. And also we wanted to make sure that teams uh empower uh your use observability in their pipelines. So we provide installation examples configuration examples uh we provided uh of the open shift team provided the capability uh to run alloy very quickly. Uh and that's how we uh use alloy. All the teams do it themselves and we help them with it. Um then we have security. uh we don't want unauthorized teams to send in data. So uh we go uh to an intake process uh they fill in a form I will contact them and we talk about 30 minutes about the plans what they're going to do platform they are on what kind of data they want to send in just check what they want what they do what they want to do and who they are uh if we approve it most of the time we do they get the tokens and they can start sending in the data um from that I'm going to enterprise and open source course uh what we noticed is uh we have tenants uh with the chains we have applications below below it but we have a lot of generic data for example the open shift team they collect metrics from all the clusters uh it's not really under one tenant um if we would send it to the enterprise tech it would also be a g big uh gap in our license uh uh capacity so we decided well let's build an LGTM stack with an open source version next to enterprise send in those generic data to that stack. So now we have uh the enterprise stack for applications open source for all generic data that teams can reuse in their dashboards. It's all available in the same front end. So it's quite easy to use and it man gives us the possibility yeah to scale licensing and keep an eye on that. Um we still have added value from enterprise because uh we have admin API we use uh we have multi-tenency system that works for us and of course enterprise plugins. Splunk is quite big at the tax office also. So Splunk plug-in is uh uh nice to have. It's an enterprise plugin and JRA also. So that's uh still the enterprise version gives us advantages. From that I'm going to give the word to Brown with the more technical insight on what we did. Yeah, let's take a deep dive in what we deploy and how we uh did deploy it. Uh our setup consists of the LGDM stack plus Pyroscope. As Frank already mentioned, they won the tender. So we are going to implement that. At this time we have two uh customer clusters running. One for the development, testing and accepting stage and we have one uh completely dedicated to pro systems. uh for ourselves. We have two development clusters to test the life cycle management, new features and our uh custom tweaks that we implement and uh as Frank already mentioned we have two open source clusters for big data and for the chainless apps as we used to call them. One example is uh the open shift team that is doing that kind of stuff. Uh our data as well because we're not really part of a chain. We just want to make all the data that we consume uh public so everyone can just watch it without any additional privileges. Uh how we uh did deploy the clusters on the open shift cluster. Uh we have as we mentioned an open shift team which helped us a lot. Uh on the left side you can see all the applications that they provide us. So we don't have to be an admin on our own cluster. uh we can uh add merge requests with all the uh permissions that we need for the software to run properly and then they will make sure that it's all implemented on the cluster. So we only have uh uh our own problems with application development and that kind of stuff and not have to worry much about the cluster itself. Uh to do that we use the pass operator. This is also available on GitHub if you want to see how it works and it's really valuable for us. So uh when we ingest uh a merge request there's lots of information available what is wrong with our request what can we do better uh how are we doing with our resources and that kind of stuff. uh to deploy the actual application on the cluster we used customize and helmcharts and for the people that don't know what helm charts are it's essentially a recipe we just say in the helm chart this is what we want and the helmchart will create all the stuff that is needed to make sure the deployment is okay to go um when we started we don't have when we started we didn't have much knowledge of the open shift cluster so uh there was the best way to go for easily deployment and we had a turnaround of one year which is really nice for a government operated team. Um you wouldn't say that but it is. Um we of course the monitoring team also want to monitor what is happening on our stack. We call it mom ourselves but also meta monitoring is used uh as a term for that. Uh what we do is we collect all the logs metrics and traces from our enterprise cluster and we push it towards our oss cluster. This uh makes sure that we don't take a huge chunk of our licenses but also when the enterprise cluster is down we can still see what is happening what the logging is saying and all uh the traces and our dashboarding still works. Um the backend resources can be scaled way more towards uh what the customers need instead of what we expect to to need because uh all the huge data is pushed to the oss cluster. So the important data is not really impacted by all the changes that we do. Uh we built a piece of custom software ourselves. We called it LGTM automate. And this piece of software is uh created so we can easily deploy a new team on our cluster. It will take approximately 1 minute to add a team to our Bitbucket repo. And then the uh software will read that repo and will communicate to the uh admin APIs with the steps on the left side of as you can see uh it creates an access policy tenant token team folder data source and then at the end sets all the accesses so uh the teams can have the chain overview that we wanted in the first place. Uh when we started this project graphana alloy was introduced in version 1.0 low and it couldn't have come better for us. Um at that time we were still seeing what we wanted to use if we wanted to use Kofka or open telemetry collector but we decided to use alloy because it is essentially an hotel collector with a fancy jacket on and a whole load of support from Cavana. So uh we decided to go that way because of the hotel compatibility and uh yeah in the Dutch tax office there was already some stones rolling for the hotel compatibility. So we decided this is a way to go. Uh alloy also supports some dynamic monitoring especially for open shift clusters. So you can deploy one configuration and it will scan for all the pots and all the services that are running. So you have the collection of the data without any additional configuration when something changes on the cluster. Uh it essentially is agentless as we like to call it. Uh we can uh do some remote monitoring without deploying the kafana alloy everywhere. We can just uh put the configuration in one alloy and it will reach out to all the different kind of services that we want to monitor. Uh one advantage uh is alloy has already uh baked in support for many applications and for many services that we use. As Frank mentioned we have like services running that are from the '90s and we still need to support that for our monitoring. So having all this compatibility and our uh and the monitoring for older solutions is really valuable to us. So that's why we use alloy. Uh some of the obstacles we face during our deployment is of course our legacy database that we'll have at the Dutch test office. It's enormous and we still running into issues today that teams are knocking on the door and say oh I still have rail 7 running and what do I need to do to uh have this monitored. Um we try to uh help other teams with the alloy configuration because it sometimes can be a bit confusing but uh yeah with the huge uh platforms we have and many programming languages it's hard to have a gen generic example for teams that they can use and adapt for themselves. We're still figuring out how we can do it best to make like many different examples or one big one. We still don't know what the best option is but we're still trying. Um, we also have force labeling. Uh, as Frank mentioned, we tried to have the chain overview and team sending data under a chain. But the downside is that we don't know where the data is coming from because we don't know which team is sending it in and who to contact. So, we decided to uh approach the teams that they should force labeling into uh their data that they ingest like uh a team name or a team solution group. But we noticed that 80% of the teams that are connected still aren't doing that and we don't know who to contact. So still an ongoing issue. And of course the last part um what is useful data? Everyone is uh having this problem because it's easy to enable let's say the metrics and push it to the stack. But what are you going to use? What is things that we can throw away? What is things that we can filter out? uh how can we manipulate data so none of their social security numbers are leaking out uh very important stuff but still ongoing challenge and we still trying to figure out how we how we can help teams with these problems and uh Frank will conclude this uh talk yes with that uh by brah thank you bra we want to make a little conclusion um first of all uh this tech is very stable and reliable for us it's it's all on premise but It's yeah working very good. No crashing, no performance issues. Uh so we're very happy with that. Um also upgrading it it's yeah just very easy. So that's one one thing I wanted to mention. Uh this is combined with the flexible architecture. You can combine enterprise features with open source. Yeah really benefits benefits for us. Uh new insights. This is what we notice with the teams that are connecting to it. Uh they really get new insights especially the tracing profiling. they really pinpoint their problems quick more quickly quickly than before. Uh they used to have scattered tools maybe a jaker or or whatever downloaded from the internet. Now we have a central platform and um we see that teams are embracing it. We went from I think zero to 250 users in yeah this to the to 25. So it's really picking on uh so we are very happy with that. Um yeah and the last one is we really want to empower teams to do it themselves. Think about how you're going to monitor your stack uh when you migrate your application to Open Shift. Uh think about this, bring Aloy with it. And uh yeah, that's what we're trying to do. Um I think we told what we uh wanted to tell and we have some time for questions.

