# Grafana Beyla February 2024 Community Call

Introducing Grafana Beyla Demo Q&A.

Published on 2024-03-13T14:11:57Z

URL: https://www.youtube.com/watch?v=04QQgw-N9gM

Transcript: okay so welcome everybody to this first baa Community call we are pretty happy that actually there are some interested people non graan istas in this in this baa C uh let me share uh first of my screen just to to to see as a guide ER let me share my entire screen we uh as you see in the in the document we share about the community call we put tentative agenda but uh it really or or or or it was just some tentative we don't need to stick to it uh as maybe you already know Baya or not or you want to know some some details so uh I don't know it's it's my first Community call too so uh I'd like to know here uh who you don't need to talk you can just drop a chat message who already already knows Baya or who already has used it or who is just just here to know what's what it's about for curiosity but don't really have tried it uh never uh sorry maybe we we should present before I'm Mario Matias I'm I'm software engineer in the grafana ba la team here in the call is also Nicola GFI as you will see in the background is he's our our principal engineer and also Mark to join sorry Mark I didn't added you in the in the caption I forgot it sorry it will be the last time it happens uh but Mark recently joined our our team too uh so we are the three Engineers working working here in in grafana in grafana [Music] yeah so yeah I don't know if anyone of the attendees wants to introduce himself and tell us what uh why or what wants to know about Baya or what they want to comment about Baya is is optional okay that's okay yeah that's that's okay uh someone else entered hello er hello Silva we we saw we were commenting uh that uh oh yeah we were commenting or asking if people want to introduce themselves volunt really I mean is not needed or because uh to introduce themselves and uh comment what they are expecting of this community call or what they want to know about grafa or what or what what do they want as to to to talk about uh if not then it's it's fine I think we can then start with a generic uh presentation about uh what is grafana baa and and then we can discuss discuss other topics do a demo um okay Adrian thanks thank you thank you Adrian Adrian comments wants to learn more about it and watch the demo okay so let's let's let's do it uh we created a we did a presentation but more as backup slides rather than something we need to or or to a script for the for the whole talk so what is grafana baa basically it's a software component that allows you how to instrument https http2 and GPC services in go applications more Protocols are on the way like SQL maybe in the midterm other messaging protocols uh it supports full context propagation but it also supports HTTP in other languages H we tested with with old versions of go uh Java net python Ruby njs rust C and C++ and we were all also able to instrument them uh it we produce partial context propagation in in that case uh another feature of ba is that we are fully integrated with kubernetes uh it means service we can select uh the services to instrument by po deployment name space and so on and we decorate metrics and traces with kubernetes metadata we are integrated with kubernetes but we are not only exclusive of kuest you can run ba as a as a as a regular operating system process so Hui commented that or asked if is baa scop to http request and grpc er he did a good question about if vaa is able to AO instrument phone call traces uh not at the moment not at the moment uh if if there is a phone call management software that that is can be instrumented uh it's another protocol in the future we could add the same way we plan to add SQL or other messaging protocols if there is a demand for this kind of uh more streaming based protocols it could be it could be ER considered but not at the moment not at the moment at the moment we are more thinking on RPC like er messaging but it's a it's a very good question it's it's actually a use case we never thought about but it can it can be interesting continuing with that ER Baya is is able to work Standalone uh uh sending data it it instruments the data and or the instruments the your your applications and it can send data uh to ER either the graphon agent the open Telemetry collector or being collected can expose metrics in promethus uh or you can submit the the data directly to the grafana open Telemetry and point I forgot to mention that grafana baa is able to expose either a metrics and traces metrics in both open Telemetry and promus formats and traces in open Telemetry in open Telemetry format and it's an open source it's an open source uh application uh based on Open Standards so you can you can use it even if you are not a grafana user you can use it with any other promus or Telemetry collector so what's the reason about baa uh imagine you want to instrument an application you have your web service and you want to submit data to a collector name let's say grafana uh you want some metrics and execution traces one option is to use a runtime agent this is uh B doesn't come here to replace the exist the existing instrumentation approaches it's just a uh it comes just to fill some gaps that the the other the current approaches ER have open so one is using a runtime agent between your service and your runtime environment this is mostly used in runtime manage languages like jbm Java net iyone it has some it has some limitation first is that you need to deploy the agent as part of your app within the memory address space you need to pack it and it uh it could bring some some overhead in some in some languages ER it will add some memory and CPU to your application uh also running multiple agents at the same time is not always support by the vendors uh be by some vendors because some of them assume they are the only agent running so there can be some incompatibilities uh or they just won't offer support if there are other agents with with their with their own vendors and some agents may have limitations and you need to you need to find some way to overcome those those limitations the other option is what we usually do in in languages like go or C that is manually instrument your code so your web service has some functions and you need to add some instrument manually some instrumentation points into your code you then uh you need in that case to recompile and redeploy your application uh it has also some disadvantages that first is that your instrumentation code is merged with your actual business ER code so it adds on maintainability overhead uh and it also add a vendor loin because changing changing your your instrumentation provider some often requires uh changing or or or or refactoring uh big parts of your of your code it requires a lot of effort even if you already don't if you are instrumenting a legacy application that is not already instrumented you need to invest some development resources instrumenting it h that means also that it's easy to Mis instrumenting uh some some apis and and enter in an in an error PR manual process the the alternative we offer we say there's the previous Alternatives we show have their hold but they they they are still valid for many other use cases but baa allows to overcome those scenarios in which either an agent or manual uh instrumentation is not feasible maybe not from a technical perspective but maybe just from an operational perspective or an organizational perspective so uh baa is a is a process that run in your in your system as a host process or as a privilege container and thanks to evf is able to inspect your run your code runtime or libraries or the Linux kernel in order to provide metrics and traces and send them to to grafana uh evf is able to hook into some concrete points of your applications and the Linux kernel and then is able to audit and create traces about what's happening there and then submitting them the advantage of baa is that h you don't need a a to ship agents with your code you you just need vaa to run into your host uh it Al has the advantage of having native performance uh this is important in in some in some languages that are interpreted and the the agent or or the the the the instrumentation agent is also in in an interpreted language that my my may add a sign significant overhead B with baa you can get metrics traces or both and you can export them in well known standards like promethus and open Telemetry H what's evf we have mentioned evf before evf is comes from the now it has its own meaning it its own but it comes from extended verc packet filter is a virtual machine that is built into the Linux kernel that allows you to write and hook your own programs into into the into the kernel functions as in in the user space that we mentioned it's like uh at the booger break point anywhere but instead of inspecting visually you inspect it inspect it automatically and then you can get data you can know when a process start when a process present the values of their their their their variables Etc uh ebpf is not magic often people say you use BPF you can say everything so you can provide a lot of information it's true but it's very sensitive about how the memory is laid out that means that evf or the way you have to code your evf programs will Vari if you are instrumenting a go program or you are instrumenting a a c program or even it's sensitive to the optimizations of the compiler or some implementation details or the compiler uh so I think that instead of after G uh giving a introduction to the to the technology and what's vaa we can do a demo instead of keep entering in in details and if you want to know some detail or there's something that you don't understand please raise your hand interrupt me and uh we can uh answer your questions I will do a a demonstration of a simple service example let me share let me share my console here here let me share let's deploy I have a kubernetes cluster here in my in my laptop ER and let's deploy a a an example web service that is not instrumented it's a service written in go let me upload first sorry I should uh make all we need some seconds to build the service and and push the images to my local I should have done the before before starting the the call but I forgot that I destroyed the I destroyed the the the cluster and started a fresh cluster but that should be quick they are simple or small Services uh this service is basically a a load generator that or or a front-end service that submits data to a backend service via HTTP the front end is also HTTP and this back end sends some request to some workers uh that are communicated via grpc in order to demonstrate all the protocols do you want to maybe just quickly show the source so people can see it what does it look like but oh yes the S the the deployment yeah the deployment yeah so that okay okay so we can see it what it looks like we're not doing anything yeah yeah we are not doing anything strange so we have this this is not a video Ying we are deploying a a front end application that opens this this container Port 880 and it is connected to a backend H service this servic is exposed as a kuet service then we have the backend deployment that has some uh workers let me one moment uh this these workers let me just this is uh this is just an implementation detail uh this way we are we are splitting up the requests on three on on on three request so we we will see how the the load is distributed amongst many many workers this is just an implementation detail of of detail of this backend example service and apart of this backend we have the worker deployments which are the images I I saw before and also we have a load generator is just sending requests to to the frontend in order to automatically generate some some traces so let me uh let me deploy it and here we see all the all the borts let me do a quick port for work just to is from and ah sorry I forgot the name I always forget the name of space okay it's at the end this this service is just a factorial number calculator you you see uh you write here the number and it should return a factorial but sometimes it just randomly fails like in this case uh to uh to demonstrate also how baa instrument some error uh some error return code but if not you you can see how it calculates some some big uh factorials this is uninstrumented so I will deploy ba to instrument it I will deploy ba with my grafana credentials I first need to to send data to grafana Cloud you could use any local grafana instance or any other open Telemetry or promises supporting monitoring solution so I will first my grafana credentials do jam and er let me see which branch I am okay and Here Also let's show let's see the what we are deploying uh we are deploying baa baa requires some special permissions one is to run in a pre priv host but when if you want to get it fully integrated with kubernetes you need to provide extra permissions to be able to read some metadata of some kubernetes objects I will describe them now so er we created a service account for baa and we granted to this service account this ER this cluster role uh permissions one is be able to list and watch replica sets and the other is to be able to list and watch PS this is all the information Baya requires to query and H to be able to query services and decorating Services uh then we deploy baa as a in it can be deployed as a as a side car container so it will instrument only one pot but uh for us the easier way or more recommended way is to deploy it as a DI on set if you deploy it as a Dion set it is important that it shares the host PID name space so it's able to inspect all the processes in a in a given in a given host and apart of that ER we are just providing baa a configuration file we can configure it also so in Via environment variables uh but in that case it's simply a config file I will show you later and we need to provide uh a open Telemetry endpoint this is graph cloud and some heers in that case that will provide authentication for for security reasons I'm not pasting here the heers so I'm taking them from the secret file I've deployed previously I can show you later how is this secret file the template and this configuration file we provide is here this is a very simple configuration file basically saying to baa to decorate the metrics and traces with rootes with roots and uh provide some heuristic approach in order to group all the roots in order to avoid cardinality explosion you can also in instead of providing this humanistic approach you can provide manually your own Roots so you will make sure that any root ER matching the pattern you provide will be grouped into that pattern so you won't get multiple uh root values for example when you when in your URLs have user IDs or product IDs or or or things that very high cardinality that you don't want to be reported as as part of the root but as part of a pattern and here we have the way we tell discover Baya to discover the services we want to instrument I say Baya toover all the services in the demo ER name space so if I deploy baa like that it will find all the services that I deployed but I can narrow this and for example uh say for example I only want to instrument the the back end this way will will instrument the back end deployment in the demo name space let's try and later later I will remove them and see how it can select multiple services do you need an extra oh do you need an extra Dash in front of it or no no no no good question good question if I added an extra an extra Dash it will instrument all the Serv they are two different entries then it will instrument either all the services here or either ER this one so it it will end up instrumenting everything this way we we want to uh just instrument all the the services that fit both criteria in the name in the name in the demo name space and in the backend deployment name uh let me also see if uh yeah uh I want it's okay I don't want to add more configuration at the moment so let me deploy it so it's it's creating the container uh I just want to see where is this back end this backend service is in the worker Noe uh let's wait a bit until it uh downloads the images from from the internet it shouldn't take so many seconds okay it is running let me let me just show the log messages okay it you can see that b started and it the log say that it is instrumenting a process actually the process command back end it is only it only found that because it's actually the only process that fits our our our criteria yeah so let me go here and let's go to grafana cloud and uh let's go for example to the my traces I will search you see here all the back end Services all all the traces of the backend if you say if you check here there is only one backend service and here you can see some some other internal traces like this back end it it receives this get factorial this is this hristic uh this factorial asterisk is theistic approach I said before here ER the the URL for this service is factorial slash and the number you want to calculate the factorial but since since this number changes a lot if we expose this as as an attribute to metrics we will get cardinality explosion and grafana could struggle with so many cardinality uh ER you will get a high cost for your for your for your Matrix this way we are any factorial slash and some variable sequence of characters in that case a number will be grouped into this into this route factorial as is rout and you can see here how we are getting the the the trace for either the the request but also as a client we can see here the re the request for the worker notes you can see how much time the request has be has been ined and how much time the request has been processed by by by the application this is something that we can only at the moment achieve with evf because evf allows us to hook into the run time in order to know not only how much time uh the the the service has been processed but also how much time the request has been ined in that case the number is pretty low because the the service is under low load but under high load this this number can be can be pretty high and since we are only instrumenting this back end let's extend our our request for any other service in ah sorry not this let's just remove this deployment mode and let's say okay now I want you to instrument all the services in that name space and baa triy to instrument all the processes service and client both services and clients into this name space I need to redeploy it again [Music] okay now you can see how um Baya found three found three services in that note the load generator the front end and the worker the back end is missing because probably the backing is in the other note this kind cluster has three three nodes if I if I do the logs in the other baa instance you will see this this other worker instance and the and the back end and now I have since I have multiple notes I have some vaa instances sending data to grafana Cloud we will already see them here so if I just refresh you can see now how I have multiple traces the low generator and the worker and the back end should be also in into in here uh let's let me Lo for example the trace of the load generator uh okay you can see it here uh let me it seems that the back end traces did not yet arri right let me just refresh it one moment and or let me directly look for the for the back and traces uh we found that this that has happened sometimes this is a matter of the catch the okay this is this is something from the grafana cach let me just one moment uh empty cat and her reload and we should see the the data coming maybe expand the Lo maybe it's under because it combined the traces uh ah okay yeah yeah it finds the loen because the bin is inside yeah yeah good good appreci n okay so here you can see how distributed traces work we can see the whole life cycle of the request from since the low generator to the front end to the back end and how the back end is invoking invoking multiple times these these workers and if you enter you can see also how the how the traces are decorated with kubernetes metadata you can see here there name space all the data name space the node name the the name and some other standard open Telemetry attributes for for kubernetes instances and this is compatible with the application observability solution in grafana this this data takes like five minutes to get fully populated but if you if you have graph on a cloud and you have application observability you can see here how the how your applications appear and and how you see some metrics I also forgot to show previously in the traces this uh this service graph you can see also here ah a service graph okay you can see here your service graph for example we have the load generator working in the front end and and and how the front end is connected to the to the worker so you can even see some applic a map with your application metrics uh yeah that that will be pretty much the the demonstration of how graab Works uh I don't know if you have some question or some comment something you would like to to to see don't be shy but if not it's it's also fine uh is there something else you would like to talk about uh Nicola or Mark yeah this was a great demo thanks for doing this and I just wanted to mention that this community call is also sort of a forum for folks to come in and just ask questions um maybe even show us something if something doesn't work we can go and debug it on on the call together or kind of look at it together uh provide General help around instrumentation and so on so I happy to do that as well shouldn't be just one-sided but uh yeah this was a great start Mario thanks for running with us yeah thank you thank you very much we are very happy and grateful that you show interest Baya and uh were with us in this in this first Community call thank you you too niola and Mark for support and preparation of this community call so we are we want to repeat this the second Wednesday of every month it will be an hour earlier than today so today it was at 500 p.m. UTC but from the next month it will be 4 p.m. UTC will be the same video call link uh the this this community call recording will be uploaded [Music] to to to YouTube YouTube so if you find it might be interesting for some colleague feel free to share it feel feel free to reach us we have a a public slack Channel ER you can reach us there I will I will later copy the the link to to the slack channel here in the document so you can reach us if you if you want we have a pretty nice uh it's small still but pretty nice Community even in the slack Channel with if you have any issu we try to reply as soon as possible but uh there are some other members external to grafana that are also collaborating and contributing so yeah we are happy if if you just join us and start asking questions suggestions or just collaborating uh the way you want so say that I think it's maybe time to if no more questions it's time to goodbye stop the recording and thank you very much see you in one month all right bye bye everyone bye okay the record stopped okay thank you very much see you later oh

