# Grafana Tempo Community Call 2024-02-08

Join our next Tempo community call: ...

Published on 2024-02-08T19:06:13Z

URL: https://www.youtube.com/watch?v=Q2m13LO-5pA

Transcript: all right so welcome to what year is it 2024 February Tempo Community call it's going to be the best ever like predicting in advance short kind of agenda here um uh but please kind of maybe get questions queued up if you have any uh feel free to put them in chat or the dock or unmute whatever you're comfortable with but uh uh starting with Tempo 2.4 we anticipate end of month we'll release 24 it'll be about right that we have about a three-month Cadence um sometimes it drifts a little bit we are not like hard set on anything but end of this month would put us at three months since 23 and so our goal is in that towards the end of February to release this you know maybe maybe it like bleeds forward to March but I don't see any reason it would now uh to4 as it is is quite stable um I don't think there's any uh anything that would be surprising we do have some cool stuff I was reading through the list and at first it seemed short which is not surprising you know it was over the break a lot of people had mult multiple weeks off during the break but I think we have some killer features coming up in two four um I was surprised how many I noted and so I have uh in the agenda I'll talk through some of these feel free again to to ask questions this isn't can presentation I'll talk through my favorites here and I have links into the change log and then from the change log of course it's easy jump to the pr uh if you want more information I'm going to make Marty talk about this first one because I don't know all the details but I think the biggest headline is experimental Trace ql metrics are going in um and he'll know of course any details about how you would enable that so Marty anything to add regarding those hey yeah so we demoed these like on a previous Community call um it's just like very basic rate count over time I am you know we're starting with like very basic features like that um there is not a Tempo dedicated UI for this so in for now we actually have a Prometheus compatible API that you could actually set up tempo as a Prometheus data source so that's how you would be able to kind of like play around with this today um rather than dig through all that I think you know we T went through that like on the previous Community call so I think we'll just leave it at that um but yeah so there's nothing else to enable it's just enabled by default for now um so yeah with two4 you would have that um but you'd have to set up the separate data source yeah uh I'll try so we have the blog post stra um and we always do like a little video I'll try to get some details in that blog post it'll be like this hacky thing basically where it will technically work right so we'll get that together for you um and that way people can experiment with that and get started on some basic ideas with the trace skill metrics and I think longterm and long-term meaning like the next release probably we're looking to have more like a dedicated endpoint uh then I guess we're not totally sure what the vision is here we'll probably we'll definitely have a dedicated endpoint I'm not sure how far down the path of prom compatibility will go um oh yeah absolutely there's there's a dedicated UI already in progress yeah I just don't know when or where it will show up right um yeah Zack do you want to add a link to the agenda DOC for that so that does that cover like um sorry you don't I know your camera off feel free not to to jump on if you're if you're busy it's good it just covers the uh the data source so if you want to add a data source for Prometheus then you can point that add Tempo and basically that's what the doc is covering so the doc should be building and deploying now and then I can drop a link to the documentation into this agenda cool thanks man uh Marty and Zack have been putting a lot of time into this last uh couple months and this is I think our absolute number one priority as a team I think we're scrambling Mario in there a little bit this quarter um I'm sure I will kick its tires a little bit try to look for performance improvements other things so this is the focus of the tempo team I think it is the future of our product and our project and um I just I think it's too important to not put all of our efforts into we're very excited about this feature um next multi-tenant query Sage I think feel like basically everybody in this call got something in here uh multi-tenant queries uh was in our jet product for a while um and we just never had space to get it over into open source um and Sage took some time this past corer to um sneak that in and so Tempo OSS supports full multi queries which mirrors the capabilities of Open Source mamir and Loki um not a feature tons of people interested in but definitely a killer feature for those who are running um you know big multi-tenant cells and maybe they want to push streams of smaller data to different tenants uh so we it's humorously one of the most upvoted requests uh on our public uh Tempo repo I do not know why but people wanted it and thanks to SJ for spending the time to get that one over there um de Par 3 will be default it was not default in 23 it will be default in 24 um it along with some Trace ql performance improvements which I just kind of note if you read through the change log you'll see three or four Trace ql Improvement style PRS um should see a very strong improvements on uh performance in Trace ql uh in addition uh the dedicated columns we talked about that in the last blog post with two three if you put these together you should see some very very strong uh performance out of your Trace ql queries um and if you're not you know it's a good good idea to file an issue maybe in the repo maybe ask in slack talk about some of the issues you're seeing and we can help you get your cluster where it needs to be in the vein of performance we've added a multi-level cache so the caching story was always pretty weak in Tempo I think we did we cached Footers and Bloom filters but Footers were broken uh and Bloom filters was the only thing that worked correctly with caching which we found when we did this rewrite now we have a full tiered cache it supports frontend jobs so if people add queries to dashboards and they're like repeatedly every 30 seconds executing or something on a dashboard refresh that will be cached in the front end there is Page level caching in the queriers which is kind of similar to maybe like a chunk caching on Loki or like that lowest level uh data source Bloom caching or sorry Bloom caching continues to work and footer caching has been fixed so the caching story and Tempo has gotten quite a bit better um um and check out that PR we'll definitely include details about this in the blog post how to configure it I hope it's kind of straightforward we added a new config block where you can just have all your caching configuration one spot and we'll talk about some best practices there in the blog post but um we've definitely seen some performance improvements across the board uh SJ rolled that out to all of our Cloud clusters and we saw what would you say SJ like half the latency what was the pretty big latency reduction yeah b90 was Prett pretty much half that's a little skewed I'll not go in details sure no worries uh but the multi- level cach is a real nice like maturity Improvement for the for uh Tempo in terms of like your ability to operate it kind of your ability to throw money at it a little bit like hey I would like to spend more money to make it faster this is a nice option on the table now um Zach did some great work what's up Marty hey um yeah I wanted to try to about the page caching a little bit more yeah yeah um I think that's really really like the out most powerful part of this is like um there's the concept of like the store Gateway in some of like mamir or Loki where it's like a buffer between it and object storage the page caching here that we've added is really our layer for that so it's it's the raw IO that would normally come out of object storage will now come out of MEC or redus I think that's like the really powerful part of this and like what Joe was saying is that you can really scale that up a lot so it's however much IO you would like to buffer right um if you have repeated queries or things like that um that you really want to get performance on um you could there's a lot of the ceiling is way higher there now with this caching than there was before yeah so yeah um it's it's pretty cool like hundreds of gigs of caching or whatever you need yeah yeah I think we saw definite Improvement on so the p level caching uh like Mario saying is at that ra IO level so just if you write a query and then you adjust a single parameter you're going to catch most of those pages on the second pass through and you should see better performance on that second query Trace by ID also saw really nice performance improvements with this page level caching because it's hitting like that same parts of the same blocks over and over again and so like repeatedly asking for that same Trace was uh was a really nice performance Improvement as well with the page level caching it does have to be pretty big because it caches a lot it takes a lot of volume um but uh it does we've seen noticeable like uh Improvement at both search and Trace byid bottomless yeah I'd really like to hear about using this with uh on Prim like object storage compatible products I think um you know like Cloud vendors object storage usually has a lot of like Headroom there right pretty high bandwidth and call rates whereas on Prem you're more constrained for resources Maybe so I'd really like to hear a story about like that I think this would be a great place for on-prem installations too uh this link you sent the McD link is this what was done in Loki the extd store is that the same thing this as it's mvme caching yep okay so internally Loki rolled out massive cash using this technology basically in MCD to lowerer their cost because now it's no longer on memory right but it's not quite as fast as memory but it is um fast enough and it is quite good oh Danny gave a talk about it very cool um oh okay cool thanks uh but uh this page level caching that could be a direction we go internally obviously you can do it every want externally but we might move to like massive like uh nvme stock cache up for our pages in our Cloud products um what else do we on here polling reduction Zach did some great work on the polling which also will massively reduce the calls to the storage back end so previously we would um on the polling cycle we would uh pull What's called the tenant index uh and then or sorry every time we built the tenant index we had to ask for every block individually and so we pull details about every block and we build what we call a tenant index which then the other components would download um now blocks are immutable they never change so this Improvement is basically using an inmemory representation if it exists so instead of asking for that same block over and over again which was unnecessary we see we already have that block GD and memory we know it can't change it's immutable and we will not make that call and we've seen massive backend redu or reduction in calls to the back end due to this polling change so this has been a real nice TCO Improvement as well as just kind of like reducing that honestly between the caching if you set it up and this pulling Improvement which will just happen automatically Ally you should see Tempo overall just kind of tax your object storage less and it should lower PCO quite a bit cool um in final news we did decide I was ready to just hatch it V park1 off that and say we're done with it Marty convinced me not to do that so in 2.4 we are going to just make v park1 no longer configurable Tempa will fail to start up and say you're allowed to uh you're not allowed to set VK the original as a um as a as their storage type it will still read V Park which will give people One release to move off of V Park one and then we can remove it in two five completely remove all the code which I was really excited to do but I agree uh this is a better path and a better path for the community for sure um so V Park if you still have it configured somewhere accidentally perhaps like maybe you hardcoded it um will stop stop fail or we'll start failing to start with Tempo and we'll give you one release to basically get off that version of be Park while we move forward all right I think those are the big ones it's got a strong change like like we always have the blog post will go into details um there'll likely be a video they like when I do that now um but get excited for that and towards the end of the month and then we can do maybe in the next Community call a quick recap too because we should have it released by them uh and I will on that note pass it off to Mario who helped along with Ruben get this PR through which is very cool uh right yeah um I just wanted to highlight this uh contribution uh we invest in the community and we valuate a lot and we love it when we get uh contributions uh from from the community members can be a lot of work um contributing to open source software for so we really appreciate it um I remember a couple months ago we also had some uh PR request I remember from kusik this time is um a PR request from D who here hi um which is it enables uh Tempo to search for T taxs and T values uh so the different values that you get suggested when you're typing tricle queries uh to the back end because uh right now until right now uh it would only search in the injustes um and now if you pass uh start and end it will also search in the back end uh we need to also update grafana to send those parameters because right now it's not sending them uh but the foundations and the bulk of the work uh it's already been done so uh that's great and this has been like a long lift request it took a couple of months um and yeah we appreciate that you stick with it until until the end and yeah that's it cool uh this has been a major request for a long time and it was one we really kind of were struggling to put resources towards and I completely agree with Mario like uh this is a really neat contribution from an external contributor to Tempo wiring up all the all the little details to pass you know create this the different jobs go down to the back end uh Mario did you talk about performance on the send Point uh no um I mean there are some concerns on how it'll it'll perform because it's just going to search for more data uh but I don't think it has been tested enough in big enough classes I didn't see a major regression in performance like still felt Snappy but um yeah I don't think we have the the ners to know what will be the impact just right I do think like uh a lot of people at uh you know single digit to double digit Megs per second we'll probably see pretty good performance here maybe as we grow to 100 100 Megs a second you this is not a feature you'll want but we are looking to figure out how to get this to that point um this first pass is just a great feature Edition that I think everyone's going to be excited about um but in a you know half gigabit of sec I was get gigabit because of networking half gigabyte a second cluster um you might see some slowness here um and we do need don't we need grafana supported as well don't we need grafana to make some changes yes yes they need to pass to new parameters the start and end of basically the time range uh for which you want to search right now okay so we'll probably get them to put that up under a feature flag that way it doesn't just roll out to cloud and make us all sad when people are searching like multiple weeks or something um but that is a good uh that is a good thing to add in the future thank you excellent work Ruben thank you so much uh Mario as well for being diligent and getting all that review done uh [Laughter] yeah for sure um VP par4 PR is up um V par4 is 100% designed to extend what we can do with trace ql and it's to get us into the ability to do lists uh map no we get maps lists uhh what else is in there Marty  I should know this uh events links thank you okay yeah I I I swear that um so yeah V A4 is an a schema like extension to to add support for this like additional Trace ql abilities um we are seeing a performance regression that we're concerned about um the block size goes up 20% now I don't mind that object storage is cheap and I will definitely uh I was 100% fine with 20% total block size increase my concern and the concern that might make it a little bit slower to roll out than three is this footer size at 30% so loading the footer in the quers is kind of like this flat static cost that is you can't outscale basically like we can go down with row group smaller and smaller and we can like make jobs smaller but you always have to load this footer and in any increase to the size of the footer uh just has this like overall holistic increase or uh you know increase in load on the queriers while they're doing the searches so we are concerned about that but we're keeping an eye on it um if you look at the pr there's also a memory increase again we're keeping an eye on it um but this is important for us to move forward with Trace go features we really want to support lists we really want to support events and links and so um like I said this might not go as fast as B Park A3 but we are committed to it and I just wanted everyone to know that it's in the works um uh and we are moving forward with it uh it will be almost certainly I guess we've not merged it yet and there's some discussion internally but we are in agreement to merge it and I think it's going to be in two four experimentals so you know any Community Support to test it out in terms of like how much additional load it or how much you know additional or any latency out of the queries would be great if people want to experiment with v park4 just to give us feedback uh I think it would help us understand impact and help us uh make choices here about how to get B par A4 where it needs to be so we can roll it out because we really want to deliver those Trace ke features um but this is this is I wouldn't say it's a blocker but it is slowing that down a bit we're kind of pumping the brakes a bit on it because of this concerning regression cool all right team I'm glad to see everybody here it is now ask me us I'm G to us there's a whole team here ask us anything well I think I'm G to change it anybody have any questions about what we talked about or Tempo generally or what my favorite hobbies are or whatever You' like nothing I can accept nothing I'm good with it um Mario I have a question for you how long did it it take you to draw that te on your whiteboard actually longer than I than I thought when I started it and I ran out of a marker by the end of it so I don't know maybe 10 minutes it's probably better than than it would have taken me nice appreciate that uh I need you to come to my house and draw me a tea somewhere because I can't do it okay and bring some P so I have some real paa oh yeah I now have a new P sure some pictures tweet somewhere the next please do oh I went to a restaurant in Louisville that claimed to sell paa but their rice was like deep was thick and I was just n it's not p all right we're definitely going to add paa talk to the agenda that's critical yeah this is GNA if this is going into a recording it absolutely will and I think it's critical everyone's GNA come to this YouTube video for all their P facts all right team it was great talking to you all H it's great to see the community again I missed last one oh Andreas has a question what's SP sir yes I have a question from so in in the temp operator the plan to move to a T-shirt size um resourcing scheme like also similar to the Loki operator where you can basically Define you have a small deployment or you have like a mediumsized deployment and [Music] um um so that will come up and we're curious if you could have some guidance for us for example for small deployments um which amount of resources should we allocate and which what should be the number of the replicas be for the components okay no I think that's really it's a good idea and we are actually asking very similar questions more focused around the query path um we want in fact me and SJ are working on this project right now we want right now like in all of our little Cloud clusters where like oh quering is slow let's add 10 queriers and it's just kind of all this spoke Madness so we want t-shirt sizes specifically on the querier path so we can definitely pass that information off like uh for 20 queriers what like a balance of other configurations to as quickly as possible get jobs to your queries for 50 for 100 for 200 kind of up the chain and I think that fits this concept of like medium large small clusters and then the other side of it of course is like what are my Distributors investors these other components look like we can definitely support you on that um um and and like maybe share some internal metrics uh there is of course some play depending on your workload but I think we could definitely get you some baselines to start with um for like maybe like a single- digit megabyte per second cluster double digit megabyte per second triple digit megabyte something like that might be some targets um but uh absolutely let's um I can't really just quote things right now but let's maybe sync on that over the next couple months and see what can give you awesome yeah that would be great and one other question I was just curious if for any reason someone doesn't have access to object storage would the local storage backend work if you have a shared file [Music] system Marty just looked out his window because I'm thinking the same thing like would it [Laughter] I don't know I'm wondering what do you mean like a mounted volume or like a network I don't know someone is using sefs or NFS or something it's probably not ideal but is it very bad and should never be supported or would it well okay so like the ingestor still have to have their own separate scratch space for local blocks so that doesn't change like all we're what we're talking about is just one shared volume for what would be object storage yep um I feel like it would technically work right yeah I can't think of an obvious no right so the answer is maybe but if somebody filed an issue on the repo and they were like I'm doing this and I'm having this very strange error I would probably kind of throw my hands up and say I'm sorry I can't help you like I I can't dig through all this and we never we don't run it this way I would call it unsupported but probably works well actually so one thing that I just remembered is the local storage uh is not optimized so we have like an implementation of the back end for like GCS S3 Azure blob storage and then local files the local files is not optimized very well so it doesn't reuse file handles it opens things like for every read so it's that will probably be kind of like bad performance that was one thing that would jump to mind yeah yeah whereas like the other implementation are real and much more perform and like don't have any edge cases why don't you try it Andreas and tell us what breaks okay I'm trying to think if there's any like semantic differences between like delete in object storage versus delete and file storage and then God you get into like the difference between Windows and Linux like if somebody F an issues like in Windows this stuff breaks I'd probably like I'm sorry technically Tempo runs on Windows but I can't help you here good luck I don't know yeah um Tempo would handle the retention but you're right there was some other there's no like fail safe like there is on the other object storages right yeah I can't I'm really working hard to think of something I would and I can't come up with it mini io on each host in front of NFS I have no idea oh you're uh as an option to like get that S3 compatibility I don't know how far Min I scales with Tempo that's another good question we use it in all our demos we use it for all our local tests and examples and stuff but like I'm I really could not tell you if manio can hit you know the gigabyte of second range or not it's a good question I have no idea if it will work I just know that you can do multi- Noe minio against NFS for Dev type stuff and it does work okay cool thanks Lucas yeah that's true SJ uh always depends on the speed uh we have oversized our discs in Cloud primarily to make sure we have the iops and bandwidth to the because all the cloud providers of course give you um iops and bandwidth based on the size so we use like 10% or less of the total disc maybe less than that um and it's really to make sure we have like good IO to the disc on our adjuster piece cool uh all right team good chatter I will see you all in a month or so and uh yeah check out 24 is it 24 yeah check out 24 uh let us know think keep an eye out for that and I'll see you in a bit by everybody bye folks see bye

