# Grafana Tempo Community Call 2024-09-12

Join our next Tempo community call: ...

Published on 2024-09-16T17:33:15Z

URL: https://www.youtube.com/watch?v=D6sO4ANgweI

Transcript: no it does not it needs to die needs to never ever be looked at Again by a human being needs to do uh yeah so welcome to welcome to Temple Community call whatever month it is September 12th 19 no 2024 not the 1900s anymore sadly the golden years uh but here we are um yeah we have a kind of short agenda we mentioned this in the slack kind of a short agenda but I think a very Critical Agenda we're looking for Community feedback for sure and then at the after that we'll give an opportunity to just kind of an AMA um so kind of maybe think about questions you have do you want to talk about trace ql or operational Tempo or plans for the future or basically anything you want to ask please do and you're welcome to type in chat or you're welcome to um uh you're also welcome to just unmute whatever you feel comfortable with basically anything goes essentially um so let's start with our actual agenda here which is a couple of where am I yeah a couple of architectural changes and it looks like oh pav posted item as well um so two changes that are coming up first of all we are looking at dropping support for serus and we put a uh issue in the repo for this so let me find this issue or I linked it I think it's in the community call yeah maybe yeah is linked so we're looking for Community discussion here what happened was the framework that we built around our Lambda or built our Lambda cus functions around became deprecated by AWS and we have simply just not had the time to go figure it out and to move on to their latest framework and the result of this is It's kind of drug um for us and we have not been able to prove its value and we've decided internally to stop using it to simplify a lot of uh internal like processes as well as our deployment patterns which we have liked and I don't think we've seen a whole a lot of change in perfor or query uh performance and so we're kind of looking at the community to see if anyone um is using these aggressively or a lot they really like them they do see a lot of value here and that's kind of what that issue is for so if anybody wants to mention it here or wants to talk in that issue uh please do and uh follow your thoughts there if nobody feels strongly about this uh we will probably just go ahead andou from the code base and if someone does feel very strongly about this we may rely on the community to kind of help us keep these up to date you know if we're not using them it's hard for us to realize there's issues with them but of course we'd accept PRS to keep it moving forward cool so that's the first one um uh that's the first issue is this uh this serverless thing we're trying to kill the second one we've mentioned a few times and I'll bring it up again um which is we we've actually mentioned a lot in the release notes I believe the blog posts I think I've discussed it for the past two uh Tempo version uh releases in the blog posts but we're looking to um looking to productionize an rf1 architecture for to GA Trace SK met as well as to improve performance um on uh normal Trace search uh the cost of this would be right now we're going to we're looking heavily at a Q based architecture so a q sitting in between your Distributors and your investors which is where we would get our durability guarantees from the que and then the investors would only have to write a single copy of the data to the back end for these performance improvements we do expect nice TCO improvements as well from this change but we added a Q and q's are operational change so this is our second request to the community and perhaps we should start an issue for this uh but I don't know how concerning it is to people to hear uh you might need to run Kafka or any of the many many different like K Kafka API compatible Alternatives right so a lot of clouds have managed kfka there's a lot of other products out there there that support the ca API and do the same things basically and so a lot of these options would be on the table for anyone running open source Tempo we would likely update the helm charts to just kind of deploy a small kopka in there and it would be on you all to manage and operate this new component basically so uh I kind of open the floor to that uh as well uh maybe we should write an issue U Marty can you throw us together a real quick issue for comment on a Q based architecture if you don't mind sure absolutely thank you so we'll get that in the chat and the doc as well so I'll open the floor up uh we would be glad to discuss either those two things uh if there are concerns there or uh yeah I'll open up for AMA generally if people want to talk about um any kind of question about Tempo I'm interested in asking about the Q based architecture um one thing that inti I'm by the way I'm from HubSpot um we've been using for about nine months it's been great so kudos to y'all and the the great work um one of the things that Drew me to Tempo over other architectures was the Simplicity of it and like the fact that the only back end was S3 and like there wasn't a kofka dependency um can you speak to like are you worried about the like operational load increasing um like when you're operating the Enterprise cluster have you have you thought about that like having the kofka dependency or is that not really a concern we have absolutely like it solved some very serious problems for us which is why we're considering it um but I mean us like bringing this to the community is US worrying about essentially it it working for everyone else you mentioned the Enterprise you all on Enterprise Tempo or are you all using open source Tempo we're on open source Okay cool so um I kind of don't know I've operated Kafka but not at extreme loads I've operated at the like 10,000 or so items per second range and we would need to push this into the millions of items per second range for our largest clusters and I think for our community's largest clusters um I I feel like I guess I don't know what the pricing looks like on cloud my in my mind it's it's always kind of like people running big architectures um will have this option of paying for manage Kafka from their cloud and I believe overall they will see a TCO decrease even with that because of how much less data we'll store how much less data will scan and it'll also come with a nice performance boost I don't know that this is true though I can't prove it but it's kind of been my thought or at least a wash perhaps um but yes that is a concern and we have talked about other ideas um and it's possible it's likely our first pass would just use kopka for Speed just to get this done because we need it but um we have considered other kind of Q based architectures that don't require kfka um maybe uh you could do a que on disk for instance the Distributors and this might meet a lot of people's needs uh who aren't you know running it like we are where we're selling it as a product uh and meet your durability needs um without requiring like an external Q can you point me to any resources about the like benefits that you've seen so far of shifting is there like anything the slack or GitHub about that uh I don't think I can maybe in this uh issue that Marty just posted be a good place for us to start accumulating some of that knowledge so one of the primary drivers here is uh Trace SKU metrics are currently kind of best effort because they are based on an rf1 architecture um and we want to make them GA we want to have them give them the same durability guarantees that Trace search CHS uh and that requires us to find a way to productionize rf1 and this qbase pattern is kind of the path we've decided to take um and then of course we will you'll be searching significantly less dat on Trace ql search so you'd see like performance improvements there as well uh so that is why we are going with this direction as well as in our largest clusters we expect a serious tcco Improvement because just running few inors is one of our most costly components running fewer ingestor uh running fewer compactors uh significantly fewer compactors I think maybe even no compactors there's possibly a compactor lless future for Tempo with rf1 so I think these things are what catch our eye um and then we just feel like with some confidence we'll be able to operate um Kofa uh having said that we recognize not everyone wants to do that that not everyone wants to operate Kaa and wants to um uh and wants to take on this burden of this new new Tool basically Loki is looking at a similar change where they do not use cop so we are kind of eyeballing that mimir has made a similar change where they are using cka so we're all kind of moving this direction sharing ideas and I think there's a lot of um different paths we can take here uh like I said though I do think the very first push will be a q-based ctha style architecture and maybe we look into ways to relieve that for those people who don't want to run that thanks Joe cool thank you I appreciate the questions and it's awesome to hear you're using Tempo and I recognize I resonate with what you said at first you were drawn to Tempo because it's oh I only have one dependency object storage and we recognize that a lot of people feel that way and that's why we're trying to have a good discussion here about this change I do see a couple questions in a chat I have a simple question do I need to enable some config in order to use event. exception. attributes or whatever so doing event based uh search which was added in in um 2.6 uh the only thing you need or the only kind of restriction here once you're on 2.6 is it can only occur on um B Park 4 blocks so when you first roll out 2.6 you probably have all V Park a 3 blocks if you're using defaults and you'll start Temple will start creating V Park four four blocks but your retention your history will be mainly V Park A3 and they'll slowly fall out of retention so um the exception search uh or the links the arrays and the events uh searching is all dependent on B Park A4 so basically those queries will only work on your recent data until we phase out the V Park A3 blocks because they fall out of retention and then those queries will work across your entire retention so um you don't have to change anything but you do just have to be patient to query your entire retention as the B Park A3 blocks disappear essentially and Marty is asking to find me and a turkey hat from the AI assistant which is is totally useless and then uh okay thank you for the links and Sir sergy apologize if I if I messed up your name what's your initial estimation regards to the timelines for the Kaa qbas architecture in the one two three how many releases I think oh Mario Marty do you want to take a step that one in this yeah Mario and I are actually we've been talking about that this week um I mean I don't have a great answer but it there's more once we there's more that we can do than just introducing the Q like once we have the que and things are rf1 it actually lets us do a lot more with Tempo so the entire kind of like things that we want to accomplish is further that's like a year something like that um we're going to try to do it in small steps that makes sense for backwards compatibility transition and migration it's not going to be something like um you install a release and everything's broken right like that's what want to avoid so um yeah I don't really have an estimation so I mean probably not this next release maybe the one after you we might start seeing some of this co uh that's about what I was going to say I was going to guess a couple quarters and we do about One release a quarter so expect to see changes um in a couple quarters um any is there some overall alignment between the lgtm move all there is I don't think there's at at grafana we generally operate uh heavily independently on purpose we all attempt to move as quickly as possible um for obvious reasons uh but we also work hard to share knowledge and information so we are all of the backends are moving to rf1 Stell architectures for very similar reasons to the ones we have um uh and we are all sharing information and looking at similar um looking at similar or or considering similar solutions to this problem so while we are moving independently because we have all have slightly different needs Loki Tempo mamir pyroscope all have different demands on their databases uh larger or smaller communities larger or smaller uh Cloud offerings uh other kind of like just simple demands of the signal itself and how it's queried propagated through the system so we all are free to move do what we want here but we are all kind of doing the same thing at the same time too so there's a lot of knowledge sharing um internally uh there's we are looking at both mamir which is gone strongly to this Q based kopka as well as Loki which is kind of considering kind of like a Q and object storage kind of idea um so there's there's different learnings internally and we're looking around to see what we intend to do and we'll execute that I think in the next couple quarters yeah next couple releases native history there we go uh Zack do you want to talk to that at all you did a lot of work on this yeah they're pretty exciting I'm glad to hear somebody's using them yeah thanks for that um one thing we don't have a lot of right now is internal adoption so we're going to be working on that over the next um few months few quarters and um so yeah anything you want to report about it feel free file issues send us uh send us PRS if there's improvements we should make so thanks for the shout out cool yeah that was one of the uh more exciting 26 um features we had some good tql features in there the native histograms both in the metrics generator as well as the ones that Tempo itself produces um we're both fantastic so nice polling improvements performance improvements uh there's always performance improvements we're always trying to do better there for sure okay team any other questions again feel free to type in chat or unmute whatever whatever floats your vote so the issue I created I kind of just threw up quickly um we We'll add more information there like pros cons more details yeah cool I have another question um how do you think of like what's your preferred way to receive support requests or like issue bug reports like is this do you think of the slack Channel as more like people helping like other like open source Community Helping other people and prefer like the TTL of GitHub because it is persistent longer than 90 days for like more bug report stuff or how do you think about that yeah I think you you hit on some of the important things right so uh slack I think is great for informal discussion um and for the community helping each other with like I just started I'm trying to figure this out can you point to some basic ideas help that kind of thing uh for if you're seeing like uh some actual issue or looking for help with tuning then yeah GitHub issue is better you're right it archives it longer makes it searchable findable for other folks um so we do prefer that uh GitHub discussions sometimes people throw those in if it's not quite an issue like nothing's broken but they're maybe just looking for help to understand some element of tempo the GitHub discussions work pretty well uh and then we also have a forum but I don't know if anybody really participates on the Forum I apologize for that we are stretched pretty thin between GitHub tracking GitHub issues as well as slack and doing our best to respond to folks in those two channels um so yeah I think you're on on the you're on the or you got the right idea in terms of where to post the right kinds of questions okay sweet you'll I'll post something I get help later this week maybe I think sure we do our best to answer um the more details you can give helps a lot sometimes I people post like it doesn't work and I'm like what doesn't work I don't know what to tell you here here's some links to talks uh so yeah any you know any kind of additional help like screenshots um details logs metrics all all the stuff any research you can do will help me in the team answer your questions quickly as possible sweet thanks very cool oh we got another question I think Zach can probably help with this uh histogram question Zack are you up for that one yeah I was just finding docks oh somebody beat me to it okay cool um yeah so that's that's everything you need to do we have an override uh we can produce um classic histograms we're calling them we could do Native histograms and we can do both um the both is there for a transition period so it will be more expensive slightly but uh you probably won't even notice it to be honest with you and then as soon as you make the transition in your dashboards um there's a visualization dock I'll paste here in just a sec and that will um show you what queries to update in your dashboards and then once you make that transition then you can stop using both and you can just migrate to Native uh directly and that should satisfy what you're [Music] after cool uh so anything else uh I I you you can what are Hobbies what are our favorite silly hats apparently that's a thing at grafana I don't know how that happened uh I guess other things to talk about I'll be both in obson in New York which is coming up and probably at cucon so if any the na cuon coming up in November so anyone uh from the community who's at either of these events please find me stop by we'll chat some i' be glad to I'd love to hear what you're doing with Tempo and help out with anything I can cool all right on that note I'd say keep an eye on the issue Marty posted himself and Mario will that's a great question we him Mario and himself will do a good job of keeping that updated as we have some new findings some thoughts maybe some paths that are query or qess I'm not sure I will be honest and say our primary motivation is to um meet our needs of reducing TCO and gaing TR skill metrics and improving TR skill performance uh but we are absolutely listening to the community and looking for pass for you all as well uh when will the trace's appy released OSS man is it this week I don't know if I should say that is it next week Kim next week don't tell anybody it's a secret but I think it's next week uh it's I think it's the week before the event Kim do you might you probably know better than I do you have the do you know the schedule I think it's next week okay so next week I think we're open sourcing it and the week after that we're doing like the big observability con you know demo promotion like announcement kind of thing so you should see if once the repo appears I'll absolutely check it in the community slack I'll throw it that Tempo slack so people can give it a shot we would love some feedback on it we spend a lot of time on it um it needs everything and it does everything at the same time I feel like some days it's amazingly powerful but there's just enormous amount of work to just improve improve improve so all the uh feedback from the community would be greatly apprecia is app with traces that does mean traces explore that's correct I'm very excited about this because I think it shows off a lot of the features in Tempo that are difficult to find without being kind of like a trace qql Master a lot of folks um you know get intimidated when they see language 100% understand uh it's hard to just walk into a new language and realize all its capabilities and I think this app shows you that a little bit like I can do all this with Tempo maybe I can go learn some Trace ql too and I can both learn through the app and improve my ability to query directly and yes trac's explore is very exciting uh the last two Community calls have demos two maybe three last two you can see the progression there and then yeah next week fingers crossed it will be released and in two weeks if you're you're in New York come find me I will be uh demoing live live demo uh in front of too many people I'm sure cool anything else this has been a fantastic call I appreciate the questions appreciate everybody uh you know jumping in here and asking good good hard questions about this uh transition we're making to the Q architecture we want to hear you and we'll get that uh we'll get that issue rolling so we make sure everybody gets a voice all right everybody uh enjoy your all's day uh take care and it was a fantastic we'll see you the next time bye everybody bye folks oh hey there's one more uh yeah hey we can uh we can chat about that actually this is something that I could help you with um so the generator replicas are only for the recent data they serve metrics queries for the past 30 minutes whatever you're configur for um if you want to scale it performance beyond that it's actually on the queriers uh but other things look at are just general query performance so look at the paret dedicated columns um look at any flush sizes things like that these are details that we can dig in on the slack in the community slack if you want to ping me there we can dig into those there too cool okay cool all right thanks bye yeah there was one final question about metrics but we kind of uh talked about that a little bit and we we'll catch up in the community like for any more details but I think we're good you all jump back in okay bye e

