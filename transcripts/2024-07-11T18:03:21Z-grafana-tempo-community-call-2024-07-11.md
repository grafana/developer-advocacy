# Grafana Tempo Community call 2024-07-11

Join our next Grafan community call: ...

Published on 2024-07-11T18:03:21Z

URL: https://www.youtube.com/watch?v=xsmlok1VDIA

Transcript: all right welcome to what are we on July 2024 uh July 2024 Tempo Community call um we have some honestly I think quite exciting things to discuss today as well as we broke Helm for a bit uh and then some exciting things so we're going to talk about some new Trace ql editions they'll be in Tempo 2.6 spam's going to walk us through those she's done most of them and and uh they are also enabled by our new park4 format and we have some nice support for some otel uh features that we did not have support for before uh We've added some dat of histograms and you is gonna review that I think the pr is up maybe merged I'm not sure uh he's going to walk us through the changes there so metric jator will be able to make Native history is cool then we'll talk about Helm because Helm was broken briefly and everybody loves helm and then finally uh we have an explore app a tracing app a query list tracing experience we're working on on top of tempo it is somewhat unannounced it's super secret so keep it under your hat and we'll give you a quick preview here and let you see some of the things where where we are working on internally so with that I will open the floor to fam Jenny fam who has some cool things to show hello everyone I am here to demonstrate the new ability that we have to search for links and vets inance that we did not have before um so we have a couple of new Trace ql syntax uh to search for an event um we simply type the word event and the in that we have for events are just can't see your screen classic classic screen sharing mistake well done I is ready to go all right can you see my screen now yep cool and that's not the right language sorry one second we go event name I think in my test environment the only one right now is under my name uh oh oh sorry my mistake as intrinsics it should be a colon not a DOT here we go well this I some events here and this is searching via the name intrinsics and we also have the ability to search for events attributes um unfortunately I think I made a typ here earlier there missing a se but I [Music] think just done this my computer freezing [Music] up cool and then we just found this fan in this event that has um a partial match exception message with index cool so intrinsic name and custom attributes and I think a common one is exception message uh I guess you had it spelled wrong in your yep all good not sure why that didn't return I don't know is that a issue with the demo maybe like the local Docker compos it tends to very aggressively kill traces when it makes them oh yeah my doctor is over board right now sure and screen sharing uh we also have searching for links which again we use the types of Link what is see I think I use relationship as my custom attribute oh I think your screen is frozen perhaps uh not seeing change I my computer is using it to much memory see I will close and do it again I think usually works [Music] okay so here is link can you see it now yep link relationship attributes go found this nice link um Thebes we are um going to make some changes to the UI to support um L events right now it's called reference here but it's actually link cool and that's it for me all right uh any update on arrays I think that's maybe some of the last features we're trying to get from Motel yep um we have arrays um we have a PR for arrays that I've linked in the uh Community call Doc and we also have a a ticket for adding instrumentation scope that we will work on very soon oh yeah instrumentation scope I forgot about that one scope scope my favorite SC okay uh very cool so link attributes and can you do link like Trace ID or link. span ID you can also do link. Trace ID link span ID it uses the hex um as the U input so this is features we scoped out last fall and really have struggled to get to in the past few months both uh Jenny fam and Adrien Stow have gotten a lot of progress there uh and have done a great job um getting some momentum behind this and in two six we will have these features available uh and then you also noticed grafana had some squiggly lines wasn't sure what to do with some of that so we need some support in grafana as well the queries will work but for you know ease of use and these things uh we'll make sure they're supported in gra as well so very excited about that a lot of people want to query on these kind of inodes these kind of features in myself included so we'll be able to do some neat stuff with that in the near future cool uh if there are any questions you're more than welcome to type in chat you're welcome to unmute and ask uh we'll also I'll prompt you probably after each section here everyone's welcome to talk or you welcome to drop them in in the middle while we're talking presenting uh and then at the end of course we'll take questions as well so feel free to let us know or let us know if you have any any questions or thoughts all right thanks Jenn I appreciate that great work next up we have youa with some native histogram support uh which is a neish I think still experimental in Prometheus is that true feature and we are adding support in the metrix generator for these um yeah so the metrix generator um currently outputs uh counters and and like the classic histograms of the the fixed buckets we're adding support for Native histograms which has um just like a a lot more fine grained buckets which allows you to see like way more um just a lot better resolution it is experimental in pricious you have to enable a feature toggle for it so it's kind of like the Exemplar storage is also a feature you have to toggle um I'm not entirely sure like how experimental this but I mean seems to work fine um and it's also supported by miman and Cloud um basically what we're doing right now is adding we're adding support for generating native histograms next to the existing implementation and you can toggle between them using an override uh named yeah L I mentioned it here metric generator Point um generate native histograms and you can pick between you know only generate the classic ones to the original ones generate both of them side by side or only generate the native ones um we're doing this because native his s have to be quered differently so it will break existing dashboards and queries you rely on um but by generating both you can gradually switch them over um and yeah I think this will be really cool because when we measure span like when we make metrics from spans we have very diverse data right like a span duration can be very short or very long I still want to have good resolution on it so having fixed buckets for it for it was was kind of a pain with Native histograms you can really you know zoom in on it and like have like really good resolution um kind of dynamically um if you try this out feel free to reach out to us via slack we' be happy to hear you know how it goes we're also still like improving it a lot so expect changes in the next few weeks as well uh yeah this was literally just merged I think is that true yeah okay so right it's it's very much a work in progress something we're experimenting with internally and right I think for 26 we hope to have a pretty strong implementation but it's basically just freshly merged to tip of main at the moment right very cool yeah I think U especially like um for like bigger um tenants will have to see how it performs um hiker and all these years that kind of stuff yep yeah a lot of questions open I suppose but we will navigate that and figure it out and then I think anyone who is aware of native histograms will be excited about right the increased resolution um I guess I'm not totally sure about the technology is it the same number of series is it fewer series how does that work um honestly it's something we still have to um kind of figure out and get a clear picture on it um have to like consult with our pricious maintainers in turn we already asked a bit about it but it's just kind of different instead of sending um series like you're doing with the classic histograms you're sending a series for every bucket um it's actually not really serious but you're sending um a bunch of spans which is kind of confusing not tra spans but spans um from a native histogram and they um kind of say like oh yeah this bucket is this white has this value and then like you have the spans indicating the buckets and then you can also have a span indic get yeah skip this amount of buckets like just not send any data um and that's sent through a protuff format so it's not a text format anymore um yeah I think in term like active series it's not always going to be lower but it's going to be more fine grained and we kind of have to like still figure out the formula of you know how many active series does this actually generate what's the impact on prous but it's kind of I think it's also something they're figureing with gra Cloud still so very cool we should have more clarity about that soonish cool very cool um I think we're pretty excited about this one for sure uh Native histograms I think we've had some Community requests we've had some internal requests as well graffan as a whole is moving to these they're just a better technology than the old histograms for sure and we excited to write and not have loger arthic buckets or linear buckets or worry about any of that instead you just get solid solid quantile data cool all right thank you uh if there's any questions about that yeah feel free to yell in fact I should open up the chat in case people have been asking questions I think I have it open H there we go uh Helm charts a lot of people use Helm charts this is a pretty quick announce nothing super exciting here but we did break them pretty badly uh and so I want to make sure people are aware of that 1130 we a Community member PR support for as zware replication and accidentally dropped in the ingestor stateful set which in Tempo is somewhat critical for doing basically everything um so a new installed the helm chart or an upgrade with I'm not sure an upgrade would drop I don't know the exact details but basically we were no longer creating the stateful set um and then in 132 we fixed it so if you are upgrading your Helm chart if you're looking at some of these versions definitely keep an eye out for 113 if you see something bizarre if you see your inors go away or something or you try to install that's absolutely broken 132 is the correct version and of course going forward we hope not to break that one we can very cool all right and then finally we're going to look a little bit at uh this query list tracing experience um like I said this is internal at the moment but I thought it was a good group to give a real quick sneak peek to um um I think we were going to roll a private preview out to a few customers in Cloud then a public preview and then do a big announce in a couple months so expect to see like an open- Source version of this as well as an announcement soon but I wanted to show you all it's it's a bit rough at the moment uh we have a lot to do but we've also made a lot of progress and it's at the point where I think conceptually the major pieces are here and what we're going for so this is a good group to get some feedback from get some thoughts from see what people um just think about our approach to taking tracing data and turning that into some higher level analytic view where we can find issues very quickly instead of looking at individual traces writing Trace Fel queries to find traces we can instead uh look at a holistic view of what this data tells us and hopefully quickly identify issues that are occurr so this is the first screen um and you can see this is all or you can't see but this is all tracing data this is queries that go directly Tempo and this is all based on the trace metrics work we've been hard at work on and is improving each release uh we can see here we can zoom in on a couple of different um ways to aggregate our traces so this is rates and you can see it rates both errors and successes so the Green's happy the red is sad you can see like a little uh some errors on this surface and then otherwise pretty good uh you can look at errors only so this particular I mean this is all simp synthetic data just to be clear this particular service is having issues over here um we can look at the duration we have a heat map up here and we can see quantal P90 down here uh we can see latency for individual traces in our applications broken down in this case by servicing so this allows us to kind of at an overview at a holistic level get a sense of what's happening in our environments and um hopefully Identify some issues and jump in so let's do that I suppose let's look get something we'll take this duration one um notice this full traces we have a couple options up here but we're looking at basically the root span the entire Trace as one at the moment so I can click uh analyze um and I can see again I can break down now by resource and span name and I have my nice or heat map up here that's showing where the traces are landing so I could for instance look at spam name uh we could look at well group name and span name are going to be the same status code doesn't have that one status message we can break it down by any span level attribute um but I think we do need to do a better job of uh only having perhaps ones up here that are available uh but we also have the ability if you were to select a section um to break down by all attributes and we can see clearly now um in the Box out of the box kind of fit functionality uh we can see like uh the car so span. vehicle is is an attribute and we can see that the value car is kind of more heavily in the Box to know so the gray outside the selection is uh inside the box and so this is showing us real quick that um between these two values this one is um excuse me this is the this is the uh sorry this one is more occurring more frequently in the Box we can also see that whatever bike is is only outside the box so we're pretty happy with that bike is lower durations and we can see this value looks like scooter here is kind of split between the two but still almost entirely outside the box so probably fine and this might allow us to look more closely we can add car to filter since we have a sense this might be a problem um we can jump to in a second we can jump to individual traces now and maybe use this as a starting off point to do some investigation and determine why this car attribute is associated with um with my high latency issues um yeah so kind of a way to go about given a a trace uh at the root looking at duration we can draw this box we can see inside outside the box and Visually quickly determine um uh maybe what attributes are correlating with my problem uh now Trace data uh one of the neat things about Trace data is it's highly annotated and structured and it covers all kinds of elements of our system right so it covers cache accesses and database accesses and so we looked at full traces a second ago but we can also look at specific things like database calls so I can see here the rate of database calls across my services and the rate of Errors let's go to errors this time perhaps so this service called the mythical server um is erroring like about one a second or so so we can go dig into that perhaps um and similar to before we can click this investigate button um and it's going to show us again inside there's no box here but it's showing us like things that are in error things that uh are correlated with the error versus things that are not correlated with the error and so we can see like okay there's an error here uh it seems to be with my inserts I have my statements or this is like my this is span name we see span name we can see the select is always uh fine the delete is always fine and the insert is a mix and the insert occasionally is um succe or failing we see a lot of failures here so again it's kind of a visual quick way to scan um and see what is going on uh since the statement itself is a value an span attribute we can also see here like uh inserts are failing we can see it actually seems to be across most inserts we can selects are always succeeding this particular insert insert into fastach is always failing insert into payment always failing so maybe we want to dig into these specifically or these inserts also uh we can use this information to write to uh analyze our errors on our dat basis from our traces and go um maybe find what the problems are I'm going to show one more feature uh and then maybe talk about next steps a little bit the final feature that I I think is cool let me let me go back here to the beginning so I'm going to look at full Trace errors again I'm going to look at this thing this is errors at the root level essentially and this structural tab I'm excited about it needs some work everything needs to work this is very raw experience at the moment but this tab will show us the hierarchical errors uh that we're finding here so we can see this span name mythal requester requester uh is the rout uh we can see we're calling something called post ENT point and we can see these inserts are failing so this is showing us the hierarchical errors down the chain of our traces so we can again quickly identify from root we have errors at the root we can see down the chain structurally where those errors are originating from uh and in this case it's that insert which kind of backs up what we were seeing before um we need some links here badly I really want to jump immediately of course from here to a trace but I can't and I'm going to go back to this spans Tab and we will of course add that soon enough and we can see here here's an actual Trace here's my requester like we saw here's my post endpoint like we saw and here's my errors like we saw so it's helping showing me the hierarchical relationships of the errors so I can quickly identify from this route um dig down a tree a bit automatically for me and I'll see oh maybe this database is having errors or maybe that uh particular service or Cache or dis or any of the million things that can go wrong uh in our services very cool so the goal here uh is to provide a query way to explore the data that comes out of our traces uh we wanted to focus on uh an experience that showed you issues instead of showing you traces so we wanted to show problems find errors find high latency find you know use that investigate tab to correlate uh find the applications are having issues and high latency and then from there once you've identified and narrowed down maybe at that point jump into an actual trace and begin an investigation on an individual trace or maybe a log signal or some other signal from there to help us understand why this issue is a PR all right so like I said keep it under your hat please super Seeker um this is where we are now uh we really want a couple more iterations on this we want get some internal feedback and uh we should open source this we're hoping in the next uh quarter or so in a couple months don't quote Mone on me on any timelin it's just uh but we will be open sourcing this somewhat soon I think cool any questions about the the traces app and then of course questions or comments thoughts about anything in the community call uh welcome as well knowing which Dimensions I agree completely um knowing which Dimensions to search for in a free form way will be a game changer I agree with this so to to look kind here if we go to my errors here right uh even in this app it's kind of apparent how much uh better it is to just show that big view I'm in here and I'm like I don't know I'm clicking on all my attributes I'm trying to find maybe something where I can see you know uh maybe a specific service or clusters having errors the other ones not being able to just say well I don't know just look at a bunch of things is very very cool um we're this view is a little rough to me it's still a bit unclear I think the team has done an amazing job it's come so far but I think there's room for improvement here in terms of taking this to the next level so it's a little bit more um clear from this area where to go next but I do like how this is breaking down a lot of attributes at once like Nest sent fa this should not even be there I don't even know what resource. blank is do we have a empty attribute somewhere that's interesting uh we have some clean up to do here for sure um but we will uh we will get that for sure we'll get it cleaned up and we'll get get it we'll get it in your all hands oh here's a good one so the errors completely correlate with the status code error and completely fail to correlate the status okay that's not very useful same here status unset happy status Air s um similar to a data dog experience oh cool I've not really messed with data dog's tracing product um uh I don't really know what they do over there uh we are very happy to offer this of course and trying to really build towards that you know user experience with a lot of value delivered with the least effort while also maintaining like you know a lot of power users love tql I love tql we want to keep that experience you'll this original Explorer still exists those people who want to write complicated queries still have that ability uh everyone else who doesn't who just wants to click things and see immediate uh information which I do too also quite often want to just click things and not write a query uh this experience will provide that for [Music] them cool all right any other questions thoughts um concerns favorite colors exciting weekend plans fantastic all right I appreciate you all being here uh shown up for the community call we will be back in a month and uh we'll have some new new uh information then of course we'll probably building towards 2.6 we won't have it out in a month but I think we'll be in the run up to 26 in a month so we'll have maybe some discussions then about what will be in 26 and you can expect to see some about we shown today in 26 so everybody have a great day and a great week great month and I will see you in August take care

