# Grafana &amp; Friends Stockholm meetup at 0+X

Published on 2025-09-22T18:28:06Z

## Description

See: https://www.meetup.com/grafana-friends-stockholm/events/310206379 Agenda 17:30 Open doors & introductions 18:00 ...

URL: https://www.youtube.com/watch?v=mbP_4QvyXvY

## Summary

The video features a meetup event titled "Grafana and Friends" held in Stockholm, hosted by Mustafa, Marco, and Mariel from the company 0 plus X. The event included two main presentations: one by Ahmed on real-time Kafka visualization using a Grafana plugin, and another by Tobias discussing the innovative integration of music data with Grafana. Ahmed shared insights into the Kafka plugin he developed, which allows for live monitoring of Kafka topics directly in Grafana without needing intermediate storage, highlighting its capabilities for real-time data streams and various data formats. Tobias showcased a hackathon project involving a MIDI input data source, demonstrating how musical data could be visualized in Grafana, envisioning future possibilities for music production within the platform. Both presentations sparked discussions about plugin development and the innovative use of Grafana for diverse applications, including music visualization.

# Grafana and Friends Event - Stockholm Transcript

Welcome to the Grafana and Friends event in Stockholm! I guess you already know the date, so I don't have to spell it out. A big thank you to 0 plus X for organizing this event. My name is Mustafa, and I'm here with my colleague Mariel from Salah and my lovely colleague from Salah. We are excited to have a great meetup and discuss some interesting topics.

Before we get started, I want to remind everyone about our **code of conduct**: if you see something, say something. We are all adults here, so let’s keep things respectful.

From myself and the team at 0 plus X, I extend a very warm welcome to the Grafana and Friends meetup. A big thanks to Ian and Grafana Stockholm for supporting this initiative. My name is Marco, and I work alongside Mustafa. I am a talent and consultant manager at the company. 

To give you a bit of background about 0 plus X, we've been in the market for quite a few years now and have a strong legacy. Our team consists of software engineers from around the world, and we have worked with big companies but also with midsize and smaller ones. Notable names we have collaborated with include Apple, Spotify, Clara, Visa, PayPal, and big gaming studios like Dice and Mojang.

If you have any initiatives like this one with Grafana for a meetup or tech talk, please reach out to us on LinkedIn. We are always happy to meet new people and discuss ideas. 

My colleague Ben, who is in charge of organizing this event, will be recording for our internal archive, and I will be taking some photos. If you feel uncomfortable being recorded, please let me know.

### Agenda
Now, moving on to the actual program for tonight, we have two really interesting talks lined up. **Hammed** will talk about real-time Kafka visualization and the Grafana plugin he worked on, which simplifies visualizations without using any intermediate storage or external services. Then **Tobias** will present a unique experiment combining music and data streaming.

After the talks, I am looking forward to mingling with all of you over food and drinks. 

With that being said, I wish you a nice and enjoyable evening, and I’m glad to have you all here.

---

## Presentation on Real-Time Visualization with Kafka Data Source Plugin

Hello everyone! This presentation will introduce you to real-time visualization using the Kafka data source plugin. First, I will share a bit about my background and the journey I had in developing plugins for Grafana. We will look at the Kafka plugin development, its architecture, and how it works. Finally, I'll discuss future developments for this plugin.

My name is Hammed. I started my career as a data scientist, primarily working on NLP tasks and modules for social media monitoring. I later transitioned into data engineering, and now I work as a data engineer at OX. Previously, I worked at Snap, a super application and ride-hailing company in the Middle East, similar to Uber.

In my spare time, I develop open-source projects for Grafana and Kubernetes. 

### Grafana Plugins Overview

Let’s start by discussing the types of plugins available in Grafana:

1. **Panel Plugins**: These are front-end plugins requiring TypeScript development. Examples include time series gauges, pie charts, and donut charts.
   
2. **Data Source Plugins**: These plugins have both front-end (TypeScript) and back-end (Golang) components. They connect Grafana to various databases and technologies, such as Snowflake, Elasticsearch, and MongoDB.

3. **App Plugins**: These are more extensive plugins that offer greater functionality and can support other back-end languages. An example is the Kubernetes app plugin.

My first plugin was developed in 2021—the Node Graph Panel plugin. Grafana had released a panel plugin for node graphs, but there was no open-source data source available to display graphs. So, I decided to develop a data source plugin to fill that gap.

### Kafka Plugin Development

Now, let’s talk about the Kafka plugin. For those unfamiliar with Apache Kafka, it is a distributed, fault-tolerant, scalable message broker system. It is extensively used for high-throughput, event-driven applications.

In terms of architecture, Kafka has producers, brokers, and consumers. Before version 3, you had to use ZooKeeper, but now you can use Kafka independently.

The core use case for the Kafka plugin in Grafana is to visualize Kafka metrics. However, we faced challenges in displaying messages within Grafana. I reached out to the Grafana team, and with their support, I developed the Kafka data source plugin.

### Features of the Kafka Plugin

The plugin features real-time monitoring of Kafka topics using streaming. You can query specific partitions, utilize advanced JSON support, and have options for offset management. Additionally, it supports various authentication methods.

During the demo, I will show you how to configure the Kafka data source, view messages in Grafana, and visualize real-time metrics such as memory load and CPU load.

### Future Works

Looking ahead, we plan to support more complex formats, data querying, and alerting on Kafka data. We are also working on adding support for Protocol Buffers and additional authentication methods.

Now, let’s see a demo of the Kafka plugin in action!

---

### Live Demo

In this demo, I will produce messages into a specific Kafka topic and visualize them in Grafana. First, I will show you how to configure the Kafka data source by entering the bootstrap server URLs and client details.

Once configured, we can explore the topic data and visualize it using Grafana panels. You will see live data reflecting memory usage, CPU load, and other metrics.

Thank you for your attention, and I look forward to your questions!

---

## Presentation on Music and Data Streaming

Now, let’s transition to our second presentation. This project was developed during a hackathon and involves using Grafana for music data streaming. 

Using RxJS and the Web Media API, we created a basic plugin that allows us to mix piano and drum sounds. The idea is to explore how we can use Grafana to visualize and manipulate music data.

### Understanding the Data

We will discuss how we receive streaming data from MIDI keyboards. The MIDI format, which stands for Musical Instrument Digital Interface, allows us to capture various musical inputs that we can visualize in Grafana.

### Live Demo

I will demonstrate how we can visualize MIDI input data in Grafana. I will set up a dashboard to show how we can track note velocity and status through a state timeline panel.

As we proceed, I’ll also show you how to visualize microphone input, transforming sound data into a frequency spectrum.

### Conclusion

This project is still in its early stages, but it showcases the potential of integrating music production with Grafana. I hope it inspires you to think about creative use cases for Grafana.

Thank you for your time! If you have any questions, feel free to ask!

---

## Q&A Session

Now, we’ll open the floor for questions. 

**Audience Member**: Is the repository for the music plugin public?
- **Presenter**: No, it’s not public yet, but we are considering making it available.

If there are no further questions, feel free to come and chat with us during the food and drinks session. Thank you all for being here!

## Raw YouTube Transcript

Welcome to the Graphana and Friends event in Stockholm. I guess you already know the date so I don't have to spell it out. Thanks to 0 plus X for organizing events. Thank you. Um I'm Mustafa together with Mariel and I from Spain, Mariel from Salah and my lovely colleague from Salah. We are going to have a good meet up and talk about this thing. So, uh, I guess I mean we're all grown-ups, but if you see something, say something. Code of conduct. Y elseh. I just already thanked you, so you don't have to. All right. So, uh, from myself and the team at 0 plus X, very warm welcome to the Grafana and Friends meetup. A big thanks to Ian and Grafana Stockholm as Mustafa said for supporting this initiative. My name is Marco as next to Mustafa I was standing. I am a talent and consultant manager in the company here. To tell you a bit about about OX, we've been on the market for quite a few years now and have a strong legacy and from our team which consists of people software engineers from all around the world. We managed to work with big companies in the market but also midsize smaller ones some uh notable names I would say it's uh definitely Apple Spotify Clara Visa PayPal big gaming studios like Dice Mojang and definitely my recommendation if you have some initiative like this one with graphana for a meetup or some smaller tech talk we do some mentorships as well and also have some open positions so reach out to us on LinkedIn we're always uh happy to meet new people and discuss ideas in terms of the bit technicality. So my colleague Ben who is in charge of organizing all this thank you Ben is going to record for our internal archive mostly and I'm going to take some photos. So if you are not feeling comfortable just let me know so I'm aware during the evening. With that being said so going to the the actual program tonight we have two really interesting talks. Our hammed will talk about real realtime Kafka visualization and graphana is the plug-in he worked on which simplifies the visualizations without using any intermediate storage or some external services and then Tobias brought his piano with him at least a medi version so music and data streaming you will you will see some very interesting uh experiment there so yeah of course afterwards I'm looking forward to meeting you better uh at the food and drinks Mingo time. Um so yeah uh to leave the floor tomed I wish you a nice and enjoyable evening and uh thank you glad to have you here. This is a presentation for having real-time visualization with Kafka data source plug-in and uh in this presentation first of course we are going you are going to get more acquainted with me and then the journey that I had for developing plugins for Graphana and uh then we were looking to the Kofka plug-in development it architecture and of course how it works how it can helps uh the users the users of graphana who are willing to have data of gra of Kofka into graphana and then finally the future works that we have in mind for this plug-in. So I'm hmed. I started my career as a data scientist. I was mainly working on uh NLP tasks and NLP modules for social media monitoring. Then I gradually were into transition into data engineering. So I'm a data engineer uh at OX. Previously about two or three years I was as a snap. Snap is a super application and right hailing company just something like Uber in the Middle East which is the one of the biggest uh companies in Middle East and so of course on my spare time I would uh develop open source projects for Graphana or Kubernetes. So let's see about the journey. So first we will talk about the plugins of Graphana. So Graphana has different kind of plugins. One sort of plugins is the panel plugins. So the panel plugins are the plugins that are mainly in the front end. So you will have to work with typoscript if you want to develop such such such plugins and if you have seen time series gauges pie charts donut chart all those charts those are actually the panel plugins and we have of course bunch of developers that are working on these kind of plugins. The other kind of plug-in is data source plugins. So data source plugins are the kind of plugins that besides front end which is of course typoscript they have backend too which is golang. So these kind of plugins are the main layer that graphon use to the graphana uses for making connection to databases or different technologies. So for example, primitives, snowflake, elastic search, MongoDB, all these actual tools that you have utilizing graphana, they are using data source plugins that might be developed by graphana labs itself or by the organization or by the community. And the third kind of plug-in is the app plug-in. So app plug-in is something more extensive that actually you can use maybe than other nested plugins and you can have more actually operability and more actually you can you can have uh have more uses for these kind of plugins and if I can mention some sort of these plugins is Kubernetes app plugin, look app plugin, radius app plugin and the good news in these plugins is that even you can use other backends in other languages and uh one One of them actually I can mention is graph on call which the main back end is in python and uh I started my first plugin uh which I developed in back in 2021 and it was the node graph panel plugin. So the thing was that uh graphana had released the panel plug-in for node graph that you could have graphs and show graph in the in the graphana and that was really amazing but the problem was that there was no data source I mean open source data source for this kind of plug-in that you could show your own graphs there so the only plugin that was there was x-ray plugin in AWS AWS which was around that time it wasn't open source it was on enterprise so what I did I was going to uh develop some sort of data source plug-in to show these things. This was my actually first plugin and this was the this is the journey that if someone who wants to develop a plug-in for graphana can take. So first you can detect a problem and by problem I mean any lack of support for some sort of data source or maybe an issue that you see in in all of these plugins and then you can research if there is any work already done on those plugins or or anyone who has actually developed these some sort of plugins. Then you can choose the type of plug plugin that is a better suit. if it's a panel plug-in, if it's a data source or app and then you can start developing and of course graphana has very very rich documentation for you to develop those and of course a rich community that you can reach them out through slack or graphon forums and uh you can submit your plug-in for graphon to graph for review and promote it by announcing in graphana slack forums tweeter or anything else like link okay so let's go into kafka plug-in development So first of all what is Apache Kovka and uh for those who have not worked with or are not familiar with Apache? Apache is a distributed falterance scalable popsup message broker system and the key feature is that you can use it as a falterance and high throughput system for eventdriven applications or architectures. So it's like a broker and its alternatives are of course something like NATS like rabbit MQ or active MQ. These are actually its its main alternatives but extensively it is utilized for high throughput and scalable applications in enterprise systems and the architecture is that it have producers the brokers itself consumers and before version actually I guess it was version three you had to use zookeeper but now you don't have to use zookeeper at all and you can use kofkco by itself. So here is a sample that you can see how kofka is working. So if this is a Kofka broker the producers would produce messages on different partitions of a topic. So graphon is using that this partition a partitioning thing to put the messages with the same actually key or ID on the same partition and this is one of the cool things that actually Costco supports and consumers actually would consume these messages using the poll mechanism. So each consumer at if you have multiple consumers in a consumer group by thanks to the partitioning you can actually scale out the the thing in Kofa. So the more your project is getting bigger the the bigger your project is getting the more partition you can use and you can simply scale out the number of consumers for that project. And uh if one of the consumers actually is going in outage being in outage so the other consumers they can take that responsibility and this is really really this is one of the things that makes cough fall tolerance and if you have multiple consumer groups for example multiple services so you can use multiple consumer group ids each one without its own actually message by itself and this is again one of the other things that you can use in Kafka. Okay, this is for getting more familiar with Kafka and the shortest story for me was that the situation was that you have Kofka cluster and you can have Kofka metrics into graphana using thanks to the Promethus metrics. So for example you could have metadata how many topics I have and uh number of brokers in the cluster how many producers how many consumers if the consumer is up or down these were the things that you had but you couldn't have the messages in the kafka into graphana you couldn't see those messages into graphana so this was actually the problem that we were facing so I contacted graphana guys which back in the days there was a guy who uh was Marcus Olen and he really helped it to gather some sort of idea to reach an idea and then I started developing it and it resulted in this plugin Kofka data source plugin. So the way that it works is very simple I will show you now as a demo. So you will uh actually enter the Kafka URL and you will configure its mechanism SAS mechanism user anything you want and then you can actually see the actual messages that are coming through that topic into to graphana and you can see the messages there I will show you soon. So the features that now this plug-in has it's that you can have realtime monitoring of cocka topics. So it's it's using s streaming. So most of the plugins that graph are using is using some sort of query. So it's uh it's a query like a batch thing but using a streaming you can have something the messages coming into graphana in life and you can query all or specific partitions you can have autocomplete for topic next because most of the times we have too many topic names into your Kafka. You have flexible offset options like latest, earliest or last end messages, timestamp mode. So you can choose if you want the Kafka event time or dash receive time. And we have advanced JSON support. So no matter if your message is in JSON, flat, nested, arrays or mix type, it will support it. And recently we have of course added the AVO support and we are going to add uh proto support of course and uh it supports Kafa authentication SAS line encryption SSL TLS MTLS plain text and escro. So this is one of the case studies that you can see that we have a sources multiple data coming through memory load CPU load anything any data coming into graphana into Kafka and graphana server with the which has the plug-in can stream that data and you can visualize it into your browser of course and you can use the client some transformation of graphana to do any kind of transformation on that data filtering anything that graphana supports of course which is really really great and another case stud is For example, you have the database and you have CDC changer data capture. Your data from database is coming into Kafka. You have different transformations and you can have streams of data into a graphana and of course there are multiple things there Kofka connect having that Kofka into for example click house. So one of the things that you can have having that data into graphunnel and even in the future as I'm going to talk about you can have you can set alert on those data too. So to see if something has been wrong there, going wrong there. So and uh the future works actually for this plug-in is that supporting more complex formats. Of course we are we have now streaming we are going to support data query too alerting. So you can set alerts on your data. So of course I know that many teams using graphana they have their they are using the agraphana alert manager or maybe they're using the primitives alert manager and or maybe using graphana on call alert manager and you can use that data source plug-in alerting to set alerts on your kafka and of course adding support for a protobuff and support for other authentication methods like keraros or ooth beer. Okay. So let's see uh a demo here. I'm going to first show you. So consider this that I'm going to produce messages into one topic. So I have a topic here for example JSON topic. So I have a JSON topic. I'm going to produce some nested shaped JSON with for this topic. And uh if I go to see the data of this topic first I'm going to show you how this data is working. So I'm going here. You should go to your data sources and here is your Kafka plug-in that you can choose and add it as a data source and there you can see that you can enter your bootstrap servers urls of your kafka which is which which could be multiple separated by comma your client ID if needed you can choose any plain text SSL SSL plain text SAS SSL so for example if you're using SAS SSL you can have you can choose the mechanism if it's plain SARS HA256 or 12. You can choose the TLS settings and uh of course some advanced settings like log level or heartbeat timeout. Okay. So this broker that I'm using it's in plain text. So it's simple. So we can see that if it's working. So yes it is the graphon actually is correctly connected to the broker. And then I'm going to go here into explorer and I want to uh enter the name of my topic. So it was JSON. And this is the autocomplete that shows you the topic and you can fetch. You can see the partitions. So you can choose any partition here or all partitions. You can choose the offset if it's latest, last any messages or earliest and of course the time stamp mode. And you can see the data coming here. And the good thing is that and the good thing is that we are going to have all this data with a dot schema. So if you see the actual data, the actual data is something like this. So if I go through JSON test if you see so actual is something like this a nested JSON. So this nested JSON actually is completely flatten through a dot mechanism into this and you can have it here. So I'm going to now show you some very very simple a very simple dashboard. Consider it as I'm going to I have a dashboard already created dashboard. So I'm going to send those messages into topic called test and uh I've already defined a dashboard into graphana. So consider that there are bunch of messages there in graphana and now you have a server monitoring dashboard for example. So now you can see live data coming through for example your memory usage your CPU load over time your I don't know current CPU load alert table so you can see values anything that you have there but how how are we using those so you can simply go here for example memory usage and you can see that it is using the test topic and of course I have defined some sort of transformation to filter only the time and the matrix.mmefree matrix.mmeu use and of course you can use any other transformations that graphon supports. So thanks to this you can have any data in your graphana in your into your kafka and after we add a and protobuff support you can have any kind of data set even alert on them and have the kafka data into your graph. Perfect. Uh okay I'm done. I guess you can also use it this SQL expression that is a new feature of graphono. So you can like pass the JSON to the next query and then it acts like a MySQL based syntax and you figure it's like that. Oh, thank you. Oh, that's why. Okay. Yeah. So I guess um so if you go to the the the panel settings I can so going through a panel setting. Yes. And then in the queries you set the data source as mixed. No no don't add anything. Yes. Thank you. And then the second the B. So you can set it. Uh oh, this is grapho version 11. Is it is it released in version 12? I guess it's 12. Yeah. Oh, sorry. I can Yeah. So in grapho version 12, you have the feature of the SQL expressions. So you basically can do anything with your data and it doesn't matter where the data comes from. It's technically JSON or you can convert it to JSON and then you can pass it to the SQL expression which is kind of MySQL based syntax and you can just do any sort of transformation. can do any transformation them here they'll explain. So what if you see here so queries so if you go to transformations transformations only apply to dashboards in graphana if you work with grapho before you know that transformations don't apply to queries they apply to dashboards so you don't have them in alerts or anything else but with the SQL expressions you can have complex transformations in the query in the graphono back end and you have the like a perfect yeah because transformation are happening in the front end So the query thing that's actually is happening in the back end. Exactly. Perfect. Exactly. And and and we are heavily using it in doing secondary detections in alerting and such. So yeah, thank you. Thank you. Thank you question. Perfect. So it looked great. I would say right now people are using cuffrop and cafka viewer for viewing messages. Uh do you have any plan of implementing some kind of schema registry for messages? Yeah, actually uh I just I can show you. Okay. So now if I go here this feature will come very very soon and uh you you could see it in caf in in graphon very very soon here you can define this URL this is perfect yeah really good yes and then I will show you this now if you go to your dashboard so for example I have here I'm going to produce some messages into avotopic schema and I'm going to Yes, produce this one and then you can see that I have a public schema can find it and if it's JSON it would of course not able to consume it and if it's SC register you can test the connection and now you have the data great you have support for it nice so so one more question this is I mean this will be amazing to have both explore cafka in graphana regarding the scram credentials Um how do do you store them and um how do you store them? Actually all the credentials in graphon actually the the things are the sensitive data are handled by graph itself. Yes. And and the bearer token would that work for the like a managed cafker. Yeah. Uh for now we are only supporting scrum and we are not supporting beer but this is one of the things that I'm going to add in the future in the near future. Yes. As well as peros I guess. uh Amazon MSK only supports uh no they they have SAS yeah and then they have this IM as well but well first of all thank you for developing it very very cool product my question is I mean now and then it's it's open source as well so the entire community can use it like have you heard of any cool use cases that other companies are using this for anything you like in particular once I I just heard from one of the graphana guys that in terms of business or pizza team I heard heard that Bank of America was uh using it but in terms of stats just know that I just saw the number of downloads was more than 2 million. So I but I don't know nobody has actually counting and okay I'm using this for this thing. Uh yeah this is the only stats that I see in the graph on back end when I'm developing but I don't know about this. So what has been the most frustrating part of uh developing a graphana plugin? E2 test maybe. Oh yeah, sometimes you play right. Yes, it's it's really annoying when you want uh and uh especially when it's going to be from version to version. So sometimes for version 10 something is support as in version 12 something is added or supported which is not supported in version 10. But of course thanks to graphana UI I guess uh there was something like UI components that was that was pretty easy. But besides the UI test I would say everything was good. I mean when I support uh when I submit it for review it will be perfectly fast to be actually released but I can't say that's maybe the difference is but of course one of the things is maybe typoscript because I'm not mainly my knowledge is mainly deep in golang and python not in typcript so sometimes typ might might be a pain in the neck but overall it was pretty good. Yeah, thanks. Yeah, it's just as if you if you want to develop a graphana plugin and do end to end testing, there are two ways to test compatibility. One is uh a project I don't remember the name of. It's called like graphana plug-in compatibility something. Yeah, I'm I'm now using in my CI. Exactly. So that that shows you exactly what's wrong and the difference in messages and and this is things develop now is really really good because back in the days there were nothing of those but now those things really help actually in CI for developers. Yeah. And as for the like if you're into like front-end testing I guess you can use synthetic monitoring of Ksix and also XK6 browser which is built in into Ksix. So you can write scripts or there's another new tool called K6 Ksix studio you can just use it just browse into wherever you want in graphono it will record it as a script and then you can play it back in your tests and you will have everything there and u one more thing I just wanted to bring up I also developed something forka almost 6 years ago it's called xk6 kafka if if you search it sure thanks xkas it's not about me it's about you xk xk xk basics. Okay. Yes. Dash. Yeah. Why was up to you? I mean, so it's uh Yeah. So if you ever want to test Kafka or if you want to produce messages to later be consumed by his plugin in in uh Graphana, you can use this project and so thanks to cases of course it could be for low testing even. Yeah. Exactly. And you can Yeah. Instead of producing with a script, you can just produce. Nice. Yeah. Exactly. Exactly. In any form you want. Yes. I got it. Perfect. And I think can register too. Yeah. Perfect. Thank you. Thank you. Thanks. Any other question, thoughts, concerns, feedback? Yeah. All right. So, at Graphana, we usually have hackathons, internal hackathons three to four times per year. They can be quite fun and sometimes even useful stuff comes out of them. And that could be stuff that improves the user experience or maybe, you know, makes us save money. That's always good for a business, right? And sometimes, uh, you know, projects can just be a a little bit of fun. I doubt we're going to save much money with with this media streaming data source. And, uh, if if you have no idea what this title means, you will know what it means at the end of this presentation. So, this was a hackathon project between me and my colleague Mark. And yeah, we'll talk a little bit about it. Yeah. Hackathon projects at Grapho uh sometimes become graphono projects like for example Loki was Yeah. Yeah. And then we also have like the more recently drill down apps. Drill down or grapho assistant and so on and so forth expressions. Thank you. We we have a lot of fun projects uh that end up in actually being used etc. And uh why can't I see my uh get the next slide? There we go. So what can you use graphana for? We're going to do a little bit of show of hands here. Who here uses Graphana to monitor their uh IT infrastructure? Yeah, quite a lot of people. That's nice. And who here uses it for uh like BI stuff, KPIs and such? Okay, not as many. What about uh your cloud costs? Yeah, a couple of those. They're probably very fun to look at, I bet. And how many here use Graphana for music? No one. I'm a little bit disappointed to be honest. But here's a dream of mine, right? This is my dream for 2028. Graphana is the most popular digital audio workstation. And we will have sampling, synthesizing, mixing, you name it. And we will tap into the creator economy and uh and have datadriven music with AB mix testing with AI with AI for sure. And Graphana is disrupting the music production industry. That's like 2028 for me. And of course, the expansion into music production for Graphana is going to double our total addressable market. So, this is something you definitely want to buy into, right? And uh this is a dream of mine, but we kind of have to start small. So, uh let's start with a little bit of a recipe. We have built this plug-in during hackathon and uh we basically used uh RxJS and the web media API on the front end and we added some piano and drum samples and we use the tonejs library to manage uh both media input and play samples and uh very important here I'm saying this because I'm doing a live demo okay things may not go so well hackathon quality coding there are most definitely bugs and Uh, we can see this as a seed of a dream or like the first mix of a cake that might not taste very well, but it kind of works. Yeah. Yeah. Yeah. So, where do we kind of start with this? Then we got to understand the data. What kind of data are we getting? We are going to look at how we're getting data through streaming just like the Kafka plugin. and we're going to look at kind of the data structure and uh what kind of data we get from media keyboard and how we then integrate that into graphana. So it's going to be a little bit technical. So this streaming data source if you haven't used the Kafka one maybe you want to look into some other ones you have other use cases etc. So you make sure that your data source supports it and if you want to know how to implement one of these go and read the docs on graphon alive that's quite nice. I have some examples here that doesn't include Kafka. So Loki or MQTT supports streaming out of the box and I I I thought I just share with you how this might look. So we start with adding a visualization and I'm going to use this test data we have. And here I can actually choose a scenario which is a streaming. So this just outputs random data. And uh up to the left here you can see this little dot which shows that we are actually streaming data. It's not updating. It's because it's last 6 hours time range. Let's do like one 1 minute now minus 1 minute. Yeah, there was we kind of see it uh update as it publishes values. And uh so you can also see the whole time series kind of moves as we publish these values. And what you can do as well because if we don't publish values this time series uh doesn't move. So we have this setting which called it's called refresh live dashboards which will make these move continuously. And uh you can see it's a little bit smoother. So it moves even when we're not receiving data. So yeah this is a little bit of an introduction to kind of how you might see or use streaming in in a dashboard. Now for the MIDI format, you're probably wondering what does MIDI even mean? It's for for short for musical instrument digital interface. Couple of decades old standard. It makes you it's possible to use music stuff with computers. So what kind of data do we receive? You can receive a lot of different kinds of data, but these are the ones we are basically interested in like a status. So it may deliver a message which has says they're on or off. It says which note it can be uh from 0 to 127 and uh this could also be doesn't have to be a note if you use a drum etc. You can have some kind of mapping there as well and also the velocity like how hard did you press the keyboard and then we need to take this data and get it into graphana somehow. So what we do is we create new columns which has the name of a note in this case as I'm using a media piano. So we create a field with a note name and then uh then we push this field the velocity and the time stab at when it happens and then we listen for the off event or when velocity is zero then we set the value to null. So here we kind of have the mapping. So for example, if you get number 21 that maps to the note a z or here we have an example of how the actual data frame may look. So one second ago you pressed C3 and you kept it pulled down until now. And while you did that you also pressed C 3 just a little bit shorter and a little bit harder. So all right now we're going to do some live demo on this how we're going to visualize this metadata. So what I'm always trying to do when I first work with the new panels is to kind of understand the data formats. We kind of dove in a little bit into that and uh I'm going to use the state timeline panel to work with this. So let's see how this go. Maybe who knows. So maybe we can remove this panel. And what we do is add a new visualization. And this time we actually let's start with changing the data source to our MIDI input data source. And uh here we can select our this is the key station that I'm using. And it's asking me if I want to use my microphone because uh now it's going to start to listen on stuff. I'm also going to show how we how we use the microphone with this. So if I then yeah we get some sound but you know this is the time series panel so it looks kind of So then we use the state timeline. This is usually a panel that's good for like visualizing state over time like a system state if everything is okay or we have an error or whatever. So what I have here I'm going to just reduce this so we don't get so many fields showing down to about there. Then I can push the button become a little bit bigger. And you're probably wondering what what's this 80 plus thing here? That doesn't make any sense, right? Well, it turns out that by default we have these kind of thresholds set. Uh so what does this even mean? 80 plus threshold. So what we want to do is change this color scheme. So I would probably go for like blue. Uh then we get when press softly. That wasn't soft enough apparently. Stop. We get a five. That's a blue. And then if we there hard one 127, we get a red one. Then we see a little bit of art. We can play guitar almost. So yeah, that's a little bit of this one. I do think if I can also change to have these drums. So yeah, this doesn't make much sense here uh on this keyboard, but the guy I developed this with, Mark, he actually has a MIDI connected drum. So he sat there and just played drums in graphana. Uh that was a pretty cool feeling to be honest. Spotify is dead. Yeah. Yeah. So what more do we have? Well, I also added kind of uh microphone input. So the data is a little bit different here. We kind of do fast for transform on on the data and get uh this intensity into frequency buckets. So we can kind of configure the size there as well. And in terms of panels we want to use here. We can use something like a bar gauge in order to see the instant levels and you can use a heat map to see a more of a spectrogram across time. Let's see if we can manage to do that. Like I'm actually going to I know there are some bugs somewhere. So I'm just going to create a new dashboard which is this one. Okay. Gotcha. I'm going to save this and then throw it away. New dashboard. Okay, add visualization. So, we're doing the same. Choose mid input. This time, we choose a microphone and uh same here. We we we kind of get the time series. Probably doesn't tell us a lot. Maybe not. Uh I don't know how much 6 hours. Yeah, quite useful. So, let's do uh like the last minute or so. So, here's a time series panel. This is also a case where you I need you need to understand what the data looks like. So we can press this table view and here we see this frequency buckets and also the time stamps of these and most of these values are kind of low kind of quiet. So this is in decibel, so it's negative. And that means we probably want to have a look at what I say bar gauge. This is the one. And then you can Where is my microphone? Hello. I Yeah, I'm not sure where wherever my microphone is on to the left left of the keyboard. Is it here? Yeah. Yeah, it's here somewhere. Yeah. Cool. So uh yeah, we can see this frequency. We can also determine the range here. So we don't care about uh 8 kHz. So, we go down to like four or something just to get, I don't know, a little bit of clearer data. And we probably want to do like a similar thing as we did with the last one here as well. We don't want colors from thresholds. We we will probably go with the same one. It kind of looks a little bit more soundy, which is the technical term, I suppose. Uh yeah. So, let's let's try this. If I if I whistle, what will happen? So, yeah, we get it as at different frequencies. It's kind of fun to look at, I guess. uh still have to kind of figure out the use cases for this. But it it's fun. It's fun for sure. And yeah, then we can also do go for the heat map. And now we're super confused because we just had a lot of data show up and suddenly it doesn't show up. And uh it turns out that there is a default setting for the heat map that we hide cells with values below like uh 10 to the 9th. Yeah. So slightly above zero, but all our values are negative. If we put this to like minus 200, we get this. And also I think I think we have to do the same thing here with with the colors. Let's do spectral. Yeah, this is this is more like it. And you can kind of see how where I'm talking more loudly. And this is also the case where you can increase the FFT size to kind of see see more things happen. So let's do 256 maybe. Then we get uh smaller buckets but a more clear view on what's happening here. And uh yeah, if we also do the whistle test here. Yeah. Yeah. No, this is uh this is amazing stuff happening here. You think so? Okay. Oh yeah. Yeah. This is a huge market opportunity. Yeah. Um so yeah, this is kind of what we we've got here. And as I said, the code we've written for this is very much hackathon quality, which means we don't have it approved in like so you can download it and try it yourself, unfortunately, which I assume that when you went home, you would probably do immediately if it was possible. Someone will pay for it. So yeah, hopefully uh even though you might not be too uh too familiar with, you know, music, etc., Maybe you got some insight into how to edit panels and like some of the options we look at and maybe maybe I showed you some dashboard or visualization feature that you didn't know of. I got a short introduction to kind of how how the media format looks like and how we map that to to a data frame in in Grafana. And hopefully it made you a little bit curious about trying to write your own plug-in. And you know, maybe it doesn't have to be too serious. And hopefully by writing a plugin for Graphana, you might be able to realize your dream for 2028. Thanks a lot. All right. Is there are there any questions or something of the sort or everything's crystal clear? Thanks. Is the repo public? I think it's already uh No, no, no, it's not. So maybe we should make it public. Yes, please. You don't make you don't make a real product like this open source, you know. That's the spirit. Okay. Anyone else has any questions? If not, you can just uh come and ask me afterwards. I'll be hanging around and eat some pizza. So yeah.

