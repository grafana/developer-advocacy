# All about Structured Metadata in Loki (Loki Community Call August 2025)

Published on 2025-08-13T03:41:51Z

## Description

Senior Software Engineer Salva Corts Sánchez talks all about structured metadata in Loki. He discusses what it is, why you might ...

URL: https://www.youtube.com/watch?v=IKdRzjwFXYI

## Summary

In the August 2025 edition of the Loki community call, Nicole Vanderhovven hosted a discussion on structured metadata with co-hosts Jay Clifford and Salva, who have been integral to Loki's development. The main topic revolved around the implementation and benefits of structured metadata in Loki, particularly in relation to its use for OpenTelemetry (OTel) and high-cardinality data management. Salva explained that structured metadata allows users to attach labels to log lines without overburdening the index, thus improving query performance. They discussed the importance of distinguishing between indexed labels and structured metadata, when to use each, and the configuration options available to Loki users. Additionally, they touched on the implications of upcoming architectural changes in Loki 4.0 that might affect structured metadata handling. The session concluded with an open invitation for community feedback and future topic suggestions.

# Loki Community Call - August 2025

Hello everyone! Welcome to another Loki community call. This is the August edition in 2025. I am **Nicole Vanderhovven**, and today I have two awesome people with me. We're going to be talking all about **structured metadata**. 

But first, let me introduce awesome person number one. Jay, would you like to introduce yourself?

**Jay**: Hi everyone! I’m **Jay Clifford**, Nicole's right-hand man as always. By the way, I just want to mention that it’s my birthday month, which is why I’m so excited about structured metadata!

**Nicole**: And below me is **Salva**. Would you like to introduce yourself?

**Salva**: Absolutely! Hi everyone, I’m **Salva**. I’ve been part of the Loki team for about three and a half years now. Time flies! I’m based in southern Spain, and I’m happy to be here to talk about structured metadata and some other things.

---

## Announcements

Before we dive into structured metadata, we have a few announcements. 

1. **Loki Helm Maintainers Group**: We now have a small group of hand-selected Grafana champions who are our maintainers of the Loki helm chart. We have added two new people since we last talked about it: **Mike Timberman** and **Quentyn Bisson**. We're thrilled to have them on board!

2. **kubectl Changes**: Jay, would you like to explain the kubectl stuff?

**Jay**: Sure! This shouldn’t affect the day-to-day running. There’s a big PR that you’ll see get merged into the Loki helm. This is related to the Bitnami image issue from August. Many images are being moved to another repository, and we use one of those images in our gel implementation to generate API keys automatically on deployment. We felt it was best to remove it to simplify the Helm chart and provide instructions for generating the initial admin keys for gel. So OSS users, there’s nothing to worry about. Gel users, there’s documentation available, but you’ll only need it if you’re deploying new gel instances. If you have any issues or concerns, drop us a message in the community channel.

---

## Diving into Structured Metadata

**Nicole**: Salva, can you tell us more about why we’re discussing structured metadata today? What’s your connection to it, and do you love it as much as Jay does?

**Salva**: Absolutely! I was one of the people who implemented structured metadata. We created it to support hotel natively, and I actually do love structured metadata a lot. 

So, what is structured metadata? It’s a feature of Loki that allows you to attach labels to each log line, but these labels don’t need to be in text, like the stream labels do.

**Nicole**: That's interesting! Can you differentiate between regular labels and structured metadata, especially in how they exist in Loki's storage?

**Salva**: Sure! In Loki, we use the term "label" in many places. A label typically refers to a name and value pair. We use it for streams, which define the source of your log. For example, in a Kubernetes environment, a stream can be defined by the cluster name, namespace, and container. 

These are indexed, meaning Loki creates a data structure that helps resolve relevant data based on your stream matcher in a query. For instance, you could query for all logs from a specific cluster in a specific region. 

Structured metadata, on the other hand, allows us to store high-cardinality labels separately. This helps keep the index small and improves query performance. 

**Nicole**: How do you decide what should be a label and what should be in structured metadata?

**Salva**: The focus should be on keeping a small index that performs well for the queries we typically want to answer. In observability contexts, this usually relates to the source of the logs. For instance, if there’s an incident with a product in a region, you’d want to query logs by cluster namespace. 

As a rule of thumb, use labels that indicate the source of your logs. Everything else, unless there's a specific case, should generally go into structured metadata. Examples include trace IDs or user agents, which can have many different values.

**Nicole**: That makes sense. So, if I'm sending a JSON payload as the log body, why should I use structured metadata instead of extracting specific values using regex from that JSON?

**Salva**: In most cases, having everything in the log lines is fine since Loki is excellent at processing large volumes of data. However, if you have a lot of logs with nested JSON objects and frequently look for specific information, it’s better to extract that to structured metadata. This avoids the overhead of parsing during queries, leading to faster execution.

---

## Querying and Performance

**Nicole**: How does querying structured metadata compare to querying log lines with regex?

**Salva**: We store structured metadata alongside the log line, but the key is that we don’t need to process the entire log line. With regex queries, you might have to parse the whole log line to determine relevance, which can be slow. When using structured metadata, you can filter directly on the metadata value, skipping irrelevant entries immediately.

**Nicole**: Are there any specific Grafana features that require the trace ID to be an indexed label?

**Salva**: There aren’t any specific requirements for Grafana, thankfully. You can correlate between trace IDs in log lines and trace IDs in Tempo using JSON parsing to extract labels. However, using structured metadata simplifies this process.

---

## Demonstration

**Nicole**: Shall we take a look at a query example for structured metadata?

**Salva**: Sure! I can show my screen. 

*(Salva shares his screen, demonstrating the Loki Explore view.)*

**Salva**: Here, you can see all the log lines for a specific cluster. This section shows the labels, with indexed labels listed first. Below, you can see structured metadata like detected error levels, trace IDs, and user information. 

For example, if I want to look for everything related to a specific user, I can easily query for that. 

---

## OpenTelemetry and Structured Metadata

**Nicole**: What collectors currently support structured metadata behavior?

**Salva**: All Grafana-owned collectors support structured metadata, including Alloy and Promtail. Some third-party collectors, like Vector, also support it. OpenTelemetry collectors can ship everything in the hotel format, mapping things to indexed labels or structured metadata based on configurations.

**Nicole**: What’s the connection between structured metadata and OpenTelemetry?

**Salva**: The challenge with OpenTelemetry was that any information outside the log line had to be allocated in the stream. Structured metadata allows us to attach metadata to log lines without bloating the index. In OpenTelemetry, we map resource attributes, scope attributes, and log attributes to structured metadata.

---

## Configuration and Best Practices

**Nicole**: Can you explain structured metadata promotion and how to set it?

**Salva**: We provide good defaults for most users, but you can configure which resource attributes, scope attributes, and log attributes to index, store as structured metadata, or drop entirely. This flexibility helps accommodate various user needs.

**Nicole**: Can you promote attributes to labels?

**Salva**: Currently, we only allow promoting resource attributes to labels to maintain good practices and avoid high cardinality issues.

**Nicole**: Are there any best practices for using structured metadata?

**Salva**: Don’t extract everything into structured metadata just because it’s possible. Keep what you need for querying performance, especially if you’re using OpenTelemetry. 

If you can avoid duplicating data, it’s generally better not to extract everything. 

---

## Conclusion

**Nicole**: Thank you, Salva, for sharing your insights on structured metadata! This has been an informative session. 

If anyone has ideas for future Loki community call topics, please let us know in the comments. We look forward to seeing you next month!

## Raw YouTube Transcript

Hello everyone. Welcome to another Loki community call. This is the August edition in 2025. I am Nicole Vanderhovven and today I have two awesome people with me and we're going to be talking all about structured metadata. But first, let me introduce awesome person number one. Can I can I just say that it's my birthday month. So, this is the fact that we're doing structured metadata because I love it's my birthday month. So, but sorry, I am Jay Clifford. I am Nicole's right-hand man as always. Um, and then below me is Salva. Would you like to introduce yourself? Absolutely. Yeah. Hi everyone. This is Salva, part of the Lock team for about three years and a half already. Time flies. Based in southern Spain and happy to be here to talk all things structured metadata and some hotel, I guess. Awesome. Before we get started with structured metadata, I know Jay is like raring to go weirdly, but we have a few announcements. First, we talked about the Loki hell maintainers group. We now have like a a small group of hand selected Graphana champions who are our maintainers of the Loki helm chart. And we have added two new people since we talked about it. Mike Timberman and Quentyn Bisson or I hope that's how you pronounce it. But we're so happy to have them and um it's been going really well. Uh and then Jada, do you want to talk about the cubectl stuff? Yeah, so this shouldn't affect the day-to-day running. Um it's just obviously a big PR that you will see get merged into the Loki helm. Um this is just to do with the Bitnami image issue by August. Um I think I think most people have seen that um a lot of images will basically be sort of made end of life. Um and they're moving these to like a kind of like a another repository. Um and so we basically use one of those images within our gel implementation in order to generate API keys for gel automatically on deployment. Um we felt that it was best just to kind of remove that. Um it it basically simplified the Helm chart and just provides some instructions for generating those initial admin keys for gel. So OSS users, nothing to worry about. Um gel users, there's documentation, but you only really need it if you are deploying new gel instances. Um so yeah, but if you've got any issues or concerns, um just drop us a message in the um community channel and we shall take a look. Yeah. And Salvo, why don't you introduce yourself a little bit more and talk about like why why we're doing structured metadata? Like what do you have to do with structured metadata and do you love it as much as Jay? Yeah, absolutely. Yeah, I gave you a bit of context of why am I here talking about the structure metadata is because I was one of the people that implemented the structure metadata. Uh originally we implemented it so we could support hotel natively. Um looks like we did so yeah I also happen to like a structure metadata a lot. Um so what's uh what is structure metadata to start with? It's basically a feature of loies that that allows you to attach some labels to each one of your lock lines but those labels don't need to be in text such like the stream labels. So that's pretty much it in a nutshell. So So that's an interesting one there already because we're already using the term labels when we also have this idea of labels as you said like indexed labels. So can you differentiate just a little bit more there we have labels which are indexed they create log streams right and then structured metadata where do they exist in the storage of Loki? Like where like if we go under the covers how does that is that represented when you're like retrieving them? Sure. Yeah. So you will see that we use the term label like on many places and label is pretty much like a name and value pair. So we use it in different ways in Loki. H originally since Loki was created we use it for streams and streams kind the can be defined as the source of your log. So for example one one example of a stream can be on a Kubernetes environment the cluster name space and the container for example that can create like an stream and then you have all the logs from that source on a single stream those are index meaning that Loki creates like a data structure so it can resolves the relevant data giving your stream matcher in the in the query. An example on the query could be give me all the logs for the cluster in US central zero for example. So that would resolve all the streams matching that uh now those are indexed right and the important part of that is that Loki ideally wants an index that is rather small so it can resolves this kind of questions relatively fast. If you start putting like many many labels on on your index and specifically those labels have like a high cardality high cardality meaning that can have like many different values the size of the index will be very big. So answering those kind of simple questions of giving all the logs line from this cluster can take way longer that you may want. So our solution is putting all those high cardality labels h somewhere else and that would be on a structured metadata. Okay. So who how do you decide what is what should be a label and what should be in the structured metadata because you know maybe I know you're trying to reduce it for high cardality but what are some things that you would think about to decide to kind of prioritize what really needs to be a label. Mhm. So as you pointed out uh one of the we we need to keep like the focus on what the target is right that is having like a rather small index that is that plays nice to the queries that we usually try to answer. So in the context of observability this usually maps to the source of the logs right. So for example, if we have like a big incident in one specific uh product on a region, you usually want to query by the cluster name space. So it makes sense that you use those uh as stream labels. Um so the general rule of thumb is that you use labels that tells you the source of your logs. everything apart from that unless some specific cases it's usually better to have them on a structured metadata structure metadata label uh examples might be things like trace ids uh customer emails that you can have many user agents right imagine if you have to put like all the different user agents on on the index like that that that index can can be huge right we we can dive a bit more into the details on why having a big index is is bad. But yeah, I think the the trace ID thing is really is really good too, good to call out because that's an example of something where if you if you are using distributed tracing and you are using trace ID as a label that's going to be that is really going to lead to high cardality and yet you don't want to not have that because having that instructured metadata means that you can correlate between telemetry signals. So you can you can see like the it's you know when we when you're using the graphana stack you can then see like the the log that corresponds to a certain component and then for that component also see like the transactions that went through it or like use Pyroscope or something to see the CPU util utilization of it but it's only in structured metadata that you can have all of these very dynamically generated ids otherwise it's just going to blow up your index. Yeah, exa exactly. And I think that also opens the door a bit of more maybe talking about hotel uh down the road because actually hotel kind of um simplifies all of this like a lot, right? Like having like a consistent labeling that allows you to correlate all these telemetry signals with with each other. Um and yeah, as I said at the beginning, we actually created a structure metadata to support hotel exactly because of this. We we had to store this kind of information somewhere. So before we get to the the hotel stuff, I do have some silly questions of my own around like structure metadata. Um I'm a big fan, but I'm just going to ask them anyway because they're fun. Why um if if I'm already say like sending a JSON payload as the log body and I've already defined my labels like why is it better to put it into structured metadata than just say using some reg x passing and extracting say like the trace ID from like the JSON body is is there a particular benefit from just going like directly to structure metadata? Yeah, absolutely. I I would say in most of the cases for most of the users having them just in the LO lines is usually fine because Loki is really good at processing like a huge amount of data and extracting labels out of them with with the parsers. Now if you happen to have a lot of logs and those logs are JSON objects with even nested objects inside each h inside the object and you want to look for something very specific and you do that regularly either because you have a dashboard with a query or you have a recording rule. It's actually a good idea to extract that specific bit to structure metadata because what you are doing is actually skipping all that parsing uh right away. So all the queries would be like way faster to to execute and play nicer to the system underneath. I I see because basically you're doing like a give me these logs, pipe it to like JSON and then you're extracting the attributes and then you're basically then having to do the reg x on top of that of going okay the trace ID equals this this is now one of those relative links in graphana and you you click that. So it's almost like you you've created three extra steps for yourself that all require like Loki processing versus just like um going straight structure metadata. Cool. I like that. Exactly. Yeah. And and also like I know we Jay and I have previously done a community call about queries and we know from that one that that if you do any sort of parsing including JSON and and then also anything with regular expressions like yes it will work but it's also it it's it it's really expensive computationally. How does it compare? How does um querying structured metadata compare to that like in terms of resource utilization? Yeah. So we actually store structured metadata along with the lo line. But the key here is that we don't need to process the whole lo line, right? So we don't need to do any parsing that is wasteful. comparatively like for example if you are matching a given string or a regular expression you need to look throughout the whole log line potentially to decide whether or not the log line that you are filtering by is relevant or not. Whereas if you have that already in a structure metadata, first you can skip right away all the entries that doesn't contain that structure metadata label at all and then you can filter right away on the structure metadata value itself instead of having to go through potentially all the lock line to decide whether it's relevant or not. But I I would say in most of the cases the performance gains come when you run expensive parsing logics uh parsing like with reg x that are quite complicated that cannot be simplified right away or JSON parsing for example. Rockco has a question that's relevant to what we were just talking about. Are there any specific Graphana features that require the trace ID to be an indexed label rather than being just a mere attribute in the payload? Uh I bet there is not because we would be in serious troubles if that would be a requirement. But that's a great question. But so far, for example, to correlate between H trace ids that you would see like in analog line and the trace ids in tempo, you could define in your data source a a matching expression like using the JSON parser if I recall correctly and extracting that into a parse labels and then use that. But now if you use a structure metadata, that just happen like out of the box. You probably only need to configure in the data source the name of the structure metadata label that you want to correlate with. Yeah. Okay. Maybe we could have a look at what a logql query looks like for for structured metadata. Yeah. I I have a question on that. If you're demoing um SA are you demoing? Sorry, that's the it's my bad. I wasn't expecting to, but I can totally do it. Um if not, no worries. I guess because there was a a question that I had you you implemented a feature maybe I got is it six months ago now. Um no it's way older than that. I would say it's probably one year and a half or something like that because it was the autocomplete feature. It's like you could basically in your query see like the structure metadata attribute like key names before you even like as you were typing the query. So I'm assuming that also we can see that as like a benefit of um using structure metadata versus extraction because you have to first do that JSON passing to see those extra attributes. Actually it's it's funny that you mentioned that because that's actually something that we didn't end up shipping. Uh so that was the outcome of a hackathon right so we cly we run hackathon scatterly and we get to to work on whatever that we like and Shantana which is another uh lucky man trainer and myself we decide to to work on that we didn't end up shipping that because we are on the process of doing major changes to Loki so at this moment in time like making huge changes to the index den probably pay off in a way because at the end of the day it's a hackathon so we did it in a very hacky way that it's obviously maybe not production ready. Uh so we decided to wait for it a bit to push it a bit back but it's definitely like a feature that we may want to to see in the future. Oh very cool. Sorry that was my bad. I thought that was in I was like yes that's great. That's good. But people can obviously look forward to it in the future potentially that you structure. Absolutely. I I I mean on the other hand we do have like a walkaround on the graphana UI itself like it can actually already recommend you some structure metadata labels by kind of peeking at some of the log lines to to see like what's in there. So that's how we it kind of works nowadays. I've been fooled. S would you would you mind showing us some just something? Yeah, absolutely. The only problem is that the only data sources that I have is our internal ones. I don't know if those are the best ones, but I can play. Okay. Yeah, absolutely. Let's use those. We can figure it out together. Um, but it's not like play@grafana.com or play.grafana.org or or.com will work as well. It it redirects. Oh, okay. Cool. But I also wanted to shout out um the the Graphana champions that were were instrumental for to this being a thing like Avanish Vagela. Uh it was actually his idea to to do a Loki community call on structured metadata. So thank him and he also contributed a lot of questions as did Andre Zivani who's in chat and Mike Timberman. So, we're mixing in a lot of those questions from champions there. We really love our our champions. Um, if you Oh, you should if you want to know about the Graphana Champions program, I will put a link in in the description and in chat because um it's a growing group of really really intelligent and experienced people who are just doing some awesome things like awesome even for us graphistas. Okay, Salva, looks like you've got something up. I'm going to put it on stage. Yeah, there we go. So, you can see my screen now, right? Yes. Okay, cool. Yeah. So, here I have uh one explore view for for Loki. And you can see that I'm pulling all the log lines for this specific cluster, right? And you can see that here I have like a long list of of lock lines. uh some of their uh seems to be erroring, other one seems to be fine. But the important bit is this section here with all the labels. Here you have the index labels which are basically the the stream labels. As you can see, this kind of looks like the best practices because this comes from the source of the of the lock line and I don't think any of them looks like high cardality to me. Uh but on the other hand you have the structure metadata one for for this specific lo line and here we have things like detected level error. This is some structure metadata label that we automatically attach to each lock line. So we can h show this uh like breakdown of the severity. Uh but you have other things like the p the trace ID and the user which can be like that can have like a huge cardality. So now for example I want to look for everything that was regarding let's use the the user for example it's as easy as using user equal and the value and here I should have like everything that is h related to that user. You can see the the user here you can see the user here. You can see the user here or I can do exactly the same with uh some trace ID. So I get everything that is uh okay. Yeah, obviously you need to change the the label name. Um yeah, let's use so that will be trace ID. I think you can you can just like click here and yeah that that will add everything here. So here you you would have like whatever that happened with with this trace ID regardless of the container the pod or or or whatever you can do other things like for example you can do the uh count let's use rate uh at auto and here we can do like a sum by user for example so you use a structure metadata as any regular um yeah as any regular label right let's do let's just remove this I don't know what's complaining that about uh unexpected identifier what did I mess up I must admit this is pretty shocking for me but I'm also super impressed to see the new um UI element separation in um the Loki log messages because before we never used to sort of differentiate we just said like here's the attributes. So now we actually say this is structured metadata. Yeah. Yeah. Exactly. And and and I actually go going back to to this thing here, you can even have a look at the table here. And if you scroll here, you can show for example a user column. So you have all those values at hand, which is also like really really handy. Very cool. So I guess my next question then is um what what agents or what collectors currently support this behavior because it's um it's something that has to happen before we hit Loki. Um so could you sort of take us through kind a couple of um collectors that can currently support structure metadata? Yeah, absolutely. So obviously h all the collectors that we as graphfana own that being alloy h prompt tail even though you should be using alloy if you use brum tail and also I think there are some third party ones that already use support structure metadata I think vector is probably one of them I don't know if you know any other and then the like collector for example That one ships like everything in the hotel format, but then we map things to index label or structure metadata based on some configurations that we can set. Yeah. And that's a that's a good point to to start getting into OTEL in general because I mean at least internally now it's hard to mention structured metadata without talking about the hotel use case because that is one of the primary ways that people are using structured metadata. So what what does structured metadata have to do with hotel? Yeah. So the challenge with supporting hotel with what we have had before structure metadata is that everything that doesn't happen to be within the lock line had to be allocating on the stream right so sends things like I'm sure the user agent or if you happen to be running in some Java maybe some compilation ID or some machine name something like that that can have high cardinality and can just like blow up the the index. Uh so what we decided to to build something that would allow you to attach some h metadata to to the lo lines and that's how structure metadata came to life and how it works for the hotel case is that in hotel you have resource attributes scope attributes and log attributes. So we map everything that is within the scope attributes and the LO attributes to a structure metadata. And for the resource attributes, you can decide whether to index some things or attach as a structure metadata other things in a Kubernetes environment. It would be and we actually have like some good defaults for this having the cluster name, the name space, the region, like you name it. things that are rather constant and not high cardinality, those would be automatically mapped to to stream labels and the rest would be put into structured metadata. Okay, that makes sense. Um, so we also in in Loki OSS we can also do metadata promotion uh structured metadata promotion. What exactly does that mean? How can how can some attributes be promoted and like how do you set that? Yeah, so as I said we provide some good defaults that would work probably in 80% of the cases but this really big and very diverse. So of course like there is no freelance and we need to have like some knots that we can adjust so we can uh make it look useful for for everyone. So we have one OT LP config um configuration that is per tenant and where you can map like all those resource attributes, scope attributes and lock attributes to whether you want to index them, have them structured metadata or drop them right away. Yeah, I I I see I I don't know if Yay or Nicole is sharing their screen, but this is the the the list of default attributes that we map to to to stream labels. No, and I think like it's a the it's an interesting one in the fact that it's like yeah, we we basically cover like a broader topic. It's like you're not always going to have all of these labels show up when you use open telemetry. Like depends on your scenario. It's like the if you're not deployed in Kubernetes, you're not going to have those as like labels by default for any reason. It's purely going to promote if they exist and only if they exist. Right. Yeah, that's correct. Exactly. So, we aim to provide some good uh defaults. Uh but if if those doesn't work for you, you can like extend this list or completely ignore this lead and come up with yours. One common use case that we see for this is uh people want to have like the team label or something like that on as a on the they ship a team label on the resource attributes and they want to to index that because when you when you have like many teams in your company you usually maybe want to focus on your local lines and you don't care that much about the rest. So that's something that you usually filter by. Ah, and then as long as they add it to the resource attributes and then they can basically use the hotel config promotion to move that up to the to a label. That's correct. Yeah. Gotcha. And I guess the um to have a sorry to get into the weeds on the configuration um but to sort of look into some of how that works on the open source side. Um so is it something that has to be a in in the Loki configuration? Does it have to be a global or can it be a per tenant uh limit that you can set for? That can be a per tenant limit that can be set. Of course, you can see you can set like a default for everyone and then if you have a specific tenants that has a special needs, you can just like configure them a amazing. And then like um let let's say you want to keep like mo like is there a way of like keeping most of the defaults um and then maybe like dropping ones? Can you can you like demote in the configuration? Um yeah, absolutely. So you you can see here in the resource attributes that you have this ignore defaults flag. If you toggle that to true, you will get rid of the labels that you saw on the list above and you will need to configure the ones that you want to index in the attributes config. whatever that if you don't set this ignore defaults to true you still like keep those and you can extend that list with whatever that you configure in the attributes config and as Jay pointed out you can not only promote things to index or structure metadata but you can also decide to drop like completely uh something and that usually necessary if you are shipping things that you should not like some I don't know credit card number or something like that. I hope you do not know but and I hope all any hotel collector would ship such things but in in in case that that happens you can drop them. Um another reason why you would need to use this drop is in case you have a collector that ships like a lot of labels. So by default all those labels will go to the structure metadata. But we do have some limits about the structure metadata in the sense of how much each payload can contain of structure metadata like in total in in megabytes uh or the amount of different structure metadata fields that it can contain. That limit is it's quite big. It's decently big. I I don't think any regular user would hit that but some big like hotel uh user can can hit those and would make sense to use this drop um action to get rid of those and be able to push things to to loy successfully. So that that's kind of like where you add like a custom attribute um that kind of like you you kind of overuse it. You might put in like a really massive like payload into the value side of a key. Um and then what you basically would just hit the limit on on that custom attribute and say sorry do yeah would we reject the whole log line because of that attribute. So is that something to keep in mind? Yeah, ex exactly that but that would solve exactly that use case. Like something that comes to my mind is maybe you have a auto collector that you add like many layers and you ship everything that is Java related and everything that is Docker related and everything that is Kubernetes related and everything that is Linux related like all those things or many many many many metadata like flowing in and you may hit like those limits and your log lines would be discarded before being ingested. In that case, you do want to filter out the things that you don't really use. And even within the regular hotel use case, there are many things that you don't regularly use because they are kind of duplicated. So for example, if I recall correctly, I think you have the severity the severity which is a string and then you have the severity number for example and they they they are pretty much like the same. So, you may want to decide, okay, I just want to keep one. Gotcha. Okay, that that makes sense to me. The um and I guess my final question, sorry, I've been quickfiring on this because I feel like I've been waiting for the configuration part. This has just been a page salv on this entire time. Um my last question was is there's we we obviously talk a lot about there's different types of attributes in hotel. There's like the resource attributes and then there's like log line attributes. Um, is it still the case we only let people promote only resource attributes to labels or do we let them access any sort of attributes um and let them promote them and we just let them take the risk of promoting them? Yeah, as of today, if I'm not mistaken, we only allow promoting to stream labels, index labels like uh here in this talk uh only the resource attributes. Um the reason for that is that usually the scope and lo attributes are usually like really high cardality. So to encourage the good the best practices, you usually want the resource thing which as the name implies kind of tells you like what's the definition of the resource right like where are these logs like coming from. So as of today we are not supporting like promoting to stream labels anything that goes like within the scope or the of the logs attributes. Ah no that makes sense. I think it was like and then we just like let people promote um I think label wasn't it like the severity or something like that because that was like an issue that was about 50 comments long being like it was like a petition let us promote body. So we were like okay fine. We we have a question from Mario Anthony Sinario. Bravo. Are there more Loki exporter examples? What do you mean by loi exporter examples here? I think for configuration I think he's saying like the configuration that we were talking about right now because this Loki exporter thing sounds more like OTLP thing to me. Is that not the Loki the the old Loki exporter like we used to have that plugin in the hotel? Um I think I think we are trying to do away with that. We're trying to move away from it and towards the OTLP the new native OTLP endpoint. Um and I think that's that's what we would recommend that you do because the Loki exporter was was something that we came up with before we had the native endpoint. Yeah. Also he says hello from Peru. Hola. Hello Salvo. Um, but okay, let's let's talk about uh oh yeah, we were talking about the those labels that by default are promoted those those the structured metadata that are automatically promoted when we see them. And I wanted to point out that this is one of the benefits of following OTEL semantic conventions because if you had you had other other structured metadata that are where the attributes are like named slightly differently then we're not going to be able to do that. And it's so nice to have that done for you to to be like it is a little bit more opinionated but it is good to know like these are safe to be labels and and some of them are not. So I think one of the best practices for structured metadata would be to use hotel semantic conventions if you're if you're instrumenting with hotel anyway. Yeah, fully agreed. I think the only one I like discovered which might be a bit of a no no in Python land um and we've kind of left it in there because we don't want to have a breaking change is let me get this one right is the um service instance ID because it turns out in hotel semantics service instance ID can be unbounded because it's basically like potentially a thread count in in Python land. I don't know if that extends to multiple languages. Um, but yeah, that was one we were like, maybe we should demote that to structured metadata rather than it be a label. Um, but because so many people use it as a label currently, it's just something we've had to sync like what we do with pod, right? And let people slowly wean themselves off of it. Um, but yeah, I think that was the only big one that I had on there. Yeah. And also like the the semantic conventions for logging in hotel that's still I mean it's technically still not stable. It's still in development. So it's constantly changing and it is a pain to keep up with. But we also have a lot of hotel contributors on our side that are making sure that um that everything hotel is is is going to be compatible with our stuff because we're using it too. So, um, that's another reason to to be up todated with a with hotel semantic conventions because if you're just using that, then we will do the guesswork of of like figuring out what needs to be a label and whatnot. But what else should we do? What are what else are some best practices for using structured metadata in general? Yeah, I I think one topic that we didn't touch base on is if if you already have things in a structure metadata, sorry, in the log line, should you extract everything into structure metadata just because it can be faster eventually? And the answer to that is no. Long story short, uh long story short, uh is that you still you you would still ingest and have to keep both things, right? So you would be storing twice as much data. You would need to process like on the ingestion part twice as much data, right? So it if if you're not using hotel and you're shipping everything in the lock line, it makes sense to use a structure metadata to add things that does doesn't already exist in the lock line or things that you query very often and you see some query performance impact on that would be the the rule of thumb here. Yeah, that is the that is like super confusing. When I first started using Loki, I'm like, okay, so there are labels, then there's structured metadata, but they're both kind of the same thing except one is like like how do you know what the difference is? And then you can also have them just in the log line, which you can also query. So, it's like how what do you put where? But I think um I the way that I think about it is like it's it's performance. it's how how often you're going to query something and also um how fast you want it to be. So something like the source, you know, or or the environment or something like that, that's a good candidate to be a label. And then for structured metadata, um it's like kind of like the next step down where you know, you you might not need it to be a label and it is a little bit less performant than than having it indexed. Um, but it's still faster than if it's in the log line. And then the log line is like, well, sometimes this sometimes I have to search for this and it might be really expensive or it might take a really long time, but that's more okay for me because I don't run it that much. Is that is that also what you would say? Yeah, I think that's a I would say like in general that's a good rule of thumb. Uh luckily we do can configure those things and as a low key operator you can learn on the go and make decisions uh along the way. Right? So one of those decisions would be uh oops okay my index is blowing up. Okay let me get rid of this label or it's like like getting a lot of cardality whereas it the was not having that much cardality in the past. let's move it to the structured metadata, right? Or the other way around like um I have this dashboard that runs like this expensive query looking for this specific JSON part. Uh okay, let me extract that to structure metadata. So I can just like filter by it right away without doing any parsing. Or the same for a recording rule that evaluates I don't know every one hour and needs to go through many many logs like it makes sense to extract those things that you are recording into a structure metadata so you can filter out like e easier. Um so yeah that I would say that's generally the the rule of thumb here. So you you touched on a minute ago about like the um the idea of size. It's like you could have like twice twice the amount if you've got it in the body and you've also got it in structure metadata. And I think this is a champion question because this is this we're getting into like monitoring our Loki instance. And this this feels like a champion question. Anyway, um the question is I might actually copy and paste it and see if we can have it uh come up in the channel. We'll see if this works. Um but the question that was asked was um the Loki distributor bytes receive total um does that include structured metadata or do they need to use the Loki distributor structured metadata bytes receive total and combine them to get the total volume of your log. Mhm. Yeah. So the distributor bytes receive total already a cones for the structure metadata and the content of the log line. The other metric that we have is specific for structured metadata is useful for you to know out of the total bytes received how much was a structured metadata. So for example in some in the hotel world you would see that most of the bytes received actually accounts for the structured metadata. H whereas outside OTAAL world you you would see the the other way around. Gotcha. So you could basically subtract the the structured metadata from and then you would just get your log body and you can see kind of like the proportion of which and kind of where you're putting most of it like per. Yeah, exactly. To to put like another example touching by to what we we discussed early on is if you have everything in your lo line and now you extract everything on a structure metadata but keep it in the log line, the bytes received total will be twice as much. Gotcha. And so I guess like Oh, sorry. Um, no, I was just going to say that was a that was a champion question from Avananisha. Yes. Awesome. Thank you, Avananish. Fantastic. That was I I sensed it. It just gave me the ultimate champion question vibes. Um, I guess the Yeah, sorry. You go for it. Sorry, Jay. Uh, I was just going to say like you talked about how you shouldn't have um you were talking about whether you put something in the log line or if you add it to structured metadata, but if you do decide so you're talking about why you know you why you shouldn't um necessarily like the difference between the two, but like if you do decide to move something to structured metadata, should you delete it? Should you try to delete it from the log body? you had more we're on the same wavelength because this is as well in the script. Yeah, I would say in most of the cases that's not necessarily as long as you extract like only like a small set of labels out of the log line. I I I don't think it's worth the extra complexity of setting the pipeline to remove that specific bits of the of the log line. I I I don't think that would make sense. Now, if you happen to decide to extract everything into structured metadata and you don't want to to ship twice as much data, then you probably need to. But but yeah, the general rule I would say is you you don't usually need to. And is there any effect if you have like very a very tiny log line and then everything structured metadata or or a label like is that is that okay? Are there any issues with that? I would say on an ideal world that's probably what happens with O tell the most, right? It's like you have a lot of metadata instruction metadata and the log line can actually be like something relatively small because that was I guess my thought as well was like that I had this idea in like the Loki pipeline and alloy. You basically do exactly what Nicole said, which is like extract like basically pull everything out into like the the cache and alloy and say, "Okay, these are all going to be structured metadata and then just use the log format component in alloy." And then I'm thinking about it, it's like you could just be left with a very tiny little log line that comes up in Graphana and it's like now you have to click the drop down to see like all of those structure metadata attributes. Is is there a way I guess in graphana to like say you've like especially in hotel can you kind of like resurface those so it makes it look like they're in the body when they're when they're not in the body if that makes sense. Yeah. So there have been discussions around that uh to maybe do some line formatting magic to put everything into a lock line but we do have seen like some mix result with that. So what we end up doing is implementing this table view. I don't know why we look smaller now. We all kind of adjust slightly to the in frame. Yeah. So that that's why we implemented this like table view that we saw like in the demo early on. Uh and in that table view you can select like show me all the labels and that will give you like a column for each one of the structured metadata fields that you want to see and it's really cool because you can filter by the column right away. So yeah has it it tricks. Yeah. So so the um you know how you can do a line format or a label format. So does a line format work for structured metadata too? It does. Yeah. So in in general in the line format you can put like any label that you want inside there. So that label can be something that you parsed previously on the on the query and you want to put it there or that can be structured metadata or that can be an extreme label as well. Is there a point or is there like a tell when you would say there's too much method structured metadata? Uh I would say obviously when you start hitting like the the limits that we were discussing early on and you start seeing uh things dropping. Uh other than that I'm sure there might be but there is nothing that comes to my mind right away. Yeah. Uh there's a question here that is exactly the next thing that I wanted to to get into. Almas Vagabov asks, "Is there a difference in query speed between filtering by fields in structured metadata and running a query using just a regular expression?" So, we had already talked about how it's it's still faster to use structured metadata than to use reax on on the log line, but like I want to get into it a little bit more like about the resource consumption and performance with with those three things. querying the log line usually through parsing um and and then structured metadata and then querying labels like what how much faster is it? Yeah. So I I would say in most of the cases is not actually faster uh by itself there are many things on how we query things that actually add more latency to the query itself rather than the filtering bit of each one of the log lines. Um, a net case can be what we discussed early on like having this huge JSON object and you're looking for something like very uh deep into the object structure and you need to do like all the parsing logic and and that stuff or speaking of regular expression you have a very complex regular expressions with many branches that pretty much like end up happening the same that was happening with the JSON portion right that it's like an expensive operation to extract what you Um but in most of the cases if you are just doing the pipe equal match string or a simple regular expression I don't think you will see much performant gain unless the lock line is huge and you happen to be looking at something that is at the very end of the log line so you need to process everything but those are like very very edge cases that probably 95% of the cases you won't run into. Um there is uh one problem with having a lot of structured metadata fields that just came to my mind asking your previous question uh Jack that I think somewhat related to this one is that when you are doing a metric query uh you may run into the maximum series per query limit because you already have like all these labels already extract racted, right? So you you you may run into a lot of inmemory cardality. In that case, uh the what you can do is use the keep or drop commands. So you only keep the the relevant labels. So for example, imagine that as in my previous example, I want to do the sum by user, but beside the user structure metadata, I I have like I have tons of other labels. I would I would do keep user. So I only end up aggregating on that one. Okay. So if it's if you're comparing structured metadata versus versus reax of a query using reax on the log line, then structured metadata is faster. Is that right? But if structure if you're comparing structured metadata to just like pipe equals or not equals then it's not really faster. No, I I wouldn't say it's really faster like at the processing level might be faster but as I said like in this distributed systems we end up having like networking latency that actually ends up adding like more to to that. Yeah. Is there or go on Jay I was going to say yeah it's just like it seems like it's the scenario in which you use it in that potentially you gain performance gains because you've adversely caused yourself a worse crew performance from doing a tunch of ton of horrific passing on like the query and you're like if I had just done it on the other end it would have been fine but at the end of the day if it's very simple just like adjacent extraction and you just pulled one key like it's going to be negligible like the speed increases absolutely Yeah, got it. Yeah, cool. Understood. So, is there a a read latency effect when when logs have a lot of structured metadata? Uh, I would say not. probably in the case where you have like pretty much like everything in structure metadata and you're really close to hitting like this limit, you may see some performance heat, but there is no example that comes to my mind right away. So, I'm just speculating that yeah, there might be some issue around that. But I'm sure it would be way worse like doing like a parse after that. What about on ingestion? Is there a noticeable difference between no structured metadata and lots of structured metadata? Uh I I wouldn't say so because at the end of the day all the attachment of a structured metadata happens more on the h client side right but for TLP but that's like a different thing. So all of that logic actually happens on the client side. So once that reaches Loki, it's very much like making sure that you put the things where they need to be. But there there is not much difference I would say. Now on the OTLP, it has like these extra steps of okay, I have the OTLP payload, I unpack it, and now I map things to index labels, the structure metadata, I drop things and so on. So, we're we're in the I'm just I'm being an active time keeper here because I'm really excited about the last question and I want to drop it. It's a really good question from the champions. Um, Salva, you can't call the safe word of pizza on this one. You can just say you can use the overarching term we're thinking about this because I think it's a really good question. Um, Loki 4.0, Zero. Uh we had a call with Ed and we obviously talked a lot about the architectural changes, new storage format, um new way of ingesting and so forth. Um the question from Mike Zimmerman is um they like how structured data is now um but with the new redesigns of the architecture, what what's that going to basically look like? Are we, you know, are we going to continue moving structured data forwards? How's that going to potentially look in the new land of Loki 4.0? Yeah. So, oh, so sorry. My bad. I I I mistyped. It's not Zimmerman. It's Timberman. Oh, our maintainer. I I was actually going to make the joke of like, it's not our new maintainer. It's another champion. We just got It is It is our maintainer and champion. Sorry, Mike. Uh, yeah. So, I I don't know how much I can answer that question. Not because I don't want to, but because maybe I I lack like some some context on that, right? So, but from the customer perspective, we still need to solve the issue of being able to attach things for lock lines, right? Like trace IDs or solving like this hotel use case where the lock line can actually be small and everything comes in metadata. So, we still need to to store that metadata somewhere. Will that be in the same way that we store structure metadata today? I I don't think so. It's probably we end up using like some columnary storage which where each structure metadata field or the equivalent will have its own column. So we can query faster or process less data. uh but my point is that the the problems for which we build a structured metadata still apply. So we need to implement something that satisfy those requirements. So it will be more on the internal side of things on how we store things. um how we query things like I don't think any of the query semantics will change that much uh but we will probably be able to process them faster or maybe having like better discovery ability about the structured metadata fields that exist like even provide some autocomp completion I don't know like there is a huge world out there to to explore And once we go down the road, yeah, I think it'll change it'll slightly change the like where on the spectrum we fall like what at what point is it better to make it a label and what point is it better to make it a structured metadata? But like I can't imagine us saying like no now that now after Loki 4.0 and all these architectural changes you can absolutely include dynamic IDs in as labels. That's never going to happen. It's still going to be like best practices not to do that. So, it's going to change it a little bit, I think, but like I I don't think it's going to change it that much. I think structured metadata is still it's not going to be obsolete. it's still going to be better for higher cardality like dynamic sort of IDs than labels will be because even though we're making these changes to make querying labels faster, it's it's not going to be it's not going to be no cost or there's still going to be a performance hit, right? So, you still should should not um include higher cardality things as labels. Yeah, I I think that's in general like the the right take here. We we don't know but we we will do our best to to make sure we can answer like those queries like in a faster way or not. I I can maybe like dive a little bit on how structured metadata is implemented on the low level. So we in Loki store like everything in chunks, right? like like a given stream has like a set of chunks that we cut every so often and we put on object store and each of those chunks is just a collection of logs and we happen to put the structure metadata along the lo line. So if you and one within next to each other. So if you want to filter on a very specific structure metadata field, you still need to go through each one of the block lines items and go to the structure metadata section and look for the structure metadata field that you are looking for. Whereas if you we happen to be on a more columnar kind of h way of doing things, we could jump right away into the relevant field that you are looking for and discard everything that doesn't contain that the structure metadata and then filter out on the ones that that we care about. And once we resolve like the rows that we care about, then we extract the the rest because it's it's like a similar vibe to how Tempo has their color storage. It's like they have extra like attribute columns um which you can like add on to. So if we basically this is all sort of us spitballing here as in like there's obviously an implementation going on behind the scenes um but like if we did have them all separated out into columns as you say it's like you just specifically query for that potential stretch structure metadata key column and you only pull th those specific value chunks out and you know those the ones specifically that you need to then run the rest of your query for. Um, yeah. So, we we potentially do gain performance gains compared to, as you say, it's like at the moment we're like row orientated and you have to incrementally go through and look for all of these things. Yeah, exactly. That that actually opens a door to maybe discuss even though I don't know if we have enough time about a feature that we implemented not so long ago that we're like using Bloom filters to kind of try to speed up the queries that were using structured metadata. That was a really interesting experiment that we ran and proved to be somewhat successful but only for very big tenants that had like a lot of data to iterate through. So it really paid off the extra cost of having to store all these blooms and query them to discard a lot of data. Uh what happened is that for tiny customers we were writing like too many things. So actually processing the blooms were taking longer than maybe just like quering things right away. So yeah that we got like many learnings from that that we expect to um to add to to the new architecture that we are working on. So bloom filters are still expected to be around for structured metadata right in even in the new changes. Yeah, absolutely. It's just that we won't use them in the same way that we were using them today. Like we may store more things in blooms or different things in blooms and arrange those blooms like on different places and even making them a firstass citizen in the future. So you don't need to don't look at way more things before deciding whether you need to look for some stuff or not. We we haven't gone uh uh there yet. So time time will will come. Yeah. So I feel like the rule of thumb with Bloomfields because we always get asked it in the community is like you're extremely proficient with low key and you know your way around and you have an extremely large bit of data set. It's an experimental feature. Use it at your own risk and and you know we we do have customers that do get the performance benefits if they're large enough. But for the everyday user of Loki, it's kind of one of those things that maybe sort of wait till Loki 4.0 and hopefully there'll be like better support and use that as that feature rolls into more of like a production side rather than experimental. Um because Absolutely. Yeah. Awesome. Well, thank you so much, Salva, for coming on and and answering our questions. It's been it's been the full hour and it's been so great to to ask you all the things, James. Yeah, absolutely. I I I really enjoy that. So, thanks for uh for hosting me. Um yeah, thank you so much, SA. I really enjoy blitzing through that entire configuration with you. I'm just there like writing notes and like add note here from Selva and so all great. Thank you very much. Anytime. Yeah. Awesome. And if anyone watching this has any ideas on what we didn't cover or or like just ideas for future topics for Loki community calls, this is for you. So give us give us a shout in the comments of what what you want to see next and we'll make it happen. And you know Sal if we can convince Salva to to come back, then we will of course. Thank you everyone for watching and we will see you next month.

