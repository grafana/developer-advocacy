# Meilleures pratiques: informations plus rapides à partir de vos métriques, logs, traces et profils

Découvrez les dernières caractéristiques et fonctionnalités des backends de télémétrie open source horizontalement évolutifs et ...

Published on 2024-12-13T16:32:43Z

URL: https://www.youtube.com/watch?v=FZyMocLRQlI

Transcript: alors vous avez peut-être remarqué déjà queon a changé un peu le titre il est un peu moins spectaculaire que la traduction mot à mot de l'américain pour autant ça ça va être quand même intéressant voilà comme d'habitude vous pouvez poser vos questions donc sur sur avec ce QR code et bah pour commencer en fait essayons de se remettre un petit peu dans le contexte ben imaginons que voilà on est dans le contexte de l'analyse d'un incident et ben en fait qu'est-ce qu'on peut faire lorsqu'on est face à un incident on peut se poser la question de trouver la route cause en naviguant à travers des dashboards qui sont prédéfinis donc avoir un chemin de navigation prédéfin avec des drillown et puis arriver d'une vision assez haut niveau vers une vision plus détaillée technique qui nous donnerait du coup la réponse à notre question l'autre approche serait de partir un petit peu à l'aventure et de se dire que ok j'ai j'ai pas forcément de dashboard qui me donne le chemin vers la réponse vers la la réponse à la question à laquelle je me pose et donc benah je vais naviguer un petit peu dans mes données pour essayer de trouver les choses qui m'intéressent les deux approches B ont chacun un peu leur avantage et inconvénient donc si on utilise un workflow bien prédéfini avec des dashboards bah forcément c'est acc accessible à tout type d'utilisateur donc tout type d'expertise de niveau d'expertise dans l'entreprise par contre bah du coup je vais être un peu limité dans mon analyse parce que si jamais les dashboards n'ont pas défini ou prévu à l'avance le chemin de naigation d'analyse qui correspond à l'incident ben on risque de passer à côté des choses d'un autre côté bah du coup si on part un peu à l'exploration ça jusqu'à présent le ticket dans c'était bah une connaissance et une expertise sur les systèmes sous-jacents donc notamment bah la connaissance du langage de requetage de notre back-end la connaissance un peu du métaodèle et des métadonnées autour no données de télémétrie mais par contre voilà si on est à l'aise avec tout ça bah on arrive quand même à trouver des h cas et être assez flexible dans notre analyse donc la motivation des choses qu'on va présenter là elle est essentiellement dans la volonté bah vouloir rendre cette exploration plus facile et plus accessible à tout type de profil d'expertise dans dans une entreprise ou dans une organisation à quoi est-ce que ça ressemble très concrètement ben du coup jusqu'à présent d'ailleurs qui a utilisé de manière approfondie la partie explore de gfana voilà il y a très très peu de gens finalement parmi ceux quiutilisent parce que effectivement ça requiert une connaissance du langage de programmation de de requettage et donc bah du coup on se retrouve à devoir écrire nous-même les requêtes qui sont assez complexes et l'idée c'est de passer à quelque chose d'un peu plus graphique et un peu plus intuitif on va jouer avec des filtres on va avoir des choses qui sont projetées sur des graphiques qui s'affichent dynamiquement et on va petit à petit euh driver notre recherche dans nos données et puis trouver ce qui nous intéresse donc voilà on rentre un petit peu dans tous les trends du moment donc il y a eu le serveur less stateless et C ben en fait nous on est en train d'introduire ce qu'on appelle le queryess et donc c'est implémenté à travers tous les les applications explore Matrix et explore logs trac et profil qu'on a mis à disposition de nos développeurs enfin des utilisateurs gfana aujourd'hui je passe donc la main à Cyril qui va vous faire une démo sur la partie export Matrix et log ouais alors c'est encore moi c'est la dernière fois pour aujourd'hui on va faire une petite démo donc si on peut changer l'écran j'ai reculé h parfait merci alors avant que je commence première chose donc je vais faire une démo de explore explor et explore je commener par M check on peut faire tous ces toutes ces démos chez vous sans sans moi si vous voulez les essayer vous-même n'hésitez pas au niveau de explore log je vais le regarder version grafana 11 11.3 à partir de si vous avez ça installé chez vous normalement c'est bon chezun qui m'a posé la question je me rappelle plus c'était si s'ils avaient 11.3 mais c'est apparemment le minimum que vous avez besoin d'installer il y a pas besoin de d'être très technique pour l'installer apparemment c'est dans le pluging catalogue donc vous allez dans le pluging catalogue de grafana et vous êtes censé pouvoir installer ça puis après il vous faut juste un Ly euh donc moi ce que je vais faire pour pour le rendre un petit peu plus facile je vais le faire sur playgrafana.com je sais pas si vous connaissez ce ce site en fait mais c'est un site qui est accessible à tout le monde sans avoir spécialement de euh de de compte grafana et puis vous pouvez jouer un peu avec des des données qui sont là puis on va faire ça là ensemble donc donc toutes les explore app je l'avais déjà montré tout à l'heure elles sont en dessous de explore donc on a matric log trace c'est et profil donc on va commencer par matrique euh donc la page d'accueil vous montre un petit peu donc là a été refaite récemment on est encore en train on travaille on travaille souvent sur ce sur ce produitl donc la page d'accueil elle vous montre les dernières mîtriques que vous avez regardé donc on appelle ça les les les récentes explorations euh puis là on peut en commencer une nouvelle euh donc le le principe hein c'est vraiment on vous montre un écran qui est pas vide comme dans les les anciens explor où il y a déjà des informations puis on peut commencer à se chercher on sent pas totalement idot et on a quand même des choses qui se montrent euh dès le début euh donc du coup là j'ai quand même pas mal pas mal de métriques on peut utiliser un petit filtre sur le côté ici qui s'appelle c'est un filtre par préfixe je sais pas si vous connaissez les les métriques promotus commence tout par un préfixe donc par exemple si je tape Go ça va être toutes les métriques de type Go que que le client Go automatiquement ajoute donc si on fait ça benah là on va être déjà on va réduire là déjà pas mal de dans les métriques on en a un peu moins et puis en plus ensuite on peut continuer à chercher donc je peux limiter mettre duration par exemple puis là c'est c'est du pH searching donc si jamais vous avez pas le mot exact il va quand même réussir à s'en sortir du moins j'espère si c'est pas le cas on peut ouvrir une isue sur le sur le ripo comme ça on essa de travailler là-dessus euh donc on essaie de on essaie de de de de comprendre un petit peu pour vous les les métriqu et de choisir les les les visualisations qui vont avec cette métrique là donc là par exemple celle-là on a considéré que c'était une gaage et puis on a fait un un average ce qui est pas forcément toujours correct encore une fois si vous trouvez des des erreurs n'hésitez pas à à changer dans l'historique ici chaque chaque fois que vous faites un pas vous pouvez revenir en arrière de de de de sur le dernier pas pour revenir et recommencer en fait là où vous en était donc l'historique petit à petit grandit de plus en plus donc n'hésitez pas aussi à utiliser ça pour revenir en arrière euh du coup je vais vous montrer une des dernières features qu'on av av donc dans les peut-être que on les appelle latin je pense je voulais vous montrer les histogrammes ok donc là on en a un ici on va utiliser celui-là donc là il a détecté que c'était un hisogramme promoteus par défaut il me montre une h map donc en fait c'est chaque carré est un bucket dans lequel vous avez les latences qui tombent donc par exemple pour celle-là on a à peu près euh 1,6 requêtes qui sont dans cette latence là ou en dessous donc on peut voir que relativement ça se passe bien on est plutôt toujours dans le dans le bas c'est pour ça que en bas c'est un peu d'une couleur un peu plus clair c'est parce que c'est là que ça arrive le plus et en haut ce sont des extrêmes qui arrivent que de temps en temps donc ça c'est c'est un histogramme qu'on voit en mode hmap mais je sais qu'on est peut-être plus utilisé on est plus on a plus l'habitude de regarder un peu en quantle donc là c'est du du 90 per 99 percent 90 percent 50 percent donc on fait la requête pour vous je sais que moi en tout cas euh qui qui connaît bien promql à chaque fois je suis à deux doigts de taper sur internet comment on fait un histogramme quanttile sur un euh sur un histogram alors que bon c'est c'est c'est su by et ensuite on met l' hisistogramme par-dessus mais c'est un peu bête faut toujours s'en rappeler en fait là on fait la requête pour vous vous pouvez pas vous tromper euh donc dans l'overview ben on a tous les labels qui sont euh attachés à cette métrique euh et donc quand on clique sur breakdown on va la voir et et on peut aller voir un petit peu le breakdown pour par rapport à tous ces labels donc on pourrait par exemple regarder par span par span name on a plusieurs visualisations là je suis en mode grid ce qui est un peu pénible avec la mode grid ce qui est bien avec le mode grid c'est que quand vous en avez beaucoup au moins pour en afficher beaucoup d'un coup mais si jamais vous voulez faire un zoom un petit peu sur une zone c'est un peu plus facile de voir de l'alignement en fait avec le reste donc quand on veut faire un zoom c'est un peu plus clair qu' on est en train de faire un alignement voilà donc là j'ai fait un zoom j'ai envie de l'enlever je reviens en arrière hop alors on va repasser en comme ça donc euh je vais remettre en grid et on va prendre le span name donc quand je le sélectionne on rentre dans ce label là et il remontre toutes les séries différemment et puis on peut refaire la même chose on peut repasser en mode donc là on peut l'avoir en single si on veut on a un seul et on voit tout le tout le breakdown et quand on est en single en fait on peut pas spécialement faire de filtre mais si on repasse en r on peut en sélectionner un on peut dire je veux juste la span pizza generation ou name generation et puis on va voir simplement C donc là je vais mettre en grid puis on va regarder qu'est-ce qu'on a d'intéressant donc on a on peut aussi donc choisir comment on va ordonner les séries là là il choisit tout seul et pour lui c'est les les Outers en premier mais on peut faire des du alphabétique si on veut donc voilà donc du coup on va aller prendre une opération celle-là donc quand je fais ça maintenant elle est ajouté dans mon filtre en haut et je garde en fait ce filtre ce qui est intéressant c'est que Ben j'étais en train de regarder cette métrique là s'il y a d'autres métriques qui aussi ont se labelle avec ce filtre là en faisant une select new matric je reviens on va tomber sur toutes les métriques qui l'ont donc comme on voit ben c'est un peu le même genre de métrique on était dans du trace span matric donc là je peux changer de métrique et aller voir une autre métrique qui qui avec lequel ce label continue de marcher et puis on peut refaire la même on peut refaire la même chose euh si je vais dans related matrique normalement il va me sortir les deux autres forcément parce que elle se ressemble mais si on était sur Go il m montré toutes les GO enfin il y a plein de plein de petits trucs Opin comme ça qui sont très intéressants euh je vais revenir encore plus on va essayer d'y arriver je suis je pense que c'était celle-là voilà là je suis revenu sur le le l'histogramme en mode qutile euh là ce qui est intéressant c'est que je peux aussi maintenant ouvrir dans explore et puis finalement j'ai la requête et je peux partager ça à un copain et dire regarde ce que j'ai réussi à faire et il va penser que je suis un pro en en promql donc ça c'est les trois requêtes qui me donnent les trois quantiles comme vous voyez c'est pas quelque chose qui est comme natif pour tout le monde de de de refaire ça puis ça aurait pris du temps aussi parce que j'aurais fait la première je l'aurais raté et il aurait fallu que je copie plusieurs fois donc c'était un petit peu plus fastidieux donc même moi en tant que professionnel ben j'ai quand même je commence à utiliser de plus en plus ce produit pour aller plus vite euh mais parfois ben il y a toujours des des petites fonctionnalité promql qui existe pas dans dans le côté explore explore Matrix et donc du coup je repasse en mode explore normal ok on va passer à explore log ok donc je reouvre ça donc là pareil on a on a ça fait on arrête pas de d'ajouter des nouvelles euh des nouvelles fonctionnalités donc n'hésitez pas à mettre à jour souvent par rapport au lancement à la grap anacon il y a ple de petits trucs et je vais passer au travers rapidement là pour vous montrer un peu tout ce qu'on a fait euh donc déjà la la page de démarrage avant on avait juste les services et on pouvait juste rentrer dans un service et puis un des gros un des gros feedback qu'on a eu de la part des utilisateurs c'est ben moi service en fait c'est pas quelque chose que j'ai vraiment adhérer je suis plus avec des clusters je suis plus avec autre chose donc vous avez la possibilité d'ajouter vos propres votre propre labble qui qui fait du sens dans vos équipes pour faire pour pour démarrer votre exploration donc là on a les ces trois là mais on pourrait très bien dire ben moi nous on travaille plus avec des namespace dans nos équipes puis là du coup en fait on va avoir tout qui est par namespace puis on peut regarder tous les namespace qui existent euh on peut commencer déjà aussi à filtrer si j'ai envie donc ça c'était pas possible si on vous si on voulait si je reviens par exemple alors c'est dans namespace je dis celui-là là je l'ai ajouté en filtre je suis pas allé voir les log et si je reviens sur service je vais voir que ceux qui sont dans ce M space là donc la page de démarrage a beaucoup changé depuis depuis le début elle vous permet vraiment de commencer à faire des filtres sans avoir spécialement à à à faire de grosses requêtes sur toute sur toute votre données puis vous pouvez aussi y aller à la main enfin à la main c'est pas vraiment la main mais pour commencer à taper d'autres filtres si vous avez envie à n'importe quel moment on peut commencer à rentrer dans l'expérience ou en cliquant sur sur un des services ici donc si je clique sur celui-là je vais rentrer dans l'expérience avec ce service là euh donc des petites features qui sont intéressantes les trois euh on détecte automatiquement les niveaux de vos logs on essaie de faire en tout cas au mieux si c'est pas le cas vous avez toujours la possibilité de le configurer on peut s'amuser par exemple à cliquer sur erreur ici puis va commencer à filtrer automatiquement seulement les erreurs on voit le filtre qui s'est rajouté ici donc on peut le mettre l'enlever on peut faire des recherches si je veux si je veux voir si c'est quelque chose lié à même cach on peut voir juste les erreurs même cche donc on peut commencer à faire des recherches juste en tapant des mots clés donc là on a un petit ça c'est N aussi on peut faire des recherches en en sensitif et pas sensitif au niveau de la CE je je sais pas comment on dit ça en français on peut passer en mode table donc ça mode table à r je l'utiliserai tout à l'heure quand on regardera sur des logs qui sont en JSON on a encore un breakdown ici par label donc là dans ce service là ce namespace là ça c'est tous les label et tous les breakdown possibles et puis on peut encore une fois l'utiliser ça ressemble un peu à la page de départ ce que j'aime beaucoup moi c'est les field donc là les fi c'est tous les fils qu'on a soit détecé soit que vous avez envoyé en plus des labels et puis là on peut avoir des fils qui sont intéressants par exemple le par type d'erreur ici donc on a le nombre de on a le nombre de d'erreurs par seconde et le par type d'erreur donc on voit qu'on a que que seulement deux types d'erreur alors je vais essayer de changer de service pour vous montrer un service avec quelque chose [Musique] comme du par exemple allez hop NG Jon attends hop voilà donc là dans ce on pourrait peut-être montrer il faut que j'enlève ça alors je vais recommencer eng x Jon ok donc là on a des logs en JSON on peut passer en table ou c'est un petit peu plus le Jon c'est dur à lire une ligne c'est quand même pas mal compact en le passant en table on peut s'amuser en fait à montrer juste les à enlever tout ce qui est tout ce qui fait partie du format et puis on peut aussi ajouter des champs les enlever donc ça va modifier la table pour la rendre un petit peu plus intéressante euh au niveau des field on en a encore plus donc là par exemple je me retrouve avec Ben le nombre de requêes par seconde par host qui est automatiquement fait à partir de de mes logs et puis pareil je peux faire des includes excludes euh et et automatiquement on va filtrer au niveau du sorting on a on a ajouté du machine learning un petit peu donc on a plusieurs options intéressantes je vous laisserai regarder ça si vous avez le temps à la maison moi je sais que le outing value et le Revel c'est les deux qui marchent le mieux pour moi et souvent me montre de suite s'il y a quelque chose d'anormal et puis on va faire dernière feature et donc je vais juste vous montrer alors space service je vais essayer de trouver un service intéressant je pense que c'est celui remettre en log ok je pense que celui-là est intéressant alors celui-là en fait il y a une erreur on la voit là un petit peu elle se montre de temps en temps mais si vous regardez le log clairement on la voit pas en fait l'erreur elle elle y est pratiquement jamais puce qu'il y a que 1000 résultats il faudrait que je zoome au maximum pour être pour tomber pileepoil au moment où l'erreur arrive et et puis je vous parle de ça parce que les patterns c'est là que c'est intéressant en fait on a 230 logs par seconde qui ressemblent à tout va bien et il y en a un de temps en temps on le voit ici là il est beaucoup plus bas qui qui en fait est une erreur donc les patterns ça sert un peu à ça à classifier vos logs en fonction de son format et puis rapidement vous tombez sur peut-être quelque chose qui était pas visible avant ça enlève un peu du bruit puis là ce qui est rigolo c'est qu'on peut une fois que je l'ai trouvé je peux faire inclule et quand je reviens dans mes logs je vois que cel c tout ça ça a enlev tout le tout le tout le succès tout le bruit du reste euh et puis forcément comme il a on a quand même des fitures qui sont similaires entre les deux applications vous allez retrouver on essaie de de garder ce quand vous avez appris quelque chose dans une application vous pouvez le le le mettre sur une autre application donc on peut aussi ouvrir dans explore et puis là dans explore ben en fait on vous a montré la requête que nous on a créé pour pour générer ce graphe là et donc du coup vous pouvez apprendre l'ql en vous amusant à cliquer à cliquer partout moi je trouve que ça marche bien dans les équipes qui qui essayent qui surtout des équipes SRE qui essayent de euh de d'entraîner leurs leurs ingénieurs d'application et avec ça on peut leur apprendre et puis leur montrer les requettes cool on peut repasser au slide je crois que minut ouais ouais ouais donc ouais c'est toi tu veux le faire le Le Rest ou je le fais ouais comme tu veux ok donc hôel support ça c'est sur quoi on travaille euh et puis là c'est une dernière cade juste pour histoire de dire bah c'est c'est plus plus facile on arrive plus rapidement à l'Inside puis on sauve on sauvegarde du temps et puis maintenant à toi al pour les deux autres applications ouis voilà pour faire un petit rappel au cas où il y a des gens qui ont jamais travaillé avec des traces en fait quand on parle de traces on parle de bah pouvoir retracer les appels successives d'une chaîne d'API d'accord donc on transmet une sorte de tress ID qui nous permett de reconstruire du coup les différents temps d'exécution de tous ces appelle qui qui s'enchaîne donc c'est ça qu' qu'on qu'on va qu'on qu'on va traiter lorsqu'on parle de trac le profiling donc ça c'est quelque chose qui est apparu très récemment avec pyoscope B du coup ça va être possible de faire un zoom sur l'application elle-même et de savoir en fait quelle partie du code qu'on qu'on a déployé consomme le plus de CPU ou de RAM et voilà donc ça va nous donner une indication sur bah qu'est-ce qu'on doit corriger ou fixer en terme de de code pour optimiser notre code et et faire des des GS en terme de performance voilà donc un profile à quoi ça ressemble donc c'est par exemple on a un certain nombre de fonctions et puis on a ce flame graph qui nous permet de voir en fait la distribution de consommation des ressources par rapport aux fonctions qu'on qu'on a utilisé ok euh c'est quelque chose qui est extrêmement utile qu'on voit apparaître souvent dans des discussions de Green IT et aussi bah toutes les entreprises qui ont atteint une certaine échelle parce que chaque économie qu'on peut faire sur le compute bah c'est autant de d'infrastructure de mémoire de CPU en moins et donc ça représente une économie d'échelle assez importante donc typiquement l'exemple qu'on a ici c'est Shopify avec l'utilisation du profiling bah ils ont réussi à réduire de 20 % leur facture d'infrastructure sur les applications qui qui faisaient tourner on va passer sur la démo du coup je vous montre à quoi ressemble l'application euh explore trace et explore profile euh alors est-ce que la régie s'il vous plaît est-ce que vous pouvez passer sur merci alors donc vous pouvez retrouver du coup tous les applications explore ici dans le menu grafana donc vous avez la partie explore trace ici ce qui se passe c'est que cette application elle va essayer de raisonner sur toutes les traces qui sont collectées hein d'accord donc c'est toutes les transactions unitaires qui sont qui sont récoltées mais ça va pouvoir faire des moyennes et des tendances sur l'ensemble de ces données là et nous donner bah une vision sur la tendance de ce qui se passe au sein de notre système donc là typiquement lorsque lorsqu'on regarde ici euh je vais mettre là-dessus plutôt voilà on voit ben en fait simplement les les métriques red rate error et duration qui sont présenté ici dans les trois panneaux euh et ça nous permet en fait de répondre à un certain nombre de questions qu'on a lorsqu'on efface à un incident donc typiquement je sais qu'il y a des erreurs dans mon système mais je sais pas exactement quelle est la séquence d'action prévalente qui tombe en erreur parce que j'ai peut-être plein d'erreurs un peu partout mais c'est quoi l'erreur qui est la plus impactante aujourd'hui et donc bah l'outil explore ça permet de répondre à ce genre de question donc là typiquement vous voyez en bas il y a un petit onglet donc lorsqu'on a sélectionné du coup tous les erreurs on s'intéresse aux erreurs on a un onglet route cause qui va essayer de regarder toutes les traces qu'il a pu récolter et faire émerger bah la trace qui est la plus prévalente et qui est potentiellement bah du coup la l'erreur la la plus impactante ici donc là bah du coup on voit que il y a une erreur sur un une insertion sur une base de données SQL postgress et du coup on voit que ben ça ça a vu cette erreur là sur 600 span donc 600 traces différentes et après donc voilà ça donne des exemples de traces qu'on pourra aller voir euh en tant qu'exemple pour essayer d'avoir plus de taille détail donc là c'est un exemple donc du coup avec les temps de d'exécution et puis on a le détail de la requête qui est passée ici voilà donc ça c'est une manière d'analyser euh des erreurs euh l'autre aspect qu'on peut faire qui peut être très intéressant bah c'est de s'intéresser au au temps d'exécution donc typiquement euh imaginons qu'on est dans une situation où bah les utilisateurs se plaignent des lenteurs et en fait un peu dans la même philosophie ça va regarder du coup toutes les traces et faire émerger en fait les services ou les fonctions qui sont exécutées et qui ont pris énormément de temps donc là typiquement ça a fait émerger que bah c'est mon service pyroscope chgo qui a pris plus de 1 seconde donc 1,2 secondes sur cette partie car handler voilà et pareil donc on peut aller naviguer là-dedans et puis voir l'exemple d'une trace euh pour essayer de comprendre quel est l'origine de cette lenteur ça me donne un un une très bonne transition justement vers la partie pyroscope parce que justement les traces bah ça donne un niveau de détail au niveau du service mais ça ne donne pas forcément une idée sur ce qui se passe à l'intérieur du code donc là par exemple bah on peut voir le profile de cette fonction là et essayer de comprendre bah où on pourrait éventuellement apporter des optimisations par rapport au code sous-jacent voilà l'autre aspect qui est extrêmement intéressante aussi je vais vous regarder le temps c'est c'est que si vous avez très souvent bah vous avez V micrer mais le le bottleneeck derrière c'est des bases de données c'est appels vers les bases de données qui sont souvent responsables de d'une certaine lenteur et donc on peut se focaliser sur les span d'une base de données et puis on peut aller ici dans la comparaison pour essayer de d'identifier bah quelle est la base de données qui est vraiment impactée qui impacte mon temps de réponse donc je peux naviguer du coup dans les dans les dans les attributs de mes traces et dire que par exemple OK j'ai deux bases de données j'ai une base de données my SQL et j'ai une base de données postcress et ben il se trouve que j'ai plus de de temps de réponse lente sur ma base de données postcress et je peux même aller plus loin parce que je peux aussi naviguer au aux alentours enfin sur l'axe par exemple de mes requêtes SQL qui sont remontées aussi dans les attributs et je peux voir assez facilement bah quels sont les les les requêtes qui sont lentes voilà donc il s'agit notamment des inserts ici sur la table car login et cetera donc typiquement ça peut permettre de répondre à la question est-ce que j'ai pas oublié de mettre un index dans ma base auquel cas bah une certaine requête est lente par rapport à toutes les autres ok il me reste 2 minutes bah je vais conclure rapidement sur sur la partie pyoscope sur la partie profile vous avez exactement la même idée sur la partie profile donc une exploration un petit peu graphique vous pouvez choisir du coup les différentes axes sur lequels vous voulez naviguer et donc ça vous donne le profile d' d'une application ce qui est assez intéressant ACI bah c'est que vous pouvez invoquer un LLM qui vous explique et qui vous donne un peu les pistes de de comment est-ce qu'on pourrait optimiser du coup le code d'accord donc là par exemple ça référence carrément le code ici et d'ailleurs si vous si vous allez ici dans le account service donc ça je vousou montrer vous pouvez même le connecter à votre GitHub et du coup ça montre en fait eu je vais me permettre de connecter voilà ça montre en fait les lignes de code qui sont concernées par la fonction que vous avez sélectionné et pareil donc vous pouvez récupérer des suggestions d'optimisation de code avec un LLM et donc ça dit par exemple pouvez optimiser une certaine mutex est-ce que vous pouvez la réduire et cetera vous pouvez même mettre VO discuter avec avec le chatbot en disant B je veux une version française et donc ça vous génère la réponse en français voilà

