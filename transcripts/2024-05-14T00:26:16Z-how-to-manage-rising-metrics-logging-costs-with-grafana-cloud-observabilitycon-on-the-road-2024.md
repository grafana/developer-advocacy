# How to Manage Rising Metrics &amp; Logging Costs with Grafana Cloud | ObservabilityCON on the Road 2024

In this video, Jen Villa shows how you ca manage your costs for metrics and logs within Grafana Cloud, This talk includes demos ...

Published on 2024-05-14T00:26:16Z

URL: https://www.youtube.com/watch?v=l3KUQ0g_EtU

Transcript: uh all right uh hey everyone uh my name's Jen via I'm a director of product here at grafana Labs uh focused on our databases so if you love Loki mamir Tempo pyroscope uh come talk to me find me at the uh experts Booth after this uh a little bit about myself I grew up in Sunny Miami Florida which means I find myself doing a lot of things outdoors although currently I live in Austin Texas uh I've picked up pickle ball me and uh the rest of the United States it appears uh so for my talk today what are we gonna go over first a little bit of framing the problem why talk about uh cost management for observability at all then how we as a company are thinking about this topic I know Richie already talked about it a little bit in his keynote but I'm going to go into a little more depth then we're going to talk about uh how we're approaching cost management for metrics uh followed by how we're thinking about this for logs and lastly wrap it up with a little bit of uh what's next where is it that we're going uh over the coming months first graphic here to kind of frame this conversation we see that the adoption of observability is happening faster than ever uh this is a graphic taken from the cncf yearly survey where they ask uh folks which of these Technologies are you using in your Cloud environments right and we see that open open source monitoring has uh massive adoption and is continuing to show growth in adoption right now as an observability company we love this right but we believe in the value of observability how it allows you to grow your software systems uh effectively efficiently make your software development teams more effective uh and leads to fewer outages uh faster time to detect and resolve now there can be though some unexpected downsides to the rise in adoption of observability right because it turns out uh that your spend on observability tends to roughly correlate with the amount of data and Telemetry that you're creating this is true both if you're running it yourself in open source right the number of machines the resources required is going to go up or if you're using a vendor right most of them are going to be charging you based on a function of that data that you were creating and storing with them uh we saw this same Trend in the observability survey that we ourselves run where 73% of our respondents uh cited concerns about cost and cost related issue uh as the top thing that worries them as they're trying to roll out observability at their companies right and it makes sense you're trying to bring a lot more teams more and more teams onto your observability platform of choice many many of those teams may not know much about observability or you're busy kind of teaching them best practices and so it's unsurprising that there is occasionally going to be significant spikes right as folks are still learning uh trying to understand you know how do I actually implement this now what we don't want is for folks to get burned by a really bad month where their cost goes through the roof and then suddenly give up on observability right uh it's important to us that the adoption of observability feels sustainable and it's interesting that we saw kind of a similar Trend with the initial move to Cloud right so there was time and it's still probably happening many of you are uh a different stages in a journey of moving to Cloud uh where it felt like everyone was doing this and as this was happening right with this kind of like Stampede of we're all moving to AWS gcp Azure right um uh a bunch of people then saw inevitable cost overruns right all these machines I provision that I forgot to clean up uh that I didn't think about uh and this therefore LED certain people to say hey is you know am I really is the juice worth it worth the squeeze am I really getting all these like mythical benefits out of going to the cloud that were promised to me in some white paper that I read fortunately I would say like to their credit the cloud providers responded to this and they've built a fair bit of tooling into their product to help you understand how you're using the resources now some of you may have different opinions on how good or not that tooling is uh but it is there right so they've they've they've realized that it's important that they give you some visibility into what is and isn't being used how that cost is broken down and so what I would say is that we ourselves are doing the same for observability we want to help you understand where that usage is coming from so you can optimize it so that as you all adopt observability it feels like it's happening in a sustainable way in a way that what you're paying for is align for with the value that you're getting out of it obviously if it costs you more to monitor your application then that application is contributing in Revenue to the business uh that's probably not a very good tradeit right we started this journey to bring more observability to the cost the spend that you have on our platform with our cardinality management dashboards these have probably been around now for about a year and a half two years uh they surface the highest cardinality metrics in your uh graphon Cloud metrics account as well as the highest cardinality labels uh this can be particularly useful when you suddenly see a sudden jump in the amount of Time series you're sending to us and you're trying to figure out where did that come from oftentimes the uh top cardinality labels uh will help you find some very interesting things such as how come someone is making error message a label on my time series uh we built on top of the cardinality management dashboards and we added another feature known as usage groups this is going to let you count the number of Time series over time associated with a particular label uh key value so if you want to count how many time series are associated with product equals gen's amazing product you can track that over time you could even choose to alert on it in case that count of Time series exceeds what your expectation would be and uh probably our flashiest and most exciting uh feature in this sphere of cost management uh we built this great feature called adapted metrics uh and I'll be using kind of the latter uh bits of my talk to go in a bit more depth here uh this is one I could probably talk about for days uh it has made me certainly lose days of sleep uh during its development uh so far though what you see is that we have provided a lot of Tools around cost management now unfortunately it's kind of been up for you up to you to hunt for the right one though which can get in the way of you taking advantage of them because you have to click around in rui find the right documentation page uh and figure out all right for what I'm trying to do today as relates to managing my Bill what should what should I be using so we realized we needed to do a bit more organization of these tools of this feature set to make it more accessible to you and so to do that we thought about okay what are kind of the classic jobs that you all are doing as you're thinking about managing your costs and we thought about it for ourselves as well right we look at how much we internally spend on observability so that for Gra a cloud and we kind of bucket it into four common use cases or pillars right the first being inspection I want to know you know where I stand today with my usage what's going on with my overall Bill second is attribution or cost segmentation which teams which groups within my company which products within my company are responsible for which fractions of my usage uh three is optimize all right now I have a sense of where my usage is coming coming from how do I figure out which pieces of it I could trim down and the last piece is Monitor okay how do I proactively set some alerts or kind of follow along with this so that I don't have these uh unexpected spikes or overruns in the future or at least I'm made aware when they're happening uh and so using that kind of philosophy of how we would organize uh cost management features and the jobs that you all are trying to get done uh we have brought all of our cost management features together into what we're calling the cost management Hub in graffic Cloud so it's live in all your environments uh and you can uh take a look at it under the administration menu and it's going to bring together uh the various pieces of graphon cloud that help you understand and look at your spend now I'm going to spend a little bit of time here uh talking about adapted metric which is my favorite tool in the cost management tool set it's a tool that's going to fall into that bucket of optimize right I want to reduce the current spend that I have today how do I do that in kind of a pre-adaptive metrics world we had a lot of customer conversations where customers would say hey right now you know I'm spending more than my organization has in its budget I'm just going to randomly drop metrics because I don't know which of these are useful but I still need to get my spend within some amount what we did with adaptive metrics is we moved beyond that you're not just randomly dropping things without any understanding of where they're being used how they might be useful to you but rather we're going to guide you and help you understand of the time series data you have what's the lwh hanging fruit that you could remove and still actually be able to observe your applications right the uh extreme way to uh reduce your observability bill is to stop stop creating or collecting any time series data we don't want that because if you do that you will have then no capability to observe your applications so how do you find that right balance between here's the time series data I need uh and here's what I'm actually willing to pay for now uh quick overview on how adaptive metrics works uh it's really uh two services so one is a recommendations engine it's going to have these three parts to it uh and the other piece is an aggregation engine which when you decide hey these are the recommendations I would like to accept it's going to actually execute those and aggregate your time series data we're really excited about the recommendations piece we think that's probably the most unique piece of this feature uh at a high level what it's going to do is it's going to to analyze the time series data that you're sending to graphon Cloud looking at what we're receiving and then it's going to compare that to your actual usage patterns what dashboards have you created in your environment what queries have you run in the Explorer over the last 30 days and what recording and alerting rules do you have in place and by comparing what you're sending us to what you're actually using it's then going to come up with a set of recommendations because what we see is that there is a number of metrics that never get queried in any capacity at all and then there's also a number of metrics that are queried in very specific ways such that a certain set of the labels are used but other labels are never used and so what we can do then is say for those labels that really never get used or never needed to respond to your queries we can aggregate those away now I would like to show you if the team back there can uh switch me over to my laptop uh a little bit about what this looks like in our product if it's not working I can just go off the video but yeah all right trying the old unplug plug back end strategy all right okay so uh this is our demo instance of grafana cloud uh here I've dropped us directly into the Adaptive metrics plugin that we've built into grafana so I'm going to give you a little test drive and and explain kind of some of the different features of it uh the first thing you'll you'll see here is a notification of when uh our last uh recommendations for adapted metrics were generated when we first launched this feature we were generating recommendations every 24 hours we've since shrunk that to be approximately every one hour uh so we're really excited that we're a lot more responsive to changes in your usage patterns you know that means if you add a new dashboard we'll pick up that that new dashboard showed up in our recommendations job within a couple hours the next thing you see here is the time series reduction that you're getting from the feature today so right now with the applied aggregation rules I have I'm reducing my time series count by 85,000 so that means I'm sending some number of metrics to graffic Cloud I'm storing some number the difference between those is 85,000 we only charge you you only pay for what you store so your mental math could be multip that 86,000 by approximately your cost per time series and that's how much you're saving in dollars we've got a little overview of how the feature Works uh but I'll jump right into this recommended rules tab uh so here what you see are all the recommendations coming out of the recommendation service and we can expand one of these and you can see that uh we're recommending to aggregate this replica set metadata generation metric uh our recommended aggregation will reduce the time series associated with this metric by 94% uh we are recommending uh aggregating away the replica set label uh and we will aggregate over that label using count and sum functions uh what we've detected here is this metric is actually not in use anywhere in your environment uh so in this case we're aggregating it to a smaller version of itself giving you 94% savings uh but we're actually keeping a sort of a compressed version of this metric in case you know maybe in the future someone might query this uh here's another example this probe duration seconds bucket this metric we've seen it's actually been queried 61 times in the last 30 days uh but we're still recommending that you can aggregate away these config version and instance labels uh because from what we've seen from analyzing those 61 queries none of them depend on those two labels applying an aggregation is as simple as clicking a button and then uh you'll actually see it showed up here in the applied rules tab so these are current the rules that you currently have in place and so when you expand that you can see here's the metric I'm currently aggregating here's the functions I'm applying to it here's the labels I'm aggregating away and here's how I see it being used in your environment today uh should you decide hey I actually want this metric back in its kind of full High Fidelity form I want that label back that's being aggregated away all you need to do is click on this remove rule button uh and the metric will be disaggregated usually takes three to five minutes maybe to apply uh and then you'll have the unaggregated version all right uh so a little bit about how this works under the hood so I'll take you through an example here so let's take this node CPU seconds total metric so this is one metric and there are four time series associated with it right we see four unique combinations of key value pairs created by two labels mode and CPU now let's say our recommendation service says hey I notice that no one is quering this metric using the CPU label in any capacity so I'm recommending that we aggregate away that label CPU and we aggregate over it using a count function how does this actually work in the aggregation engine well we're going to essentially drop that label group uh Time series by matching label sets so now we have a system group and a user group and then we're going to apply our aggregation function uh so a count to each of those groups uh we have a count of two time series in each of those buckets so the result of our aggregation in both cases is two so what do we do here we started with four time series and now we've reduced it by aggregating over the CPU label to two time series it's a 50% reduction in the count of Time series 50% reduction then uh in what gets stored and what you pay for now what does this look like on the graphon cloud back end you can see in red uh this is the time window at which the aggregation is actively being applied what you'll notice at the top this is the result of performing a promql count query what's great is if you look at before and after the aggregation is applied the result of that numerical operation is the same the same thing happens if you look at applying the sum function right before and after the result is the same and this highlights that we're actually aggregating the metric in such a way that the result looks the same so if you're end user you're developer they just keep quering the metric they keep seeing the same value they saw before and after it was aggregated now the panel uh someone who is responsible for the observability bill cares most about is the bottom panel which shows your billable Time series series and you can see that after the aggregation is applied that count of Time series decreases so users are seeing the same results for their queries your bill is seeing a lower number uh I am happiest about adaptive metrics when people tell me I didn't even realize it was there or doing anything right and that's the the dream the goal of this feature we're aggregating away things that weren't really being used so in most cases most people don't even know the difference or experience the difference between an aggregated or an unaggregated metric uh We've since added some Advanced use cases to adapted metrics as we've seen more and more adoption of this feature right we have over 800 customers using it now uh hundreds of millions of Time series being aggregated some folks they love our recommendations but they actually say hey I would like to add additional uh aggregations beyond what you're recommending to me uh I have some knowledge of my system so you can do things now like Define custom rules that match uh all metrics with a particular prefix or suffix so for all metrics matching HTTP request total please drop the instance label aggregated with a sum counter aggregation uh similarly we also have keep label rules so this allows you to say for this metric proxy SQL queries total I want to specific speically keep the name space and job labels but please aggregate away all other labels on that metric another great addition we've made to Adaptive metrics recently is what we call exemptions this has come up because we've had a lot of customers talk to us who said hey I love the recommendation service but this metric metric X is extremely important to my business and I never want it to be aggregated I don't care if it's not an dashboard I don't care if no one's quering it it must remain untouched so you can build an exemption that says hey please never aggregate that metric the same is true with labels we found that many customers have certain labels that are important to them uh sometimes for cost segmentation even you know hey my product label or my business unit label or my team label I want to make sure that that label never gets aggregated away you can set up an exemption that says hey adapted metrics never recommend aggregating away this label for those of you who love as code we recently added a terraform provider for managing these aggregation rules so you can both do so in the guey like I showed you uh or you can use terraform and the last slide brings me to is what I'm most excited about I think this was really in our initial vision for when we started building adaptive metrics but we're only just getting there is this idea of Auto applying the recommendations from the recommender system so in the early days the way this works was adapted metrics make some recommendations human in the loop reviews them and decides hey I want some of these but maybe I'm not so sure about applying these other ones uh as we ourselves and as more of more of our customers have built confidence with the recommendations we are already actually seen people who've scripted this they pull down our recommendations and they just apply them daily uh we now want to make that even easier for anyone using the feature uh this will take out really the human in the loop need to daily interact with the recommendations uh and this is made possible not only by the fact that we're running the recommendations job more frequently now but also based on the fact that we have extended the recommendation strong to not not only recommend aggregating metrics but disaggregating them in response to changes in your usage patterns so what this means is that if metric X is aggregated developer gen comes along today and tries to query it for a label that might not be there anymore the recommendation service will detect this it will propose in its next run actually we should add that label back we should stop aggregating it away and then and next time she comes along we'll be able to complete her query and so this is going to bring us to a world where we're basically dynamically aggregating and disaggregating your metrics in response to how you all are using the system which means that at any given time we are storing exactly the metric set that really maps to the usage you have uh and really trying to find that sweet spot between how much you're paying and the value you're getting out of the system so stay tuned for this one uh we are starting to test it with a small handful of customers if you're interested in this let me know all right with my last five minutes I want to touch a little bit on logging right I've said a lot about metrics we started with metrics because that's where we were hearing the most pain also because fortunately for Loki Loki was really good at storing a lot of logs very cheaply but we get it at some point log volumes get extremely large and no matter how cheap your unit cost is when you multiply it by pedabytes that's still a big number uh similarly we also see more and more companies putting their costs under the microscope and nothing is nothing is Exempted from that kind of a review so we've launched our first cost management feature in the log space known as the log volume Explorer uh and this is I call this almost more like the cardinality management dashboards for logs it's going to help you analyze and understand where your log volumes are coming from and I'm going to show you really quickly uh how that works so if we could switch over to the computer so uh here I am in the log volume Explorer we start with a little video about how this feature works but I'm just going to jump into the feature itself so often times what we see is that uh our customers know uh what particular labels they like to segment their log volume by so for us in graphon labs for example we rely a lot on the namespace label for very kubernetes Centric shop and so one of the first things I might want to do is break down my log volume by namespace what I see when doing this is all right there's about three 33 gigabytes of log volume associated with the production name space uh and 1.8 gigabytes of log volume associated with the dev name space I can do that over an arbitrary time range I have one hour now maybe I want to do that over 30 days uh boom let's say I want to break that down further I can do kind of the next level of segmentation so maybe I want to look at the development name space but then I want to break it down by by job great now I can do that as well let's see how it worked over 30 days nothing like a good old live demo I do it on time I'm gonna I'll show you over the last hour see there we go uh one other nice thing that we have in addition to showing you the total volume so if you look at the total volume over the last hour is the ability to then look at that ingestion rate over time we find this to be very helpful I'll show it to you here we find this to be very helpful because you can see when there's spikes in log volume so if you look here the production name space was pretty quiet up until around 11:15 where we saw a jump in volume this is helpful when you're looking at your bill for the month you're like how did I get to 50 terabytes did something change or was it steady state now you can actually see where the Peaks and valleys were so switching between these kind of two views what is the aggregate uh volume ingested versus you know at an instantaneous moment in time what was the rate of ingestion is really going to help you work back and figure out all right what is the chattiest part of my logging infrastructure which is then going to help you start figuring out okay then how can I start to optimiz imize uh the log spend that I have all right and we're not done there right the log volume Explorer it helps you understand where your log volume is coming from but it's still then kind of on you to figure out all right I've got to go back and B bug my developers to remove some uh lines from their code uh we want to do better than that and in the same way that we introduced adaptive metrics for helping you reduce uh your time series volume for metrics we're actively working on developing adaptive logs using that same philosophy we want to calculate a difference between what you're sending us and what we see you actually querying and use that to create recommendations about what you should be sampling or dropping or aggregating away uh and we think uh this same philosophy uh will really help you be smart about what is it that I want to keep what is it that I want to throw away so that you can sort of maximize the value you get out of your observability budget and with that thank you very much I appreciate the time

