# (Spanish) Kuberneteando con k6 (Café con Grafana #009)

Hoy vamos a echar un café con Jorge Turrado, un SRE en Lidl International Hub, MVP de Microsoft por 4 años, y Embajador de ...

Published on 2024-01-19T05:19:57Z

URL: https://www.youtube.com/watch?v=GCQHZR_cgHo

Transcript: [Música] Oh se acabó la música he sabido de algunos que dicen que les agrada bastante es tonado está bastante animadora todos acá en el Backstage para los que nos están viendo previo estamos acá dejar una hora a ver si te Hola a todos Bienvenidos a este nuevo o siguiente episodio que tenemos de café con grafana eh donde les traemos a otro invitado muy especial que viene acá eh mostrándonos casi literalmente en el pecho de qué viene a hablar un poquito por supuesto orgullosamente casero o kero cómo se dirá ker este tenemos hoy con nosotros a nuestro amigo Jorge turrado que viene a platicar Uf un montón de cosas entre componentes casis kubernetes y unas que otras aventuras También peculiares acá que ya nos comentaron que va a haber ya spoilers vamos a platicar de actividades extracurricular de Jorge interesantes e Pero bueno Bienvenidos a todos hoy tenemos también a algunos anfitriones especiales así que sin ningún orden en particular vamos a empezar alfabéticamente Antonio bienvenido muy buenas Cómo estamos de dónde reportamos estoy reportando desde España desde Cádiz aquí y nada encantado otra vez estar por aquí después del parón de de navidades y listo nos habías hecho falta el episodio anterior Así es bueno tenerte acá de regreso y como ven Nicole sigue ocupada pero tenemos Oh Wow me acabo de dar cuenta creo que soy el único no español aquí en el show tenemos a nuestra amiga ima ima cómo estás hola buenas Gracias por invitarme si no me equivoco es la primera vez que viene es al show verdad sí la primera vez que he conseguido venir Fu conta que ha conseguido No es porque no la hayamos invitado ojo ya ha habido un par de veces que casi lo logra pero casi en finalmente poder venir y además con jor conozco mucho Yo estoy en Barcelona así estamos todos en España excepto le Ya sé eh reportando yo aquí su amigo Leandro bueno no me quiero brincar a Jorge el orden alfabético Jorge De dónde estás reportando yo desde país Vasco desde Victoria al norte donde siempre hace frío o mucho calor en verano Define mucho calor bueno el año hace dos años en la ola de calor marcaba 47 gr Yo me quería arrancar la piel Oh Wow [ __ ] esa ola de calor Mala mala que nos vino Yo sé que 47 por el sur debe de ser un verano fresquito per aquí en el norte el 47 es arrancarse la piel Oh Wow y yo que presumo ser fan del calor no ahí sí ya son niveles superiores a lo que Ah 42 no recuerdo pero vamos más de 40 Seguro sí no no no eh familia acá de Sinaloa en México que es un estado bastante cálido y desértico y bla bla bla donde Pues sí 40 gr a la sombra en un verano es perfectamente normal pero ahí están mis límites ya es donde yo así de 30 y algo es el Sweet spot donde alegría por motón Bueno pero no venimos a hablar aquí de climas yo soy Leandro Meléndez reportando desde Ciudad de México el único que no anda de aquel lado del Charco y feliz de pues traer todas estas conversaciones todas estas estoy viendo aquí que tenemos también algunos saludos almudena que vino también hace algunos episodios está saludando a todas las personas favoritas pues yo me llamo Leandro no s Favorito pero no no es cierto e y Tenemos también a Alfonso aquí no sé si celebrando la camiseta de Jorge es que alena Alfonso y Fernando son mis compañeros a intentar trolear pero es un troleo muy pobre esforz es la realidad tenemos que estar gente okay pero es una famosa vata no sabía que tú vas famosa Jorge pero ahorita platicamos al respecto Jorge ya hablando de que está todo el troleo está todo aquí la situación platícanos de ti quién eres qué haces Y qué dijiste puedo venir a hablar con est Yo sí yo puedo contaros cómo estaba arreglando máquinas por el mundo tirado pasando cable por medio mundo cómo estuve en el desierto de Arabia en verano Y en la estepa siberiana en febrero y dije Esto no es para mí okay porque era programador y pasé de programar robots y autómatas industriales y tirar cable a programar visión artificial eso fue mi primer contacto con el performance porque claro un segundo es mucho hasta que empiezas a procesar visión artificial que las cosas pesan y ya de ahí dije esto no es para mí Yo quiero trabajar más tranquilo y ya fue saltando al software y hasta hoy soy un electricista va muy subido esa es la realidad Ok entonces Oh Wow ese es un salto muy interesante que creo que en performance y en testing me ha tocado muchísimo Ver gente que viene de otras áreas de cosas siempre son cosas peculiares también ya me ha tocado quien hace temas de Inteligencia artificial con minería y luego acaba siendo tes todo este tipo de mezclas Pero y bueno todos esos caminos a dónde te llevaron al día de hoy qué te entretienes Qué andas haciendo pues todo eso me ha llevado a dar mi trabajo oficial por el que me pagan lo único que puedo considerar trabajo porque el resto hasta que no me de incom son aficiones estoy trabajando de expert en el grupo junto a almo en el mismo domain Y bueno pues somos los que llevamos la aplicación de móvil del y del plus para tema de pagos tema de todo el tema de loyalty lo hacemos a través o sea lo hace nuestro Nuestra Empresa estamos dentro del grupo sars leel cofl prero otras de fabricación Bueno un clúster empresarial muy grande dentro de Europa Wow y y tú en particular En qué ayudas a toda esa ese clúster de empresas es una buena pregunta y me encantaría saberla pero la respuesta pero no lo sé yo vengo hablo de kubernetes eh digo cosas técnicas y bueno de momento llevo un año y medio Así que algo estará funcionando Bueno ahora hablando un poco más en serio ayudo con la adopción de kubernetes e por cómo trabajamos en mi departamento no soy un sre al uso que está todo el día operando sino que apost por equipos empoderados en mi departament mi dominio donde los equipos son autónomos Y eso implica mucha formación mucha ayuda acompañar a los equipos porque Bueno kubernetes no es fácil Como creo que bien descubriste ayer Leandro porque vi algo de que teníais grabado de antes de navidades no es fácil es una tecnología muy compleja y pues mi labor es ayudar a los equipos básicamente es claro he estado teniendo recientemente mucha exposición con kubernetes De hecho tengo bastante interés en que podamos fluir más en esos ambientes pero me llama mucho la atención que mencionas que tu trabajo es ayudar y convencer o pues eres como un kubernetes advocate me suena en la organización pero no porque la labor del advocate igual está más le más lejos de bajar al fango pero yo sigo bajando al fango o sea mi labor no se aleja de estar trabajando muy a bajo nivel muy conocer las cosas ayudar a los equipos plantearles las soluciones o sea yo no diría advocate porque no estoy cómo decirlo no estoy evangelizando sino que por un lado evangelizo la cara evangeliza la cara ve pasa miseria es uno intermedio un poco no yo no lo tenía podemos decir como una especie de consultor interno yo estoy muy contento me gusta el trabajo yo yo ahí difiero un poquito porque ser advocate no implica que no te metas no es que yo no he escrito un Script de k6 o que no que Antonio no s pelea con el módulo de notificaciones acá de grafana y ha hecho sus es es normal y pues a mí me parece que sí pero me brinca muchísimo ahorita mencionaste que ayudas a los equipos qué Cuál es el reto mayor en ayudar a los equipos o qué se toran más qué es lo que más frecuentemente haces el mayor reto para mí con kubernetes y los equipos es conseguir intentar queere de manera sencilla una tecnología que por definición es compleja kubernetes es muy complejo Y es ahí está muy bien almudena lo sabe claro tu rado educa y divierte Efectivamente es la realidad no pues operar al final kubernetes es una es una tecnología muy compleja y el problema es que no es una tecnología es una plataforma sobre una plataforma compleja añades muchos proyectos aún más complejos y acabas teniendo una amalgama de cosas que no sabes muy bien cómo llegado ahí pues quizás una de la parte más complicada es por un lado luchar contra el hype de [ __ ] quiero meter esto porque mira cómo está porque en cuon todas las charlas van de esto porque ah cómo cómo Va con el tampoco vamos a reinventar la rueda balancear y que los equipos realmente operen porque es verdad cuando tienen un problema gordo de verdad que no saben solucionar a la parte más Cross nos involucran pero en el día a día de los equipos ellos han aprendido a utilizar argo CD están Aprendiendo a utilizar argo rollout lo usan en su día a día son totalmente autónomos operan su clúster tienen sus alertas Y eso sin caer en el hype de Quiero poner todo lo nuevo y aún así conseguir que los equipos lo operen me parece una de las partes más complicadas el balancear velocidad nuevas tecnologías y que la gente lo conozca a mí me gusta mucho kubernetes dedico mucho tiempo pero entiendo que a una persona que de su lo que le gusta es de rollar y le gusta net o Go o lo que sea igual kubernetes dice a mí me da un poco igual es es interesante y suena hay este síndrome psicológico que tenemos los seres humanos heurísticos con el juguete nuevo y tengo la impresión de que kubernetes es propenso a eso impresionante No yo tenía una antes de trabajar de sre estaba trabajando en una consultora y una frase que solía decir es montamos kubernetes por encima de nuestras posibilidades todo el mundo quiere kubernetes kubernetes es muy elástico kubernetes me va a resolver el oro y el moro me va a dar un montón de opciones pero luego he visto clusters con versiones no soportadas de un único noo para ahorrar dinero porque todo eso que se iba a hacer todas esas buenas intenciones de Esto va a ser la plataforma al final fue el proyecto que cerró que nadie mantiene que nadie opera que claro esas cosas yo las he vivido Y sí kubernetes muchas veces genera hype cuando tienes 100 usuarios quizás tres concurrentes una una Landa o un algo no te iría mejor que un kubernetes ya cambiarás cuando escales por ejemplo y es y es todo esto también que dices no hay alternativas hay otras no es nada más por kubernetes ye kubernetes lo voy a brincar lo hago analogía a veces las consolas de videojuegos es el Play 5 todo el mundo lo quiere está agotado no sé pero yo quiero jugar Halo o mi organización tiene alguna otra dependencia eso ha sido un golpe bajo eh para la gente de Sony pues este me gustaba mucho el Halo Ya ahora que no puedo jugar con varios en la misma consola eso también me un poco de pero estamos hablando de cuber netes este no pasa nada Yo estoy de acuerdo la gente de Play no conoce Lo bueno que es que es Halo yo soy jugador de PC Así que ninguna envidia eh okay No esto no sé qué quiera decir eso es que tengo dos perros golfo y que suelen por eso iba a cerrar la puerta antes de entrar suelen decidir salir en cámara cuando a ellos les viene bien no sé si habéis quizás oído no les gusta la fama Yo se oye oyen apare en cámara no pasa nada que se ponen muy pesados no les damos un momento de fama de ser necesario No pasa nada este bueno y retomando un poco el el asunto acá no de que quién Qué haces de tu día a día qué es lo que estás ahí e pues ayudando a la organización a mí me sale ya mencionaste no que hubo este episodio que hicimos tratando de meternos a explicar kubernetes acá almudena me educó pero pues podrías continuar mi educación cubereta Qué es kubernetes qu de qué se trata hay gente que no ha estado eh Muy involucrado o también tengo entendido que hay quienes lo ven diferente y me da Curiosidad no para ti Qué es kubernetes cómo lo defines es una pregunta trampa eher la respuesta de No pues kubernetes al final es una es una es una tecnología que nos permite crear un clúster un conjunto de máquinas muy heterogéneas trabajando Al mismo son orquestando contenedores porque al final kubernetes va de levantar contenedores vamos a hacer un pequeño break que es un contenedor es un proceso que corre aislado en un motor de contenedores no es una máquina virtual ligera no es una máquina virtual la containerization no es virtualización pero podríamos hacer un símil salvando muchas distancias para entendernos lo lo digo así para que luego nadie me diga has dicho que es una máquina virtual ligera porque yo también lo hago eh Y digo eso no es una máquina todos los do quereros ahí linchando a jorges y ya correcto Yo soy el primero No pero bueno Más allá Es porque hay que picar a la gente para que hay alguna de alguna manera Hay que picar Nunca me gustó el fútbol pero siempre me enteraba de qué equipo perdía para picar al de la oficina que era de ese equipo esa es la realidad ya os dije que para trolear al troll Hay que ser muy fino dicho eso al final kubernetes de lo que se va es de tenemos una tecnología que es docker que me sirve para levantar contenedores que levanta procesos pero qué le falta docker escalabilidad temas de auto escalado self healing el poder distribuir la carga el poder orquestar todo eso docker no lo permite hubo muchos muchos sistemas de orquestación al final kubernetes ha ganado la batalla y ya está es un sistema de orquestación que nos permite levantar controlar conjuntos de máquinas muy diversos para levantar contenedores y poder gestionar desde ahí nuestras cargas de trabajo okay Me gusta la no sé si ha sido una explicación simple o no pero bueno no sé cómo explicar kubernetes de manera simple tampoco no sí tiene muchos bemoles y detalles eh Por debajo pero a grandes rasgos Me parece que que por lo que yo estoy entendiendo que es kubernetes apruebo eh No siendo autoridad ni nada para aprobar ese tipo de definiciones pero gracias y me ayuda en mi educación no hay problema ahora también aquí Eso es lo importante eh No Porque hay que ha divertido todo este tipo de e creo que la escuela por eso no nos encantaba si fuese de Uh nos vamos a reír mucho y salir educados No pues ahí estaríamos más tiempo no Oye y hace rato hubo menciones de keda por supuesto qué hijos es keda hay quien opina que puede ser el mejor proyecto del landscape de la cncf a ver a ver a ver espera landscape nsf más términos Qué pasó a ver po tú no has oído lo de solta un tecnicismo y reinicia eso es la manera además aquí vas a tener que soltar algunos de esos y pasarlos al español correcto landscape a ver al final la cncf es una fundación la Cloud native computing foundation la fund Cloud native eh la fundación de computación nativa en la nube suena terrible pero es una traducción libre es un conjunto es un conjunto de empresas y fundaciones detrás que se unieron para intentar que las tecnologías que llevan el foco en correr en la nube tengan un poco de criterio un poco de unificación y un poco de estandarización donde ahí salen proyectos como kubernetes promicious bueno en el en el portfolio de la cncf hay muchísimos proyectos se puede consultar Luego si quieres os paso el enlace aunque creo que poner landscape cncf Ah sí por procurar no tener muchas ventanas abiertas en el browser porque consume rama consume mucha rama el el landscape Pero hay son muchos proyectos y se catalogan En diferentes niveles pueden pueden ser sandbox cajón de arena proyectos que acaban de entrar que se están probando pueden ser proyectos en incubación proyectos que ya tienen un recorrido que han demostrado que suplen una necesidad real que tienen una base de usuarios o proyectos graduados que es bueno la cncf se los plantea como proyectos que se que considera que están listos para producción en cuanto a estabilidad en cuanto a que no te meten un Breaking change de hoy para mañana y Ah sorpresa haber elegido muerte no todo tu producción ya se va Claro que a nivel de seguridad se trabaja o sea trabajan con altos estándares de seguridad de hecho la cncf audita todos los no la cncf la fundación osti audita todos los proyectos para pasar a graduados es un requisito que hay es un nivel de vale el proyecto es lo suficientemente maduro como para que cualquier empresa lo Us en producción con garantías es un poco como catalogan los proyectos Qué es queda pues es un proyecto de la cncf y ahora hablando en serio es un proyecto que cumple que cubre una necesidad hay muchos no puede que puede o sea yo sinceramente no pienso que sea el mejor es el que a mí más me gusta que por eso lo mantengo Pero hay otros proyectos que pueden cubrir otras necesidades y ser igual de buenos Como por ejemplo kubernetes sin kubernetes podríamos tirar todo el portfolio a la basura es un proyecto que se graduó ya no precisamente hbre hbre estaba entre ponerme la camiseta de keda y la de k6 pero he dicho quiero más suag hay que hay que lucir los colores si no Florentino No saca la chequera pero pero no es un proyecto nos conseguimos graduar en agosto septiembre después de un proceso de un año bueno casi un año muy largo con auditorías con reuniones con diferentes grupos de la cncf y ya está y ahora somos un proyecto Pues a nivel de en teoría madurez igual que kubernetes o promicious o cualquiera de los proyectos graduados que ahora mismo no recuerdo todos No pues como dices deben de ser bastantes pero pues muchas felicidades se ve que es un esfuerzo interesante lograr llegar a ese nivel llevar a queda a estos Eh pues ya formal es estable es aceptado es bienvenido a la familia y bueno qué ha se queda todo esto Pues mira te lo voy a decir con un ejemplo tirando para la casa porque eh el suag queda es lo que corre por debajo para que el querier de tempo si no me equivoco no sé si es el de tempo o es el de locky gestione las peticiones de request El querier de manera eficiente es un al final el problema de autoescala loky tempo estaréis hartos de conocer y de oí hablar de vuestro stct Así que no no entro mucho en ello pero al final En kubernetes qué pasa que tenemos fuera de la caja out of the Box tenemos escalado por cpu y por memoria son las dos opciones que hay que te vienen por defecto eso se queda muy corto en el mundo real en el mundo real en un mundo distribuido donde surgen eventos donde no donde las cosas van pasando se lanza un evento Aquí acaba en un Rabbit se mete en un kafka pasan la cpu y la memoria no es real y esto holo un poco con el tema de la performance eh lo habréis visto si os habéis dedicado a performance porque de hecho hay casos de uso casos de estudio por ejemplo zapier hizo un caso de estudio de Por qué queda le beneficiaba diciendo es que para cuando la cpu sube en un proceso totalmente asíncrono basado en eventos significa que el propio proceso está procesando tiene en memoria demasiados handlers esperando es decir si yo no hago el trabajo y yo llamo de manera asíncrona cuando mi memoria sube es porque tengo que procesar tanta tanta sincronía que solo procesar la sincronía consume memoria por lo que voy tarde si yo yo espero a que estando consumiendo eventos de un Rabbit de un kafka o lo que sea y mandándolo a otro sitio mi cpu sube significa que voy tarde porque yo no proceso nada Entonces qué es lo que hace keda keda viene a solventar un agujero que había en el auto escalado en kubernetes queda kubernetes even Driver even driven autoscaler es un componente es un operador que tú pones en tu claser y que sin tener que preocuparte de más te da acceso a escalar en base a no sé si son 60 o 65 orígenes de métricas distintos como pueden ser colas de rabbit kafka pueden ser promius puede ser gcp aws esteet digo Nat pero también incluso tenemos un instalador para loki Por ejemplo puedes hacer cues a tu a tu servidor de loki y ya está igual que lo harías a promicious y en base a los resultados escalar diferentes orígenes de datos Y otra cosa y otra cosa que que da es escalar a cero que kubernetes no lo permite a día de hoy Y eso es una es un beneficio Porque si yo estoy mandando mensajes y tengo un servicio que manda mensajes para que voy a escalarlo si no tengo ningún mensaje que mandar para que voy a estar pagando por una cpu vale no está trabajando está parada lo que quieras pero está ahí Entonces es otra de las cosas que permite queda está muy interesante porque todo este ahorita haciendo un poco alusión que mencionabas no aquí tenemos algo más de información de este eh autoescala que hacías mención eh Jorge eh pero me parece interesante porque me haces pensar no a veces eh queriendo no sé me hiciste recordar a tiempos de pruebas de carga donde tenías que tener varios backends para soportar toda la carga y ponías un load balancer que el estar administrando todos esos backend y tenías demasiados se volvía el cuello de botella irónicamente tratando tú de liberarte de esos cuellos de botella son un poquito lo que queda está ahí también ayudando a administrar no bueno queda en realidad lo que te está ayudando es a por ejemplo Imagínate que tú tienes eh el típico ejemplo tonto de te registras en una web y te llega un mail Claro pero ahora resulta que yo que sé sakira Lady Gaga algún famoso de estos anuncia tu producto y de repente tienes que enviar 10 millones de mails claro Cuál es el tema que para enviar 10 millones de mails igual Tu único contenedor corriendo ahí con la lengua fuera pues no le da Pero tú quieres enviarlo porque [ __ ] vas a perder la oportunidad que te acaban de dar con ese anuncio qué te permite pues te permite extender kubernetes con haar en base al tamaño de la cola de mensajes Si yo tengo un millón de mensajes Pues igual necesito 100 contenedores Y si solamente tengo 50 mensajes igual con uno me vale te permite eso un poco escalar como escalar con cpu y con memoria pero en base a unas métricas que queda Pone acc pone disponibles para el claser mm o sea y estas métricas pueden ser no sé Hardware pueden ser Cuáles es en específico aquí por ejemplo déjame nada más agrego rápido que aquí tenemos eso Por ejemplo esa es al final Tú tienes tu es el el escalador de loki Tú tienes tu instancia de loky donde sea en local en el claser en grafana Cloud donde quieras y tienes un endpoint un endpoint al que puedes consultar pues esto te permite sin necesidad de tener que picarte tú tu código para obtener esa información darle los datos queda se va a conectar a a tu instancia de loki va a hacer la query que tú le has dicho que tiene que hacer y le va a devolver al clúster el resultado de esa query por ejemplo No lo sé porque no sé cómo funciona eh Cómo puede funcionar No tengo tanta experiencia con el stack de grafana pero imaginaros que eh yo quiero escalar mi consumidor o lo que sea si yo tengo mucho tráfico yo me las métricas me están dando o un promicious me está diciendo [ __ ] tienes mucho tráfico o la cpu vale tanto métricas que no estaban accesibles para el claser porque no son cpu y memoria se acaban de convertir accesi Gracias a que este componente te va a hacer de intérprete va a pedirle el valor al origen de datos que tú quieras y se lo va a dar a kubernet Okay Oye y qué valores qué métricas Porque ahorita mencionas cpu cómo está de memoria Cómo están las solicitudes puedo inventarme yo mi valor que diga Ok su televidentes del superb número de personas conectadas o viendo si tienes una que puedes consultar o un servidor grpc por supuesto puedes decirle a queda utilizando un escalador de grp del escalador de de Rest o el de grpc decirle vete ahí y Hazle y pide haz un get Es verdad que hace un get no es el verbo que te dé la gana hace un get que puedes autenticar si responde tú luego le dices con Jason p Dónde está el valor por el que tú quieres y ya está de hecho es una manera en la que podrías controlar el número de instancias Porque si tú le dices quiero que haya una instancia por O sea que que el valor devuelto sea uno por contenedor uno por pod y tú devuelves 12 qué va a pasar que va a ir a 12 es decir podrías incluso controlar de manera externa en una ap y de un que hayas hecho hacerlo rompe un poco con la idea de autoescala hay algunos Pues yo que sé un poco más locos o que pueden ser un poco más útiles Por ejemplo si tú tienes tu agentes de de github tus runners no sé si vosotros por ejemplo habéis usado github actions con Runner privados la realidad es que tener un Runner parado es dinero que no estás usando pero a la vez no quieres que cuando tus equipos de desarrollo estén trabajando estén esperando porque hay dos Runner para 50 equipos y el último paso no quieres ser tú quien vaya y le diga vaya sube la cola por qué Porque monitorizar una cola es un trabajo muy iable Y eso lo hace queda puede monitorizar la cola de trabajos pendientes y decir hay 50 trabajos levanta 50 ranes han acabado los trabajos quita todos los ran por ejemplo es otro ejemplo de lo que podrías hacer Incluso se me está ocurriendo no Casi casi algo de Hardware tener no sé una palanca que diga 10 instancias la bajo a tres manual siempre que mande una métrica y todo eso lo puedo interface bueno eh O sea ahorita se me ocurren muchos experimentos muchas cosas interesantes con esto lo que pasa es que queda opera a nivel de kubernetes es decir queda no te va a Añadir nodos no te va a quitar nodos va a Añadir pots Y eso es lo que va a trigar o lo que va a forzar a que aparezcan nuevos nodos o desaparezcan pero podrías usar métricas del Hardware si las exportas a un promius por ejemplo las mandas a otro sitio las podrías usar perfectamente eso está muy interesante bueno eh y aquí también teníamos otras preguntas un poco más ya Antonio creo que tú tenías unos detalles acá con Sí mira Jorge te voy a preguntar un poquillo hablando de de prueba de rendimiento por ejemplo cómo qué estrategia sigue para para bueno para asegurarte de que siguen siendo eficaces a medida que va evolucionando vuestra aplicación hablamos de aplicación en scrm o hablamos de aplicación en queda eh Qué es srm srm es mi empresa donde trabajo srm le International Hub Okay todas manas que quieras la respuesta en ambos casos es la misma y es lo que diga el muden y puede sonar a vacile pero la respuesta es la misma porque en scrm es la responsable de performance y en keda es la responsable de la performance es maintainer de keda eso se lo tiene calladito no no lo dice pero es mantener no de todo el proyecto pero sí es la responsable del repo de performance y ella es la que diseña y siempre tiene la tiene la última palabra sobre que sobre si algo es útil o no Porque es muy buena en lo suyo Yo soy el mero brazo ejecutor a mí me dicen hay que probar esto y yo hago que se pruebe y que funcione bien pero es El ejecutor dicho eso cómo hacemos esto Pues básicamente por poner el caso de queda al final o una aplicación ella o la persona diseña ciertas diseña ciertas métricas que hay que medir diseña cierta prueba y ya cae un poco más al lado de de proveedores de de proveedores de plataforma conseguir que eso se pueda hacer qué es lo que hacemos pues medirlo un 3 de k6 que alguien hace o que hago yo y que ejecutamos porque k6 a mí me gusta mucho es de decir eso eso iba yo a preguntar porque digo viendo abajo de la bata que pues tienes eh bastante interés en k6 Cómo fue este pues encuentro cómo fue pues acabas de declarar fuertemente estas fuertes declaraciones de que te agrada mucho k6 cómo fue por qué y qué te gusta y en qué lo usas Pues el primer punto es que lo usamos lo empezamos a usar eh tanto en es crm como en queda poco más o menos a la vez y el el hecho de hacerlo el hecho de hacerlo por ejemplo en keda es porque otras herramientas que te dan tercer Bueno aparte de que muchas gracias grafana por el tier gratis para proyectos Open source si hay eh Muchas gracias es es la realidad estamos muy agradecidos en nombre de los maners de queda os lo puedo decir eh pero empezamos con eso y también porque Pese a que teníamos crédito en azure k6 te permite mediante las extensiones del disruptor de de xk6 te permite operar un clúster que es algo que jitter no gestiona tamban bien y que si además te vas al azur elad test que corre con Jer por debajo ni gestiona bien ni gestiona mal no puedes hacer cierto tipo de operaciones en el clúster que por la naturaleza de keda necesitas hacer queda es un operador a qued no le haces llamadas http a ver qué hace queda configuras ciertos procesos y mides Cómo van entonces necesitábamos acceder en directo al claser y k6 nos lo permitía y además nos lo permitía con de una manera bastante elegante que es hago un pipeline lanzo un char de helm configuro con el operador y ya está y el operador lo hace y corre dentro del clúster y dependo del hardback del clúster Y eso cuando nos lo llevamos a es crm el mismo el mismo planteamiento funciona solo que en vez de tener una Vu pues le puedo decir 500 y ya está y añadimos hierro Y empezamos a tirar peticiones como si no valieran dinero aquí se ve que empiezas también como a integrar e interactuar mucho porque mencionas el disruptor que tenemos eh con k6 eh y otras extensiones se ve que también juegas bastante fuerte con las extensiones No sí también tengo hecha la mía para poder traer porque al final queda bueno sin entrar a muchos detalles aunque podemos tengo tengo preparados los enlaces También estamos para los detalles por fa detalles que haga falta como queda no es algo que puedas llamar por Http es verdad que k6 y ojo no es una queja lo entiendo perfectamente el entorno de testing en general de performance testing está pensado para para usuarios en su mayoría quiero decir para cosas que inicia o un browser o una Api si yo tengo que medir algo que no se que no se dispara mediante un browser o una Api sino mediante recursos que yo despliego en un clúster eh cómo lo puedo medir porque claro qué estoy midiendo estoy midiendo queda estoy midiendo la latencia de queda con la Api de kubernetes estoy midiendo la Api de kubernetes Qué es estoy midiendo la latencia desde donde Yo mido hacia la Api de kubernetes eh qué es lo que estoy midiendo en ese escenario Claro en un escenario http una Api es muy sencillo llamo a la Api y yo soy el cliente Si digo quiero hacer en un p9 nu de 50 milis Ese es mi punto de medición pero cuando te vas a unos escenarios un poco un poco más más complejos Es verdad que k6 no llega pero permite que haga yo lo que falta para llegar que es una de las cosas que me gusta de ahí por ejemplo esa extensión qué hicimos fuimos a keda y añadimos una métrica de promius que nos da esa información que queremos medimos dentro del del propio componente dentro del propio workload en el claser dentro de la propia carga medimos y exponemos la métrica de que nos da la información por ejemplo qué métrica es la que utilizamos las latencias consultando los proveedores de métricas o las latencias en loops internos si yo sé que cada 3 segundos tengo que ejecutar el Loop yo puedo antes de empezar a esperar puedo decir voy a tener que ejecutarlo por ejemplo son y segundos y lo quiero hacer cada segundo el siguiente Loop tiene que ser a un segundo si es Ah 1 y medio significa que el proceso no ha sido capaz de Recuperar el contexto de ejecución en el tiempo correcto entonces midiendo la desviación del tiempo en el que se ejecuta con el tiempo esperado que queremos ejecutar podemos determinar de una manera bastante bastante acertada si estamos en una si estamos en una situación de mucha carga por qué porque al final si eso es un es un for en Go donde haces un slip dices empieza el eso hago no sé qué voy el siguiente ciclo es a esta hora y hago slip hasta esa hora si yo no recupero el contexto más o menos a esa hora significa que la cpu está que no da más que es un poco lo que nos puede pasar en un Force sin un slip en cualquier proceso si yo no llego a la velocidad a la que Espero llegar significa que la cpu está a más del 100% o debería estar a más del 100% y tengo un problema sea contención throttling que es muy conocido en kubernet es el famoso throtl la contención sea que que el nodo no da más por la razón que sea entonces medimos esa desviación y la exponemos en la en nuestra prueba lo que hacemos Es recojo Esa esa métrica desde queda y la mando a O sea la recojo desde un promicious y como soy bastante vago la mando a grafana a grafana Cloud Gracias por el por la cuenta de Open source la mando a grafana Cloud porque luego nos permite hacer paneles y poder utilizarlo pero yo la quiero en mis en mi test yo quiero que el test falle si esa métrica No si esa si ese valor se desvía lo quiero en grafana en promicious pero la también lo quiero en el test Entonces ahí es donde empezaron las fricciones no tenía ninguna manera de quef de que el propio test de k6 leyera de un servidor de promicion no leyera para hacer una prueba de carga de Cuánto puedo escribir sino leyera a modo de consulta y esa es la extensión que hice un una extensión para poder usar y decirle Vete a este promicious Haz esta query Devuélveme el valor que yo ya me creo una métrica dentro de mi test de k6 con el que poder verlo de hecho os lo puedo enseñar porque lo tengo aquí a ver que se pare para seguir viéndonos De hecho también acá tenemos el comentario de almudena sí recuerdo que habían estas preguntas no de cómo puedo acceder un promius desde k6 o como ver toda esta información eh del clúster que el potencial aquí es impresionante debido a que pues sí ya que tienes esta información en tus automatizaciones de k6 que vienen de datos productivos métricas que ya tienes y por lo que estoy entendiendo tu Script de k6 agarra métricas de promius y dice no sé se me ocurre este proceso ha tenido un tiempo de respuesta tal históricamente Y de ahí generas los si meas la pantalla te enseño el test vamos a ver Esto es el puedes dar un poco de zoom eh Sí claro Sí porque creo que hay gente viéndonos en dispositivos móviles y luego es bueno Luego os paso el enlace y quien quiera que entre aquí por si eh se lo tenía calladito Eh Esto almudena se lo tenía calladito aquí pero realmente lo que hacemos Es si venimos aquí a mirar el test Más allá de que esté con carpetas Y bueno pues esto es javascript Eh Esto es lo peor de casis Para qué nos vamos a engañar o sea yo entiendo la razón de usar javascript Pero bueno es javascript go hubiera molado más pero bueno Y aquí hasta aquí mi lloro dicho eso qué es lo que hacemos generamos una métrica que tenemos por aquí de queda latency y lo que hacemos Es aquí durante el proceso vamos a ver por aquí tenemos una función que lo que va a hacer es consultar la métrica esto es un poco tricky un poco aquí un poco hecho no muy allá pero realmente durante el propio Loop de ejecución de k6 cada cada x tiempo pues vamos y obtenemos la métrica Y además que esta es la parte chula se me ha ido el bueno no pasa nada porque le damos aquí Ah vale que han puesto una opción para filtrarlo si yo vengo a la configuración y yo miro qué es lo que hay aquí es donde está la magia vamos a ver eh esto es que esta es la parte yo le puedo definir Cuál es el cuál es el thresh en el que lo quiero tirar y por eso me hace falta aquí el poder consultarlo porque esto es lo que hace que yo sin necesidad de entrar a mirar gráficas lo vea pueda [ __ ] y decir el test falló Por qué Porque falló el threshold punto y si quiero voy y entro pero gracias a que esto está yo no tengo que entrar a cada uno de los test esto se lanza de manera automatizada una vez por semana y Y si hay alguna cosa pues ya avisará pero no hace falta estar monitorizando de manera activa Este es el caso de uso en el que esa parte nos hace falta el poder hacer esto y más allá de ello y de que soy un programador de javascript bastante chusquero como se puede ver no nos vamos a mentir pues lo que tenemos es que usando la extensión podemos crear un proveedor de un cliente de promicious al que vamos a hacer queries directamente y Esto va a ir al promicious donde lo tengamos es una manera de hacer una medición indirecta de lo que quiero medir quizás no es lo más acertado o lo más preciso pero pues con lo que tienes haz lo que puedas Yo creo que es bastante bueno no eh No sé por qué qué qué le falta para ser más acertado y preciso está obteniendo el valor que necesitas no Claro pero es verdad que realmente a mí lo que quizás me gustaría o lo que quizás entendería que es mejor es si yo pudiera o Bueno de hecho es otra parte que en el futuro quizás podamos implementar si yo pudiese medir realmente cuánto tiempo me cuesta añadirlo Pues eso que os decía realmente Qué es un proceso es Añadir el manifiesto que este componente lo procese que genere lo que necesita que empiece a escalar pero Cómo puedo medir yo eso sin estar midiendo también sin poder evitarlo el control Plane las latencias con el control Plane porque claro esto es un proyecto Open source esto La idea es mediante dashboard poder que que poder exponerlo y que quien quiera consultarlo pueda entrar y ver el valor de lo que pasó en una prueba comoo al final una prueba yo entiendo desde mi ignorancia que tiene que ser lo más replicable posible y cuando empiezas a meter el control Play de un claser de kubernetes El plano de control las latencias creo que se hace menos replicable o menos O sea el el sistema bajo test es mucho más abstracto Sí porque va comar a tener metes L tensia y esto se vuelve se escala y sí lo veo como a Entonces es verdad que no me acaba de gustar porque realmente si la si el si la desviación es muy alta si mi carga si mi carga de trabajo está demasiado sobre O sea si si queda el operador estuviera demasiado sobrecargado esa métrica que expone puede no ser real Tampoco porque se pueden solapar los loops porque puede pasar puede no ser real Entonces el problema de esto que no me gusta es que puedes medir si vas bien a un nivel o si te empiezas a desviar pero no creo que pueda decir estoy muy lejos de ir en en el funcionamiento creo que me permite medir si voy bien Me permite decir voy a responder a esta carga con estos recursos s lo puedo medir puedo hacer un benchmark de cómo voy a ir ahí pero no podría predecir por encima cuánto me va a hacer falta de una manera eficiente de una manera determinista que creo que sería importante también pero bueno insisto con lo que tienes haz lo que puedas Es mejor decir con una cpu procesas 1000 que decir Welcome To The Jungle prueba y ya ya te explotará oye y algunos ejemplos o experiencias prácticas con esto que ya tienes aquí que empezaste a implementar Supongo ya has empezado a tener diversión con ello como que pero como Qué cosas acá porque pues me contabas que ahí ya estás Eh poniendo al límite ya estás corriendo k6 ya estás haciendo algunas cosas en qué esto lo tiramos de manera automatizada todas las veces pero también tenemos http y tengo otra demo eh Porque hablar es gratis entonces tengo otra demo que es una demo Bueno pues siguiendo mi nivel no sé si se pide un poco de zom el código otra vez gracias y creo que la gente dice que se ve mejor el tema en blanco No yo no tengo preferencia ahí son dos equipos no Team Edward y Team qu era los de Crepúsculo no hemos oído tu voz blanco oscuro a mí me gusta en oscuro pero s ahí es muy personal el que más te guste No te preocupes haciendo un gran alarde de originalidad pues me he ido a la página de grafana y me he cogido el Script de demo de de grafana Pues porque yo que sé insisto soy un programador muy chusquero y en javascript y así se soluciona entonces claro esto podemos pensar que es una de las pruebas de carga que hacemos en el trabajo tranquilamente eh claro qué es lo que hacíamos nosotros poníamos y decíamos fácil pongo en un proceso en un pipeline de azur debs de github pongo el binario de k6 y lo ejecuto desde ahí fácil bien tiene sentido hasta que empiezas a pensar cu Cuánta capacidad me va a dar ese proceso Porque si yo quiero más usuarios qué hago pongo máquinas más grandes hasta dónde llego con eso qué es una de las cosas que permitía en su día Ya jmeter hacer un modelo de claster viación de jmeter que es una de las cosas que me gusta de k6 que tiene un operador que hace eso por ti directamente que es muy cómodo Y muy fácil entonces bueno el enlace del operador lo tenéis vosotros tampoco os voy a hacer todo el trabajo no Pero qué es lo que hacemos nosotros no es broma me podéis decir Cállate Ya no pasa nada Qué es lo que hacemos pues realmente este puede ser un ejemplo en el que vamos a definir durante el test todas esas cosas pero cuando lo cuando lo ejecutemos no lo vamos a ejecutar desde la máquina porque mi máquina con un mac el que sea con un mac puede llegar a tanto con otro puede llegar y con un Windows y al final no es replicable por eso intentamos que los los teses sobre todo cuando estás haciendo un test de carga de un producto crítico sea replicable sea determinista en cuanto a Qué recursos tienes Por eso intentamos evitar malos vecinos el típico en inglés suena mejor el Bad neighbors de si tengo en el mismo nodo varios teses corriendo intentamos que que se pare Entonces vamos a utilizamos el operador que nos permite sin entrar Bueno podemos entrar a detalle vamos a buen esto es dejémoslo nos saltamos el detalle la documentación es buena he de decir que lo habéis dicho muchas veces pero es verdad que la documentación de casis es buena eso hay que reconocerlo entonces se puede ir a mirar vamos a lanzarlo y os enseño el manifiesto en el claser pero realmente eh lo que lo que hacemos nosotros es desplegamos lo hemos automatizado con un char de helm para poner todos los valores que necesitamos el char de helm lo está en github el que hemos hecho eh el de queda lo copiamos a srm el de srm lo he limpiado de cosas de negocio y lo he traído aquí Así que es más o menos lo que va a ha Pero qué es lo que tenemos pues Vale Nos va a desplegar un test de k6 y este test de k6 es un manifiesto sencillo en el que vamos a poder configurar los teses y esto está muy bien porque yo le voy a decir cuántas instancias quiero y me desentiendo 100% de cómo va el operador lo va a hacer por mí dale un poco de un poco de zoom para verlo un poco más Ah claro zooma todo correcto un poquito al final es un manifiesto que que ofrece el operador en el que yo voy a poder definir qué es lo que hay y bueno olvidémonos de este init que ahora entraremos a detalle porque no se acaba de no acaba de encajar con Cómo trabajamos nosotros pero yo le voy a poder decir mira Oye ejecútese si yo vengo a ver los nodos pues veo que hay uno arrancando que lleva 5 segundos Por qué Porque una ventaja de usar el operador es que aprovechándome del operador más las bondades de kubernetes puedo decir yo tengo este tipo de nodos que tienen una capacidad que yo ya he medido que yo ya sé cuántas vus me va a dar cada nodo de manera que yo puedo decirle Yo quiero tantos runners tantos procesos de k6 el operador va a dividir de manera eh equivalente las vus entre la cantidad de instancias que hay por lo que yo puedo decir vale en mis pruebas sé que este tipo de máquina de asur de awws o de lo que sea este tipo de máquinas me da 100 vus por ejemplo qué es lo que voy a hacer decir Bueno si mi test tiene 500 vus Levántame cinco máquinas ya está y el operador lo va a hacer y además estoy delegando a mi proveedor Cloud levantar las máquinas porque un test de carga no se lo no sé entiendo que quien hace un test de carga de 6 horas no le importa esperar 15 minutos a que se aprovisionen las máquinas a cambio de ahorrarse pasta mientras no lo está haciendo hay gente que necesita ver todo no lo veo no lo veo pero o en un pipeline también si requieres no se me ocurre y no es buena práctica No metan mucha carga en pipelines no no porque Porque además los pipelines no te permiten distribuirlo que eso es un problema de los que vimos Yo tengo un pipeline que puede lanzar 500 vus pero necesito 1000 digo pongo dos Claro pero fijaros que este ha arrancado Pero si yo veo los logs este es k6 yo veo y esto no está haciendo nada y puedes pensar [ __ ] Jorge Por qué está esto para no está el test porque yo le he dicho 200 vus y le he dicho dos instancias y el operador ha dicho fácil 100 y 100 vus yo no puedo empezar mi test hasta que todos los runners están listos porque si no no tengo 100 no tengo las 200 vus que yo le he pedido tengo 100 Entonces mi test pues es un poco es importante porque hay que coordinarlo si no vas a tener 100 y cuando van acabando los primeros 100 vienen los siguientes también es es muy muy importante de hecho ahora acaba de aparecer otro nodo y cuando ha podido está ya este pod que lo bueno y por eso me gusta casis es que se aprovecha de las propias herramientas de kubernetes para para distribuirlo ahora ha salido este starter Y seguramente si vengo a ver los logs de un momento a otro empezará a tirar cosas empezará a tirar peticiones O de hecho puedo venir y verlo Incluso en promicious porque hay que hacer la demo completa Entonces lo tengo con un promicious instalado donde yo podría poner y venir Y decirle k6 también hay que probar las últimas features de k6 y está ahí el exporter claro hombre si no hubiera funcionado os lo diría para que lo arreglara hay que no hay que perder la oportunidad y por ejemplo pues vamos a ver las vus que tenemos ahora mismo porque es un proceso que haciendo el ramping que va subiendo Bueno aquí tenemos que el proceso ahora ha iniciado y tengo las métricas y veo que está funcionando pero que han ido a la vez que si yo quisiera ver cómo está Pues bueno estos promicion en el teclado siempre pasa eso no te preocupes correcto pero ya vemos que que han arrancado a la vez es decir el operador me está dando esa sincronía si yo tengo si yo le digo quiero 500 vus y la infraestructura lo soporta me lo está dando que es una cosa que a mí me gusta mucho y me y creo que soluciona un problema de de Real en las pruebas de carga por eso me gusta es verdad que quizás pues hay que construirse un poco que el operador es un operador y que hay que construirse un poco tu herramienta lo que le das a los equipos sobre el operador porque al final es nuestro trabajo también como como ingenieros no no decir Ah es que que no encaja Mira me sobra un milímetro Aquí no hay que adaptar las cosas y construir Pero la realidad es que bueno Nos da una herramienta fiable para ejecutar de manera determinista las cosas entonces curiosidad qué le habéis puesto por encima Perdona por encima para los desarrolladores Pues mira una de las cosas que hemos hecho es el operador no acaba de soportar o sea es demasiado pide demasiados detalles que quizás un equipo no tiene Qué son demasiados detalles Cuántas vus puede correr un nodo eso para un para un developer eh Quizás es demasiado detalle qué es lo que hemos hecho Nosotros hemos calculado Cuántas Vu Sabiendo el tipo de nodos en el que corremos y lo que le decimos a los equipos es bueno Me puedes Me puedes pasar diciéndome Cuántas vus es el máximo que va a usar tu test Y nosotros a través de este char de helm que unifica y que estandariza los despliegues ya Calcula Porque si yo sé que cada nodo aguanta 100 y tú me dices 300 te tengo que poner TR que me dices 350 te tengo que poner cuatro ese tipo de cosas que es verdad que no son poner una persona en la luna no es ciencia de cohetes pero que ayuda a que nuestros equipos se puedan centrar en lo que saben hacer que es su el negocio testear cómo funciona su appi no preocuparse de la plataforma otra de las cosas que no acaba de encajar y que es una Bueno no sé si es una ñapa o una genialidad Qué es ñapa esapa es un hack cutre feo es un una tirita un parche no sé si es una ñapa o una genialidad yo apuesto más por la ñapa eh Pero qué pasa que el operador nos permite tres modelos de proveer los datos que son un config map un persistent volume o sea un volumen de persistencia dentro del clúster o local local como tal meterlo en una imagen docker Es muy feo No claro el volumen de persistencia puede parecerlo mejor pero cómo pongo yo mis teses en ese volumen en ese storage compartido en ese almacenamiento que van a usar los ranes tengo que tener otro sistema que publique ahí claro quizás se complica y luego está el más sencillo el que apriori es más sencillo que es el config map que tú puedes [ __ ] y decir yo creo un un config map que es un manifiesto de kubernetes y lo subo todo ahí y lo tira Pero esto eh es un poco lo de el quick Start funciona y el siguiente paso explota en la cara claro Cuando entras un poco en detalle resulta que no puedo hacer una prueba de carga ignorando usuarios Ah pues le meto un csv ya pero el csv de o sea el config map de kubernetes aguanta un mega no Pero puedes utilizar k6 archive que genera un tar y optimiza eh rafan muchas cosas bien pero la compresión es casi uno de los problemas de la informática y eso llega a un punto en el que no llegas a a más no puedes meter Si tienes un csv de 500 megas archive no da y que conocemos varios que quieren implementar csvc que tengo un millón de usuarios en el sistema ahí te va un Macro csv con todos los datos Y como dices el quick fix puede sonar bueno eh que creo que así lo diría en inglés ya no se me ocurrió otra palabra en español de acá de México pero que cuando ya empiezan a ver estas complejidades Pues sí obvio que vas a toparte con peculiaridades no sobre todo concurrencia cuando ya tienes cantidades impresionantes ahorita estás diciendo no necesito 300 usuarios Sí pero 300000 usuarios cómo los divido Cómo Claro pero no solo eso sino que para mí y para nosotros es muy importante que los equipos no teng O sea que la herramienta se adapte a los equipos no los equipos a la herramienta Entonces algo tan simple como este repositorio se complica porque tengo rutas y en el config map no entiende de rutas qué hago hago un Script que a la hora de desplegar haga un flat O sea me me quíos las rutas adapte el javascript se complica o sea seend sinceros no es la manera más limpia el config map te sirve para un par de scripts sencillos pero a la que tienes escenarios con proyectos un poco más estructurados no en caja y ahí es donde me parece que además vamos a pasarnos de tiempo así que cierro con el colofón final qué pase qué rápido pasa el tiempo si se está a gusto qué hacemos qué hacemos nosotros nos aprovechamos de un mix entre varios Yo sé que que lo que puedo leer local files pero no puedo generar una imagen docker con con local files porque me cargo a alguien si alguien hace eso pero qué puedo hacer puedo aprovechar las herramientas de kubernetes para tomar ventaja de ellas puedo [ __ ] y decir Bueno pues aquí os lo enseñaba no sé si lo tengo todavía por aquí eh Sí vamos a hacerle zoom Qué puedo hacer puedo meter un contenedor de init que sé que por cómo funciona kubernetes se va a ejecutar siempre donde puedo clonar el repo que yo quiera con el Branch que yo quiero es decir arranco el arranco el contenedor creo un St un almacenamiento compartido a nivel de pod entre los dos contenedores el que va arrancar y el dk6 antes de arrancar ese ese contenedor de inicio clona el repo que esto en ese crm lo hacemos con un token y no es un problema se puede hacer perfectamente porque a git clone le puedes dar el token en línea clono el repo lo dejo en una ruta dentro del podt Y qué hace pues cuando aquí venimos y vemos repo test demo no es coincidencia es porque aquí esto ha clonado el repo con una profundidad de de uno para no traerme todo el histórico que no me hace falta he clonado el repo al contenedor es decir tengo el repo directamente ese que os enseñaba de queda en mpod Si tuviera un csv de 500 megas estaría ahí si tuviera si tengo una carpeta una jerarquía compleja está ah esto es mejorable y de hecho tenemos plan de mejorarlo optimizando un poco el proceso que lo clone solo uno no está no es una versión final pero nos permite aprovechá del operador que ya nos da mucho que la plataforma se adapte a nuestros equipos y aquí si git se traga un csv de un giga quién soy yo para que tú no te lo bajes eso no sé Ahí ya son otras eh Y algo que me gusta y que creo que por lo que agarraste a k6 para hacer todo este tipo de malabares piruetas que estamos viendo que son necesarias pero creo que otras herramientas a lo mejor no te hubieran permitido dada eh esta flexibilidad que te da k6 no me lo hubieran permitido no es a lo mejor es seguro no me lo hubieran permitido para el trabajo Sí para qué dan seguro no y incluso a ver ahorita ya para también ya tenemos que ir dando el rapd este me me me llama la atención porque también hay muchas configuraciones y particularidades que luego tienes que hacer o sea ahorita que dices no el csb de un giga que se va cargar ahí yo estaría de Por qué no lo subes a una base de datos intermedia que ya lo baje o que lo ya lo puedes poner en el propio promius que baje los nombres de usuarios o sea este tipo de malabares Por así decirlo eh es muy importante que se puedan hacer y que los equipos pues lo adopten comiencen a implementarlo en sus organizaciones y y todos estos porque ahorita mencionas un ejemplo Estoy seguro que hay 20 más que pueden salir mal con esta implementación así como está y que hay que irlos puliendo e Pero bueno para no extendernos y que eh híjole Creo que nos podemos llevar aquí horas viendo todo esto no no no me quejaría es mejor no dejarme hablar No pues a eso vienes e antes de despedirnos quisiera eh también que nos platiques rápido qué andas eh Porque aquí ima también trae unos spoilers de comunidad y de cosas que andan también participando y trayendo mucho eh pues allá en España cuéntanos un poquito ima tú también ahí eh balconea a Jorge decimos aquí en México Jorge va a venir a contarnos de qué da en un meap en Barcelona la semana que viene así que en su oficina se lo montado perfecto estamos esperando la charla con demo incluida espero de queda ya [Música] [Risas] veremos alguien está por Barcelona qué fecha dónde Cómo se puede 23 en las oficinas dehub y hay que ir a.com ahora calle Vergara 14 Plaza cerca deo cerca no con Plaza Cataluña Cataluña justo encima en frente de cómo se llama el grupo de donde podemos tener más información Cloud native Barcelona ahora os paso Cloud native Barcelona ahí busquen para eh la próxima semana eh 20 Qué dijeron Perdón 23 entendí 23 el 23 además oficinas con unas vistas a plaza Cataluña espectaculares una terraza fantástica y va a haber Pizza Ah no Bueno ya czas cervezas se los mando cargado almo aquí de todos se encarga almo hasta de eso va a estar bueno entonces todo el evento Déjenme también Aquí lo ponemos en pantalla para que todos tengan la información el Cloud native Barcelona bcn y no se lo pierdan ahí va a estar Jorge como pueden ver eh le cuesta trabajo más que nada dejar de hablar de estos temas y parece que va a estar muy divertido y bueno con esto creo que ahorita ya vamos a ir cerrando el episodio no sin antes quiero yo también darles un anuncio bien interesante que tenemos ya la grafana con 2024 anunciada si alguien quiere ir a presentar el Call for papers la llamada para papeles Híjole Esto suena muy mal en español Este pero pues creo que así se dice no hay algún término por favor déjenos saber propuesta de charla propuesta de charlas me encanta Gracias e aquí eh manden sus propuestas también si quieren vayan suscribiéndose e va a ser la graf anacon en amsterdam me parece Así es sí y y se pueden entregar papeles hasta propuestas hasta el 20 de febrero creo que es sí okay Así que estén al pendiente porque pues se va a poner muy bueno no había habido evento esto de temas de pandemia temas de posponerlo y bla entonces Bueno ya está de regreso en persona así que pues no se lo pierdan eh deen les pongo aquí también para que lo tengan no se deja Esto bueno Los invito a manden sus propuestas de charla como dizo Jorge Gracias por la traducción y Eh Pues bueno eso ha sido hoy café con grafana Jorge te agradecemos muchísimo por haber venido a platicar de todos estos temas y estos no sé si llamarle malabares pero estás haciendo muchas cosas bien interesantes que eh definitivamente Vamos a darle algo de seguimiento estoy muy curioso de todas estas actividades te lo agradezco muchísimo y pues Qué gusto que pudiste venir ah gracias a vosotros A mí Yo vengo a hablar y hablar es gratis cosa no pero hablar con lo que me gusta Muchas gracias a vosotros no ha sido un gusto y pues bueno Antonio ima también gracias por venir aquí a ayudar a trolear a Jorge no se puede trolar un troll como dice yo solo para daros el dato dice almudena que no me sé ni la dirección me he equivocado en un número viviendo a 600 km creo que eso es porque me sé bastante bien la dirección o sea no porque vienes cada mes no no cuela heo 14 y es 13 creo que está muy bien Él sabe qué puerta es ahí llega y es todo lo necesario Muchas gracias almudena y pues bueno ahora sí muchas gracias a todos hoy por Ya se acabó el cafecito y es hora de retirarnos Así que nos vemos la semana que entra y con aviso de que la semana que sigue No la que viene la primera de febrero me parece vamos a estar en fosam Así que no va a haber cafecito Entonces no se espanten si no nos ven es ese jueves pero terminando F estamos de regreso y va a haber más episodios más diversión y más cafecito para todos los grafein manos que nos siguen entonces Muchas gracias a todos los que nos sintonizaron Jorge de nuevo Muchas gracias Cuídense mucho y nos estamos viendo la semana que entra adiós a todos chao y

